{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IanMcDevitt/Interview/blob/main/backtestRLlevel2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this work-in-progress project, I am developing a high-frequency trading (HFT) model utilizing an Actor-Critic framework with Proximal Policy Optimization (PPO). This project aims to create a sophisticated market-making strategy that incorporates directional-trend position holding. Key features include an evolutionary algorithm for model training, custom engineering of reward and state for decision-making accuracy, and a specialized backtesting system for model evaluation. This effort demonstrates my expertise in applying deep learning and reinforcement learning techniques to financial trading, emphasizing adaptive strategies and precision in navigating the cryptocurrency market.\n",
        "\n"
      ],
      "metadata": {
        "id": "VkN7HITDGl5q"
      },
      "id": "VkN7HITDGl5q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dc24fad0",
        "outputId": "bbe61e43-86a6-4d6e-c178-d2e12ff9c616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting uuid\n",
            "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: uuid\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6479 sha256=1add64483d2059e7e1018319d9fbfc645abc64650bb427f1c5ad11d1c4646fbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/08/9e/f0a977dfe55051a07e21af89200125d65f1efa60cbac61ed88\n",
            "Successfully built uuid\n",
            "Installing collected packages: uuid\n",
            "Successfully installed uuid-1.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "uuid"
                ]
              },
              "id": "1c629ff4a1014e0fa306e36bb7fce3ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement queue (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for queue\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement math (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for math\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement glob (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for glob\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement matplotlib.pyplot (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for matplotlib.pyplot\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement matplotlib.patches (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for matplotlib.patches\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting matplotlib.colors\n",
            "  Downloading matplotlib_colors-1.0.16-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib.colors) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib.colors) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib.colors) (1.16.0)\n",
            "Installing collected packages: matplotlib.colors\n",
            "Successfully installed matplotlib.colors-1.0.16\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "\u001b[31mERROR: Could not build wheels for pytorch, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement deque (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for deque\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install uuid\n",
        "!pip install numpy\n",
        "!pip install queue\n",
        "!pip install math\n",
        "!pip install glob\n",
        "!pip install time\n",
        "!pip install matplotlib.pyplot\n",
        "!pip install matplotlib.patches\n",
        "!pip install matplotlib.colors\n",
        "!pip install tqdm\n",
        "!pip install pytorch\n",
        "!pip install torchvision\n",
        "!pip install scipy\n",
        "!pip install scikit-learn\n",
        "!pip install gym\n",
        "!pip install keras\n",
        "!pip install deque\n",
        "\n",
        "\n"
      ],
      "id": "dc24fad0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb3pa4aVyzN-"
      },
      "outputs": [],
      "source": [
        "# At the start of your Jupyter Notebook\n",
        "%matplotlib inline\n",
        "# or\n",
        "%matplotlib notebook\n"
      ],
      "id": "Bb3pa4aVyzN-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7zqTk39OvDl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Example hyperparameters\n",
        "actor_critic_hyperparams = {\n",
        "    'state_size': 66,#324\n",
        "    'action_size': 8,\n",
        "    'shared_layers_config': [\n",
        "        # Shared layers are defined within the class\n",
        "    ],\n",
        "    'actor_layers_config': [\n",
        "        {'in_features': 128, 'out_features': 256},\n",
        "        {'in_features': 256, 'out_features': 256},\n",
        "        {'in_features': 256, 'out_features': 128}\n",
        "    ],\n",
        "    'critic_layers_config': [\n",
        "        {'in_features': 128, 'out_features': 256},\n",
        "        {'in_features': 256, 'out_features': 256},\n",
        "        {'in_features': 256, 'out_features': 128}\n",
        "    ],\n",
        "'action_scale': np.array([\n",
        "    0.00035,  # Bid Price Adjustment\n",
        "    0.00035,  # Ask Price Adjustment\n",
        "    0.0255,  # Buy Order Size\n",
        "    0.0255,  # Sell Order Size\n",
        "    0.5,     # Hold\n",
        "    0.35,    # Target Inventory Level\n",
        "    0.5,     # Cancellation Intensity\n",
        "    0.5      # Cancellation Strategy\n",
        "]),\n",
        "'action_bias': np.array([\n",
        "    -0.00025,       # Bid Price Adjustment\n",
        "    0.00025,       # Ask Price Adjustment\n",
        "    0.001,  # Buy Order Size\n",
        "    0.001,  # Sell Order Size\n",
        "    0.5,    # Hold\n",
        "    0.0,       # Target Inventory Level\n",
        "    0.5,     # Cancellation Intensity\n",
        "    0.5      # Cancellation Strategy\n",
        "]),\n",
        "\n",
        "    'log_std_min': -20,\n",
        "    'log_std_max': 2,\n",
        "    'init_nu': 15  # Initial nu value for the Student's t-distribution\n",
        "}\n",
        "ppo_hyperparams = {\n",
        "    'clip_param': 0.2,  # Clipping parameter for PPO's objective function\n",
        "    'ppo_epoch': 1,     # Number of epochs for PPO updates\n",
        "    'mini_batch_size': 128,  # Size of mini-batches used in PPO updates\n",
        "    'value_loss_coef': 0.5, # Coefficient for the value loss term\n",
        "    'entropy_coef': 0.1,   # Coefficient for the entropy bonus 0.001\n",
        "    'lr': 3e-4,             # Learning rate for the optimizer\n",
        "    'eps': 1e-5,            # Epsilon value for the optimizer\n",
        "    'max_grad_norm': 1.0,   # Maximum norm for gradient clipping\n",
        "    'target_entropy': -0.1 # Example target entropy value for your HFT scenario\n",
        "}\n",
        "\n",
        "\n",
        "environment_training_settings = {\n",
        "    'buffer_size': 2048,              # Size of the rollout buffer\n",
        "    'state_shape': (1,66),            # Shape of the state space\n",
        "    'action_shape': (1,8),\n",
        "    'mini_batch_size': 128, # Shape of the action space\n",
        "    'gamma': 0.99,                    # Discount factor for future rewards\n",
        "    'lambda_gae': 0.95,               # Lambda parameter for Generalized Advantage Estimation\n",
        "    'total_timesteps': 100000,        # Total number of timesteps for the training process\n",
        "    'evaluation_interval': 5000,      # Interval (in timesteps) at which the model is evaluated\n",
        "    'num_evaluation_episodes': 10     # Number of episodes to run during each evaluation\n",
        "}\n",
        "\n",
        "evolutionary_training_config = {\n",
        "    'age_threshold': 6,\n",
        "    'performance_threshold': -0.2,\n",
        "    'improvement_rate_threshold': 0.01,\n",
        "    'relative_ranking_threshold': 0.25,\n",
        "    'diversity_threshold': 0.5,\n",
        "    'baseline_avg_age': 10,\n",
        "    'baseline_avg_performance': 0,\n",
        "    'age_std_dev_factor': 1,\n",
        "    'performance_std_dev_factor': 1,\n",
        "    'population_size': 20,\n",
        "    'num_generations': 50\n",
        "}\n"
      ],
      "id": "m7zqTk39OvDl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUswFXtdWAtR"
      },
      "outputs": [],
      "source": [
        "EVOLUTION_INTERVAL = 2 * 60 * 60  # 2 hours in seconds\n",
        "TRAINING_FREQUENCY = 4  # Train 4 times within the evolution interval\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import time\n",
        "from collections import deque\n",
        "from threading import Lock\n",
        "from scipy.stats import mstats\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import StudentT\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from gym import spaces\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import numpy as np\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import kurtosis\n",
        "\n",
        "\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import queue\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "class ModelWithAge:\n",
        "    def __init__(self, actor_critic, lob_instance, ppo, rollout_buffer, environment, volatility, trading_manager):\n",
        "        self.actor_critic = actor_critic  # The model (neural network)\n",
        "        self.lob_instance = lob_instance  # Instance of the Limit Order Book (LOB)\n",
        "        self.ppo = ppo  # Proximal Policy Optimization (PPO) algorithm instance\n",
        "        self.rollout_buffer = rollout_buffer  # Rollout buffer for storing training data\n",
        "        self.environment = environment  # Trading environment\n",
        "        self.volatility = volatility  # Volatility of the model\n",
        "        self.decision_time = None\n",
        "        self.trading_manager = trading_manager\n",
        "\n",
        "        self.age = 0  # Age of the model\n",
        "        self.performance = 0  # Current performance of the model\n",
        "        self.performance_history = []  # History of the model's performance\n",
        "\n",
        "    def update_performance(self, new_performance):\n",
        "        \"\"\"\n",
        "        Update the model's performance and add the new performance to the history.\n",
        "\n",
        "        Args:\n",
        "            new_performance (float): The new performance metric of the model.\n",
        "        \"\"\"\n",
        "        self.performance = self.environment.portfolio_manager.get_latest_portfolio_value() - 500\n",
        "        # self.performance_history.append(new_performance)\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Use the model to determine an action based on the given state.\n",
        "\n",
        "        Args:\n",
        "            state (array): The current state of the environment.\n",
        "\n",
        "        Returns:\n",
        "            action: The action determined by the model.\n",
        "            log_prob: The log probability of the action.\n",
        "            value: The value estimate for the state.\n",
        "        \"\"\"\n",
        "        return self.actor_critic.act(state)\n",
        "\n",
        "    def train(self, env, hyperparams):\n",
        "        \"\"\"\n",
        "        Train the model using data collected in the environment.\n",
        "\n",
        "        Args:\n",
        "            env: The environment to interact with.\n",
        "            hyperparams (dict): A dictionary of hyperparameters for training.\n",
        "        \"\"\"\n",
        "        # Training logic using self.actor_critic, self.ppo, and self.rollout_buffer\n",
        "        # ...\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the rollout buffer for fresh training data\n",
        "        self.rollout_buffer.reset()\n",
        "\n",
        "        # Reset the model's inventory and cash balance to their initial states\n",
        "        self.inventory = 0\n",
        "        self.cash_balance = self.initial_capital\n",
        "\n",
        "        # # Clear any pending actions that were accumulated in the previous episode\n",
        "        # self.pending_actions.clear()\n",
        "\n",
        "        # Reset the reward-related metrics\n",
        "        self.reward.reset()\n",
        "    # Other methods as needed...\n",
        "\n",
        "# Additional methods, like PPO, RolloutBuffer, and neural network definitions would be here\n",
        "\n",
        "\n",
        "    # ... Any other necessary methods ...\n",
        "class EvolutionaryModel:\n",
        "    def __init__(self,  actor_critic_hyperparams, ppo_hyperparams, rollout_buffer_params, initial_lob_state, evolutionary_training_config, volatility, portfolio_manager, capital, trading_manager):\n",
        "        self.actor_critic_hyperparams = actor_critic_hyperparams\n",
        "        self.ppo_hyperparams = ppo_hyperparams\n",
        "        self.rollout_buffer_params = rollout_buffer_params\n",
        "        self.initial_lob_state = initial_lob_state\n",
        "        self.volatility = volatility\n",
        "        self.portfolio_manager = portfolio_manager\n",
        "        self.capital = capital\n",
        "        self.evolutionary_training_config = evolutionary_training_config\n",
        "        self.trading_manager = trading_manager\n",
        "        self.population = self.initialize_population()\n",
        "\n",
        "    def initialize_population(self):\n",
        "        population = []\n",
        "        for _ in range(self.evolutionary_training_config['population_size']):\n",
        "            actor_critic = self.create_random_actor_critic_model(self.actor_critic_hyperparams)\n",
        "            #self.inject_adaptive_noise_into_model(actor_critic, )\n",
        "\n",
        "            lob_instance = copy.deepcopy(self.initial_lob_state)\n",
        "            ppo = PPO(actor_critic, self.ppo_hyperparams)\n",
        "            rollout_buffer = RolloutBuffer(self.rollout_buffer_params)\n",
        "            portfolio_manager = copy.deepcopy(self.portfolio_manager)\n",
        "            trading_manager = copy.deepcopy(self.trading_manager)\n",
        "            new_volatility = copy.deepcopy(self.volatility)\n",
        "            trading_environment = ContinuousTradingEnvironment(new_volatility, portfolio_manager, self.capital, trading_manager)\n",
        "\n",
        "            model_with_age = ModelWithAge(actor_critic, lob_instance, ppo, rollout_buffer, trading_environment, new_volatility, trading_manager)\n",
        "            population.append(model_with_age)\n",
        "        return population\n",
        "\n",
        "    def clone(self):\n",
        "        # Create a deep copy of the model along with its LOB\n",
        "        cloned_lob = deepcopy(self.lob)\n",
        "        cloned_model = deepcopy(self.actor_critic)\n",
        "        return ModelWithAge(cloned_model, cloned_lob)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_random_actor_critic_model(hyperparams):\n",
        "        # Initialize a new ActorCriticNetwork instance with random weights\n",
        "        random_model = ActorCriticNetwork(\n",
        "            state_size=hyperparams['state_size'],\n",
        "            action_size=hyperparams['action_size'],\n",
        "            shared_layers_config=hyperparams['shared_layers_config'],\n",
        "            actor_layers_config=hyperparams['actor_layers_config'],\n",
        "            critic_layers_config=hyperparams['critic_layers_config'],\n",
        "            action_scale=hyperparams['action_scale'],\n",
        "            action_bias=hyperparams['action_bias'],\n",
        "            log_std_min=hyperparams.get('log_std_min', -2),\n",
        "            log_std_max=hyperparams.get('log_std_max', 1),\n",
        "            init_nu=hyperparams.get('init_nu', 7)\n",
        "        )\n",
        "        random_model.eval()\n",
        "        # Randomize the weights and biases of the network\n",
        "        for layer in random_model.modules():\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "                if layer.bias is not None:\n",
        "                    nn.init.uniform_(layer.bias, -0.1, 0.1)\n",
        "\n",
        "        return random_model\n",
        "\n",
        "    def evolve_population(self):\n",
        "        avg_age = sum(model.age for model in self.population) / len(self.population)\n",
        "        avg_performance = sum(model.performance for model in self.population) / len(self.population)\n",
        "\n",
        "        print(f\"Average Age: {avg_age}, Average Performance: {avg_performance}\")\n",
        "\n",
        "        dynamic_age_threshold = self.adjust_age_threshold_based_on_population_trends(self.population, self.evolutionary_training_config)\n",
        "        dynamic_performance_threshold = self.adjust_performance_threshold_based_on_population_trends(self.population, self.evolutionary_training_config)\n",
        "\n",
        "        print(f\"Dynamic Age Threshold: {dynamic_age_threshold}, Dynamic Performance Threshold: {dynamic_performance_threshold}\")\n",
        "\n",
        "        # Pruning models based on age and performance\n",
        "        self.population = [model for model in self.population if not self.should_prune(model, avg_age, avg_performance, dynamic_age_threshold, dynamic_performance_threshold)]\n",
        "        print(f\"Population size after pruning: {len(self.population)}\")\n",
        "\n",
        "        scores = [model.performance for model in self.population]\n",
        "        # Maintaining diversity\n",
        "        # self.population = self.maintain_diversity(self.population, scores, self.evolutionary_training_config['diversity_threshold'])\n",
        "        # print(f\"Population size after maintaining diversity: {len(self.population)}\")\n",
        "\n",
        "        sorted_population = sorted(zip(scores, self.population), key=lambda pair: pair[0], reverse=True)\n",
        "        top_performers = [model for _, model in sorted_population[:len(sorted_population) // 2]]\n",
        "        new_population = top_performers.copy()\n",
        "\n",
        "        print(f\"Selected top performers. New population size: {len(new_population)}\")\n",
        "\n",
        "        while len(new_population) < self.evolutionary_training_config['population_size']:\n",
        "            parent1, parent2 = random.sample(top_performers, 2)\n",
        "            child_actor_critic = self.two_point_crossover(parent1.actor_critic, parent2.actor_critic)\n",
        "            self.mutate(child_actor_critic)\n",
        "\n",
        "            child_lob_instance = copy.deepcopy(self.initial_lob)\n",
        "            child_ppo = PPO(child_actor_critic, self.ppo_hyperparams)\n",
        "            child_rollout_buffer = RolloutBuffer(self.rollout_buffer_params)\n",
        "            child_portfolio_manager = copy.deepcopy(self.portfolio_manager)\n",
        "            child_volatility = copy.deepcopy(self.volatility)\n",
        "            child_trading_manager = copy.deepcopy(self.trading_manager)\n",
        "            child_trading_environment = ContinuousTradingEnvironment(child_volatility, child_portfolio_manager, self.capital, child_trading_manager)\n",
        "            child_model = ModelWithAge(child_actor_critic, child_lob_instance, child_ppo, child_rollout_buffer, child_trading_environment, child_volatility, child_trading_manager)\n",
        "            new_population.append(child_model)\n",
        "\n",
        "            print(f\"Added new child model to population. Total population size: {len(new_population)}\")\n",
        "\n",
        "        self.population = new_population\n",
        "        print(f\"Final population size after evolution: {len(self.population)}\")\n",
        "        # Additional methods as needed for training, performance evaluation, etc.\n",
        "\n",
        "    # Additional methods as needed for training, performance evaluation, etc.\n",
        "\n",
        "    def calculate_rate_of_improvement(self,model):\n",
        "        if len(model.performance_history) < 2:\n",
        "            return 0\n",
        "        return model.performance_history[-1] - model.performance_history[-2]\n",
        "\n",
        "    # Function to calculate relative ranking of a model in the population\n",
        "    def calculate_relative_ranking(self,model, population):\n",
        "        scores = [m.performance for m in population]\n",
        "        return sum(1 for score in scores if model.performance > score) / len(scores)\n",
        "\n",
        "    # Function to decide whether to prune a model\n",
        "    def should_prune(self, model, avg_age, avg_performance, population, config):\n",
        "        age_difference = model.age - avg_age\n",
        "        performance_difference = model.performance - avg_performance\n",
        "        improvement_rate = self.calculate_rate_of_improvement(model)\n",
        "        relative_ranking = self.calculate_relative_ranking(model, population)\n",
        "\n",
        "        age_threshold = config['age_threshold']\n",
        "        performance_threshold = config['performance_threshold']\n",
        "        improvement_rate_threshold = config['improvement_rate_threshold']\n",
        "        relative_ranking_threshold = config['relative_ranking_threshold']\n",
        "\n",
        "        return (age_difference > age_threshold and\n",
        "                performance_difference < -performance_threshold and\n",
        "                improvement_rate < improvement_rate_threshold and\n",
        "                relative_ranking < relative_ranking_threshold)\n",
        "\n",
        "    # Evolutionary Functions\n",
        "    def two_point_crossover(self, parent1, parent2):\n",
        "        child = copy.deepcopy(parent1)\n",
        "        for param1, param2 in zip(child.parameters(), parent2.parameters()):\n",
        "            if len(param1.data.size()) == 2:  # Weight matrices\n",
        "                num_rows = param1.data.size(0)\n",
        "                points = sorted(random.sample(range(num_rows), 2))\n",
        "                param1.data[points[0]:points[1]] = param2.data[points[0]:points[1]]\n",
        "        return child\n",
        "\n",
        "    def mutate(self, model):\n",
        "        for param in model.parameters():\n",
        "            if len(param.size()) == 2:  # Weight matrices\n",
        "                for i in range(param.size(0)):\n",
        "                    for j in range(param.size(1)):\n",
        "                        if random.uniform(0, 1) < 0.1:  # Mutation probability\n",
        "                            param.data[i][j] += random.uniform(-0.1, 0.1)  # Mutation amount\n",
        "\n",
        "    def inject_adaptive_noise_into_model(self, model, base_noise_std=0.1):\n",
        "        with torch.no_grad():\n",
        "            for param in model.parameters():\n",
        "                param_std = param.data.std().item()\n",
        "                scaled_noise_std = base_noise_std * (1 / (1 + param_std))  # Example scaling based on std deviation of the parameter\n",
        "                noise = torch.randn_like(param) * scaled_noise_std\n",
        "                param.data += noise\n",
        "\n",
        "\n",
        "    def calculate_genetic_distance(self, model1, model2):\n",
        "        distance = 0\n",
        "        for param1, param2 in zip(model1.parameters(), model2.parameters()):\n",
        "            distance += torch.norm(param1.data - param2.data, p=2).item()  # Euclidean distance\n",
        "        return distance\n",
        "\n",
        "    def calculate_population_diversity(self):\n",
        "        total_distance = 0\n",
        "        count = 0\n",
        "        for i in range(len(self.population)):\n",
        "            for j in range(i + 1, len(self.population)):\n",
        "                total_distance += self.calculate_genetic_distance(self.population[i].actor_critic, self.population[j].actor_critic)\n",
        "                count += 1\n",
        "        return total_distance / count if count > 0 else 0\n",
        "\n",
        "    def maintain_diversity(self, population, scores, diversity_threshold):\n",
        "        diversity_score = self.calculate_population_diversity(population)\n",
        "        if diversity_score < diversity_threshold:\n",
        "            for i in range(len(population) - len(scores) // 2, len(population)):\n",
        "                hyperparams = population[i].ppo.hyperparams  # Assuming hyperparams are stored in the ppo object of each model\n",
        "                population[i] = EvolutionaryModel.create_random_actor_critic_model(hyperparams)\n",
        "        return population\n",
        "\n",
        "    def adjust_age_threshold_based_on_population_trends(self, population, config):\n",
        "        ages = [model.age for model in population]\n",
        "        avg_age = sum(ages) / len(ages)\n",
        "        age_std_dev = (sum((age - avg_age) ** 2 for age in ages) / len(ages)) ** 0.5\n",
        "        baseline_age_threshold = config['baseline_avg_age']\n",
        "        age_std_dev_factor = config['age_std_dev_factor']\n",
        "\n",
        "        # Adjust the age threshold based on the average age and standard deviation\n",
        "        # Older populations might need a higher threshold\n",
        "        if avg_age > 5:\n",
        "            return baseline_age_threshold + age_std_dev_factor * age_std_dev\n",
        "        else:\n",
        "            return baseline_age_threshold - age_std_dev_factor * age_std_dev\n",
        "\n",
        "\n",
        "    def adjust_performance_threshold_based_on_population_trends(self, population, config):\n",
        "        performances = [model.performance for model in population]\n",
        "        avg_performance = sum(performances) / len(performances)\n",
        "        performance_std_dev = (sum((performance - avg_performance) ** 2 for performance in performances) / len(performances)) ** 0.5\n",
        "        baseline_performance_threshold = config['baseline_avg_performance']\n",
        "        performance_std_dev_factor = config['performance_std_dev_factor']\n",
        "\n",
        "        # Adjust the performance threshold based on the average performance and standard deviation\n",
        "        # Higher performing populations might need a tighter threshold\n",
        "        if avg_performance > 200:\n",
        "            return baseline_performance_threshold - performance_std_dev_factor * performance_std_dev\n",
        "        else:\n",
        "            return baseline_performance_threshold + performance_std_dev_factor * performance_std_dev\n",
        "\n",
        "        def select_top_performers(self, num_top_performers):\n",
        "            # Sort the population based on model performance in descending order\n",
        "            sorted_population = sorted(self.population, key=lambda model: model.performance, reverse=True)\n",
        "            # Return the top performers\n",
        "            return sorted_population[:num_top_performers]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RateLimiter:\n",
        "    def __init__(self, max_num_orders, max_ratecount, ratecount_decay, decay_interval):\n",
        "        self.max_num_orders = max_num_orders\n",
        "        self.max_ratecount = max_ratecount\n",
        "        self.ratecount_decay = ratecount_decay\n",
        "        # self.max_total_orders = max_total_orders\n",
        "        #self.max_buy_ratio = max_buy_ratio\n",
        "        #self.max_sell_ratio = max_sell_ratio\n",
        "        self.total_orders_placed = 0\n",
        "\n",
        "        self.decay_interval = decay_interval\n",
        "        self.rate_limit_window_reset_time = None\n",
        "        self.current_ratecount = 0\n",
        "        self.last_action_time = None\n",
        "        self.lock = Lock()\n",
        "\n",
        "    def update_rate_limit_reset_time(self):\n",
        "        if self.current_ratecount > 0:\n",
        "            time_to_full_decay = self.current_ratecount / self.ratecount_decay\n",
        "            self.rate_limit_window_reset_time = self.last_action_time + time_to_full_decay\n",
        "        else:\n",
        "            self.rate_limit_window_reset_time = None\n",
        "\n",
        "\n",
        "    # def simulate_time_step(self, current_time):\n",
        "    #     with self.lock:\n",
        "    #         elapsed_time = current_time - self.last_action_time\n",
        "    #         self.current_ratecount = max(0, self.current_ratecount - self.ratecount_decay * elapsed_time)\n",
        "    #         self.last_action_time = current_time\n",
        "    #         self.update_rate_limit_reset_time()\n",
        "\n",
        "    def simulate_time_step(self, local_timestamp):\n",
        "        #with self.lock:\n",
        "        if self.last_action_time is None:\n",
        "            # For the first action, set the last action time to the current timestamp\n",
        "            self.last_action_time = local_timestamp\n",
        "        else:\n",
        "            # Calculate the elapsed time since the last action\n",
        "            elapsed_time = local_timestamp - self.last_action_time\n",
        "\n",
        "            # Apply the decay to the rate count\n",
        "            # The decay is based on the elapsed time and the ratecount_decay parameter\n",
        "            decay_amount = self.ratecount_decay * elapsed_time\n",
        "            self.current_ratecount = max(0, self.current_ratecount - decay_amount)\n",
        "\n",
        "            # Update the last action time to the current timestamp\n",
        "            self.last_action_time = local_timestamp\n",
        "\n",
        "        # Update the time for when the rate limit window is reset\n",
        "        self.update_rate_limit_reset_time()\n",
        "\n",
        "\n",
        "\n",
        "    # ... other methods ...\n",
        "\n",
        "    # def get_time_until_rate_limit_reset(self):\n",
        "    #     if self.rate_limit_window_reset_time:\n",
        "    #         return max(0, self.rate_limit_window_reset_time - time.time())\n",
        "    #     return 0\n",
        "\n",
        "    def get_time_until_rate_limit_reset(self, local_timestamp):\n",
        "        \"\"\"\n",
        "        Calculate the time until the rate limit is reset, based on the provided local timestamp.\n",
        "\n",
        "        :param local_timestamp: The simulated current time in the backtesting environment.\n",
        "        :return: Time in seconds until the rate limit resets. If no reset is scheduled, returns 0.\n",
        "        \"\"\"\n",
        "        #with self.lock:\n",
        "        if self.rate_limit_window_reset_time:\n",
        "            return max(0, self.rate_limit_window_reset_time - local_timestamp)\n",
        "        return 0\n",
        "\n",
        "    def get_usage_percentage(self):\n",
        "        # Calculate the usage percentage\n",
        "        usage_percentage = (self.current_ratecount / self.max_ratecount) * 100\n",
        "        return usage_percentage\n",
        "\n",
        "    def can_execute_order(self, local_timestamp):\n",
        "        #with self.lock:\n",
        "        self.simulate_time_step(local_timestamp)\n",
        "\n",
        "        if self.current_ratecount >= self.max_ratecount:\n",
        "            return False, \"EOrder:Rate limit exceeded\"\n",
        "\n",
        "        if self.total_orders_placed >= self.max_num_orders:\n",
        "            return False, \"EOrder:Max number of orders exceeded\"\n",
        "\n",
        "        return True, \"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _calculate_cancellation_penalty(self, order_age):\n",
        "          if order_age < 5:\n",
        "              return 8\n",
        "          elif order_age < 10:\n",
        "              return 6\n",
        "          elif order_age < 15:\n",
        "              return 5\n",
        "          elif order_age < 45:\n",
        "              return 4\n",
        "          elif order_age < 90:\n",
        "              return 2\n",
        "          elif order_age < 300:\n",
        "              return 1\n",
        "          else:\n",
        "              return 0\n",
        "\n",
        "    def update_on_order_placement(self, local_timestamp):\n",
        "        with self.lock:\n",
        "            self.simulate_time_step(local_timestamp)\n",
        "            self.current_ratecount += 1\n",
        "            self.total_orders_placed += 1  # Increment total orders\n",
        "\n",
        "\n",
        "    def can_cancel_order(self, order_placement_time, local_timestamp):\n",
        "        order_age = local_timestamp - order_placement_time\n",
        "\n",
        "        #with self.lock:\n",
        "        self.simulate_time_step(local_timestamp)\n",
        "        penalty = self._calculate_cancellation_penalty(order_age)\n",
        "\n",
        "        if self.current_ratecount + penalty >= self.max_ratecount:\n",
        "            return False, \"EOrder:Rate limit exceeded\"\n",
        "\n",
        "        self.current_ratecount += penalty\n",
        "        self.last_action_time = local_timestamp\n",
        "\n",
        "        return True, \"\"\n",
        "\n",
        "    # def can_cancel_order(self, order_placement_time):\n",
        "    #     current_time = time.time()\n",
        "    #     order_age = current_time - order_placement_time\n",
        "\n",
        "    #     with self.lock:\n",
        "    #         self.simulate_time_step(current_time)\n",
        "    #         penalty = self._calculate_cancellation_penalty(order_age)\n",
        "\n",
        "    #         if self.current_ratecount + penalty >= self.max_ratecount:\n",
        "    #             return False, \"EOrder:Rate limit exceeded\"\n",
        "\n",
        "    #         self.current_ratecount += penalty\n",
        "    #         self.last_action_time = current_time\n",
        "\n",
        "    #         return True, \"\"\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Swish, self).__init__()\n",
        "        self.beta = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(self.beta * x)\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mish, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Mish function: x * tanh(softplus(x)) = x * tanh(ln(1 + e^x))\n",
        "        return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "\n",
        "class ActorCriticNetwork(nn.Module):\n",
        "    def __init__(self, state_size, action_size, shared_layers_config, actor_layers_config, critic_layers_config, action_scale, action_bias, log_std_min=-2, log_std_max=2, init_nu=15):\n",
        "        super(ActorCriticNetwork, self).__init__()\n",
        "        # Shared layers\n",
        "        # Shared layers\n",
        "        self.shared_layers = self._build_layers([\n",
        "            {'in_features': state_size, 'out_features': 128},\n",
        "            {'in_features': 128, 'out_features': 256},\n",
        "            {'in_features': 256, 'out_features': 256},\n",
        "            {'in_features': 256, 'out_features': 128},\n",
        "            {'in_features': 128, 'out_features': 128}\n",
        "\n",
        "        ])\n",
        "\n",
        "        # Actor layers\n",
        "        self.actor_layers = self._build_layers(actor_layers_config)\n",
        "        self.actor_mean = nn.Linear(128, action_size)\n",
        "        self.actor_log_std = nn.Parameter(torch.zeros(1, action_size))\n",
        "        self.actor_log_std = nn.Parameter(torch.zeros(1, action_size).fill_(-0.5))  # Initialize closer to the middle of your range\n",
        "\n",
        "\n",
        "        # Critic layers\n",
        "        self.critic_layers = self._build_layers(critic_layers_config)\n",
        "        self.critic_output = nn.Linear(128, 1)\n",
        "        self.actor_nu = nn.Parameter(torch.tensor([np.log(init_nu)]))\n",
        "\n",
        "        # Action scale and bias\n",
        "        # Set action scale and bias\n",
        "        # self.action_scale = torch.tensor(action_scale, dtype=torch.float32)\n",
        "        # self.action_bias = torch.tensor(action_bias, dtype=torch.float32)\n",
        "\n",
        "        # # Ensure these are registered as part of the model's parameters\n",
        "        # self.register_buffer('action_scale', self.action_scale)\n",
        "        # self.register_buffer('action_bias', self.action_bias)\n",
        "        self.register_buffer('action_scale', torch.tensor(action_scale, dtype=torch.float32))\n",
        "        self.register_buffer('action_bias', torch.tensor(action_bias, dtype=torch.float32))\n",
        "\n",
        "\n",
        "\n",
        "        # Log std bounds\n",
        "        self.log_std_min = log_std_min\n",
        "        self.log_std_max = log_std_max\n",
        "\n",
        "    def _build_layers(self, layer_config):\n",
        "        layers = []\n",
        "        for idx, layer_details in enumerate(layer_config):\n",
        "            layers.append(nn.Linear(layer_details['in_features'], layer_details['out_features']))\n",
        "            if idx < len(layer_config) - 1:\n",
        "                layers.append(nn.BatchNorm1d(layer_details['out_features']))\n",
        "                layers.append(Mish())  # Replace ReLU with Swish\n",
        "                if layer_details.get('dropout', 0) > 0:\n",
        "                    layers.append(nn.Dropout(layer_details['dropout']))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, state):\n",
        "        # Check for NaN in input state\n",
        "        assert not torch.isnan(state).any(), \"NaN detected in input state\"\n",
        "\n",
        "        # Shared feature extraction\n",
        "        shared_output = self.shared_layers(state)\n",
        "        assert not torch.isnan(shared_output).any(), \"NaN detected in shared_output after shared_layers\"\n",
        "\n",
        "        # Actor path\n",
        "        actor_output = self.actor_layers(shared_output)\n",
        "        assert not torch.isnan(actor_output).any(), \"NaN detected in actor_output after actor_layers\"\n",
        "\n",
        "        mean = self.actor_mean(actor_output)\n",
        "        assert not torch.isnan(mean).any(), \"NaN detected in mean after actor_mean\"\n",
        "\n",
        "        # Ensure std is positive and within reasonable limits\n",
        "        log_std = self.actor_log_std.clamp(self.log_std_min, self.log_std_max)\n",
        "        std = torch.exp(log_std)\n",
        "        assert not torch.isnan(std).any(), \"NaN detected in std after exponentiation\"\n",
        "\n",
        "        # Ensure nu is positive and greater than 1 to avoid undefined behavior\n",
        "        #nu = torch.exp(self.actor_nu).clamp(min=5, max=30)\n",
        "        nu = torch.exp(self.actor_nu.clamp(min=np.log(1.1), max=np.log(30)))\n",
        "        assert not torch.isnan(nu).any(), \"NaN detected in nu after processing\"\n",
        "\n",
        "        # Critic path\n",
        "        critic_output = self.critic_layers(shared_output)\n",
        "        assert not torch.isnan(critic_output).any(), \"NaN detected in critic_output after critic_layers\"\n",
        "\n",
        "        value = self.critic_output(critic_output)\n",
        "        assert not torch.isnan(value).any(), \"NaN detected in value after critic_output\"\n",
        "\n",
        "        # Final check before returning\n",
        "        assert not torch.isnan(mean).any(), \"NaN detected in mean before return\"\n",
        "        assert not torch.isnan(std).any(), \"NaN detected in std before return\"\n",
        "        assert not torch.isnan(nu).any(), \"NaN detected in nu before return\"\n",
        "        assert not torch.isnan(value).any(), \"NaN detected in value before return\"\n",
        "\n",
        "        return mean, std, nu, value\n",
        "\n",
        "    # def forward(self, state):\n",
        "    #     # Flatten the state tensor to 2D (batch size by features)\n",
        "    #     flattened_state = state.view(state.size(0), -1)\n",
        "\n",
        "    #     # Shared feature extraction\n",
        "    #     shared_output = self.shared_layers(flattened_state)\n",
        "\n",
        "    #     # Actor path\n",
        "    #     actor_output = self.actor_layers(shared_output)\n",
        "    #     mean = self.actor_mean(actor_output)\n",
        "\n",
        "    #     # Ensure std is positive and within reasonable limits\n",
        "    #     log_std = self.actor_log_std.clamp(self.log_std_min, self.log_std_max)\n",
        "    #     std = log_std.exp()\n",
        "\n",
        "    #     # Ensure nu is positive and greater than 1 to avoid undefined behavior\n",
        "    #     nu = torch.exp(self.actor_nu).clamp(min=1.1, max=30)\n",
        "\n",
        "    #     # Critic path\n",
        "    #     critic_output = self.critic_layers(shared_output)\n",
        "    #     value = self.critic_output(critic_output)\n",
        "\n",
        "    #     return mean, std, nu, value\n",
        "\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        # Pass state through the network\n",
        "        # flattened_state = state.view(state.size(0), -1)\n",
        "        # print(flattened_state.shape)\n",
        "        # Flatten the state tensor to 2D (batch size by features)\n",
        "        shared_output = self.shared_layers(state)\n",
        "        actor_output = self.actor_layers(shared_output)\n",
        "\n",
        "        # Get parameters for the Student's t-distribution\n",
        "        mean = self.actor_mean(actor_output)\n",
        "\n",
        "        # Clamping the logarithm of the standard deviation and then exponentiating it\n",
        "        log_std = self.actor_log_std.clamp(self.log_std_min, self.log_std_max)\n",
        "        # std = log_std.exp()\n",
        "        std = torch.exp(log_std)\n",
        "\n",
        "        # Ensure nu is positive and greater than 1 to avoid undefined behavior\n",
        "        # nu = torch.exp(self.actor_nu).clamp(min=5, max=30)\n",
        "        nu = torch.exp(self.actor_nu.clamp(min=np.log(1.1), max=np.log(30)))\n",
        "\n",
        "\n",
        "        # Create Student's t-distribution\n",
        "        t_dist = torch.distributions.StudentT(df=nu, loc=mean, scale=std)\n",
        "\n",
        "        # Sample action and compute log probability\n",
        "        raw_action = t_dist.rsample()  # Raw action sampling\n",
        "        log_prob = t_dist.log_prob(raw_action).sum(-1, keepdim=True)  # Log probability\n",
        "\n",
        "        # Scale and bias the raw actions\n",
        "        scaled_action = torch.tanh(raw_action) * self.action_scale + self.action_bias\n",
        "\n",
        "        # Get the value prediction from the critic network\n",
        "        value = self.critic_output(self.critic_layers(shared_output))\n",
        "\n",
        "        # Return the action, log probability, and state value estimate\n",
        "        return scaled_action, log_prob, value\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PPO:\n",
        "    def __init__(self, actor_critic, ppo_hyperparams, target_entropy=.2, entropy_coef_adjust_rate=0.01, alpha=0.1):\n",
        "        self.actor_critic = actor_critic\n",
        "        self.clip_param = ppo_hyperparams['clip_param']\n",
        "        self.ppo_epoch = ppo_hyperparams['ppo_epoch']\n",
        "        self.mini_batch_size = ppo_hyperparams['mini_batch_size']\n",
        "        self.value_loss_coef = ppo_hyperparams['value_loss_coef']\n",
        "        self.entropy_coef = ppo_hyperparams['entropy_coef']  # Initial entropy coefficient\n",
        "        self.max_grad_norm = ppo_hyperparams['max_grad_norm']\n",
        "        self.optimizer = optim.Adam(actor_critic.parameters(), lr=ppo_hyperparams['lr'], eps=ppo_hyperparams['eps'])\n",
        "        self.target_entropy = target_entropy\n",
        "        self.initial_entropy_coef = self.entropy_coef  # Store initial value\n",
        "        self.entropy_coef_adjust_rate = entropy_coef_adjust_rate\n",
        "        self.alpha = alpha  # EMA smoothing factor\n",
        "        # Initialize EMA for average entropy\n",
        "        self.ema_entropy = 0\n",
        "\n",
        "    def update_ema_entropy(self, current_entropy):\n",
        "            self.ema_entropy = self.alpha * current_entropy + (1 - self.alpha) * self.ema_entropy\n",
        "\n",
        "    def sigmoid_adjustment(self):\n",
        "        if self.target_entropy is not None:\n",
        "            current_deviation = self.ema_entropy - self.target_entropy\n",
        "            k = 1.0  # Sensitivity parameter\n",
        "            adjustment = 1 / (1 + np.exp(-k * current_deviation))\n",
        "            new_entropy_coef = self.initial_entropy_coef * adjustment\n",
        "            # Implementing a smooth update with a maximum change rate\n",
        "            max_change_rate = 0.05  # Maximum change of 5% per update\n",
        "            change = new_entropy_coef - self.entropy_coef\n",
        "            change = np.clip(change, -self.entropy_coef * max_change_rate, self.entropy_coef * max_change_rate)\n",
        "            self.entropy_coef += change\n",
        "            self.entropy_coef = max(min(self.entropy_coef, 1.0), 0.01)\n",
        "\n",
        "\n",
        "    def compute_losses(self, sample):\n",
        "\n",
        "        states = sample['states']\n",
        "        actions = sample['actions']\n",
        "        old_log_probs = sample['log_probs']\n",
        "        returns = sample['returns']\n",
        "        advantages = sample['advantages']\n",
        "        #states, actions, returns, advantages, old_action_log_probs, old_nu = batch\n",
        "\n",
        "        # Get current policy outputs given the batch states\n",
        "        states = states.squeeze(1)  # This removes the second dimension\n",
        "\n",
        "        print(\"States shape:\", states.shape)\n",
        "        action_means, action_std, action_nu, state_values = self.actor_critic(states)\n",
        "\n",
        "        # Create Student's t-distribution for current policy\n",
        "        current_dist = StudentT(df=action_nu, loc=action_means, scale=action_std)\n",
        "\n",
        "        # Compute log probabilities of batch actions\n",
        "        current_action_log_probs = current_dist.log_prob(actions).sum(-1, keepdim=True)\n",
        "\n",
        "        # Compute ratio between new and old probabilities\n",
        "        ratios = torch.exp(current_action_log_probs - old_log_probs)\n",
        "\n",
        "        # Compute actor (policy) loss\n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1.0 - self.clip_param, 1.0 + self.clip_param) * advantages\n",
        "        actor_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        # Compute critic (value) loss\n",
        "        value_loss = F.mse_loss(state_values, returns)\n",
        "\n",
        "        # Compute entropy for exploration bonus\n",
        "        entropy = current_dist.entropy().mean()\n",
        "\n",
        "        # Compute the total loss with the dynamically adjusted entropy coefficient\n",
        "        total_loss = actor_loss + self.value_loss_coef * value_loss - self.entropy_coef * entropy\n",
        "\n",
        "        return total_loss, actor_loss, value_loss, entropy\n",
        "\n",
        "\n",
        "    # def compute_gae(self, next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
        "    #     values = values + [next_value]\n",
        "    #     gae = 0\n",
        "    #     returns = []\n",
        "    #     for step in reversed(range(len(rewards))):\n",
        "    #         delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
        "    #         gae = delta + gamma * tau * masks[step] * gae\n",
        "    #         returns.insert(0, gae + values[step])\n",
        "    #     return returns\n",
        "\n",
        "    def mini_batch_generator(self, rollouts, advantages, returns):\n",
        "        batch_size = len(rollouts)\n",
        "        ids = torch.randperm(batch_size)\n",
        "        for i in range(0, batch_size, self.mini_batch_size):\n",
        "            yield rollouts[ids[i:i+self.mini_batch_size]], advantages[ids[i:i+self.mini_batch_size]], returns[ids[i:i+self.mini_batch_size]]\n",
        "\n",
        "    def adjust_entropy_bonus(self, avg_entropy):\n",
        "        if self.target_entropy is not None:\n",
        "            if avg_entropy < self.target_entropy:\n",
        "                self.entropy_coef *= (1 + self.entropy_coef_adjust_rate)\n",
        "            else:\n",
        "                self.entropy_coef *= (1 - self.entropy_coef_adjust_rate)\n",
        "            # Keep the coefficient within reasonable bounds\n",
        "            self.entropy_coef = max(min(self.entropy_coef, self.initial_entropy_coef), 0.01)\n",
        "\n",
        "    def update(self, batches):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        actor_loss_accumulator = []\n",
        "        critic_loss_accumulator = []\n",
        "        entropy_accumulator = []\n",
        "        for batch in batches:\n",
        "            # Print the overall structure of the batch\n",
        "            print(\"Batch structure:\")\n",
        "            for k, v in batch.items():\n",
        "                print(f\"{k}: {v.shape}\")\n",
        "\n",
        "            # Move batch data to the appropriate device (GPU if available)\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            total_loss, actor_loss, critic_loss, entropy = self.compute_losses(batch)\n",
        "            print(\"Processed a batch.\")\n",
        "\n",
        "            # Accumulate losses and entropy for averaging\n",
        "            actor_loss_accumulator.append(actor_loss.item())\n",
        "            critic_loss_accumulator.append(critic_loss.item())\n",
        "            entropy_accumulator.append(entropy.item())\n",
        "\n",
        "            # Optimization step for each batch\n",
        "            self.optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            if self.max_grad_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(self.actor_critic.parameters(), self.max_grad_norm)\n",
        "            self.optimizer.step()\n",
        "\n",
        "        avg_entropy = np.mean(entropy_accumulator)\n",
        "        # Update the EMA of entropy after each update cycle\n",
        "        self.update_ema_entropy(avg_entropy)\n",
        "        # Adjust the entropy coefficient based on the EMA and target entropy\n",
        "        self.sigmoid_adjustment()\n",
        "\n",
        "        avg_actor_loss = sum(actor_loss_accumulator) / len(actor_loss_accumulator)\n",
        "        avg_critic_loss = sum(critic_loss_accumulator) / len(critic_loss_accumulator)\n",
        "        # avg_entropy = sum(entropy_accumulator) / len(entropy_accumulator)\n",
        "\n",
        "        # self.adjust_entropy_bonus(avg_entropy)\n",
        "\n",
        "        return avg_actor_loss, avg_critic_loss, avg_entropy\n",
        "\n",
        "\n",
        "class RolloutBuffer:\n",
        "    def __init__(self, environment_training_settings ):\n",
        "        self.buffer_size = environment_training_settings['buffer_size']\n",
        "        self.state_shape = environment_training_settings['state_shape']\n",
        "        self.action_shape = environment_training_settings['action_shape']\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        # Initialize buffers as empty lists for dynamic appending\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.dones = []\n",
        "        self.log_probs = []\n",
        "        self.values = []\n",
        "        self.returns = []\n",
        "        self.advantages = []\n",
        "\n",
        "    def add(self, state, action, reward, done, log_prob, value):\n",
        "        # Directly append new experience data to the buffers\n",
        "        self.states.append(state.detach().cpu().numpy() if isinstance(state, torch.Tensor) else state)\n",
        "        self.actions.append(action.detach().cpu().numpy() if isinstance(action, torch.Tensor) else action)\n",
        "        self.rewards.append(reward.detach().cpu().numpy() if isinstance(reward, torch.Tensor) else reward)\n",
        "        self.dones.append(done.detach().cpu().numpy() if isinstance(done, torch.Tensor) else done)\n",
        "        self.log_probs.append(log_prob.detach().cpu().numpy() if isinstance(log_prob, torch.Tensor) else log_prob)\n",
        "        self.values.append(value.detach().cpu().numpy() if isinstance(value, torch.Tensor) else value)\n",
        "\n",
        "    def compute_returns_and_advantage(self, last_value, gamma, lambda_gae):\n",
        "        # Convert lists to numpy arrays for efficient computation\n",
        "        self.rewards = np.array(self.rewards)\n",
        "        self.values = np.array(self.values)\n",
        "        self.dones = np.array(self.dones)\n",
        "\n",
        "        # Initialize returns and advantages arrays\n",
        "        self.returns = np.zeros_like(self.rewards)\n",
        "        self.advantages = np.zeros_like(self.rewards)\n",
        "\n",
        "        last_advantage = 0\n",
        "        for t in reversed(range(len(self.rewards))):\n",
        "            if t == len(self.rewards) - 1:\n",
        "                next_non_terminal = 1.0 - self.dones[t]\n",
        "                next_value = last_value\n",
        "            else:\n",
        "                next_non_terminal = 1.0 - self.dones[t + 1]\n",
        "                next_value = self.values[t + 1]\n",
        "\n",
        "            delta = self.rewards[t] + gamma * next_value * next_non_terminal - self.values[t]\n",
        "            last_advantage = delta + gamma * lambda_gae * next_non_terminal * last_advantage\n",
        "            self.returns[t] = last_advantage + self.values[t]\n",
        "            self.advantages[t] = last_advantage\n",
        "\n",
        "        # Normalize advantages\n",
        "        advantages_mean = np.mean(self.advantages)\n",
        "        advantages_std = np.std(self.advantages) + 1e-8\n",
        "        self.advantages = (self.advantages - advantages_mean) / advantages_std\n",
        "\n",
        "    def get_sequential_mini_batches(self, mini_batch_size):\n",
        "        num_samples = len(self.states)\n",
        "        for start in range(0, num_samples, mini_batch_size):\n",
        "            indices = slice(start, start + mini_batch_size)\n",
        "            yield self._create_batch(indices)\n",
        "\n",
        "    def get_random_mini_batches(self, mini_batch_size):\n",
        "        num_samples = len(self.states)\n",
        "        indices = np.random.permutation(num_samples)\n",
        "        for start in range(0, num_samples, mini_batch_size):\n",
        "            batch_indices = indices[start:start + mini_batch_size]\n",
        "            yield self._create_batch(batch_indices)\n",
        "\n",
        "    def _create_batch(self, indices):\n",
        "        # Convert lists to numpy arrays only when creating batches\n",
        "        return {\n",
        "            'states': torch.tensor(np.array(self.states)[indices], dtype=torch.float32).to(self.device),\n",
        "            'actions': torch.tensor(np.array(self.actions)[indices], dtype=torch.float32).to(self.device),\n",
        "            'rewards': torch.tensor(np.array(self.rewards)[indices], dtype=torch.float32).to(self.device),\n",
        "            'dones': torch.tensor(np.array(self.dones)[indices], dtype=torch.bool).to(self.device),\n",
        "            'log_probs': torch.tensor(np.array(self.log_probs)[indices], dtype=torch.float32).to(self.device),\n",
        "            'values': torch.tensor(np.array(self.values)[indices], dtype=torch.float32).to(self.device),\n",
        "            'returns': torch.tensor(np.array(self.returns)[indices], dtype=torch.float32).to(self.device),\n",
        "            'advantages': torch.tensor(np.array(self.advantages)[indices], dtype=torch.float32).to(self.device),\n",
        "        }\n",
        "    # def reset(self):\n",
        "    #     # Resetting buffer arrays with appropriate shapes and types\n",
        "    #     self.states = torch.zeros((self.buffer_size, *self.state_shape), dtype=torch.float32, device=self.device)\n",
        "    #     self.actions = torch.zeros((self.buffer_size, *self.action_shape), dtype=torch.float32, device=self.device)\n",
        "    #     self.rewards = torch.zeros(self.buffer_size, dtype=torch.float32, device=self.device)\n",
        "    #     self.dones = torch.zeros(self.buffer_size, dtype=torch.bool, device=self.device)\n",
        "    #     self.log_probs = torch.zeros(self.buffer_size, dtype=torch.float32, device=self.device)\n",
        "    #     self.values = torch.zeros(self.buffer_size, dtype=torch.float32, device=self.device)\n",
        "    #     self.returns = torch.zeros(self.buffer_size, dtype=torch.float32, device=self.device)\n",
        "    #     self.advantages = torch.zeros(self.buffer_size, dtype=torch.float32, device=self.device)\n",
        "    #     self.ptr = 0\n",
        "    # def reset(self):\n",
        "    #     # Use numpy arrays for storing experiences\n",
        "    #     self.states = np.zeros((self.buffer_size, *self.state_shape), dtype=np.float32)\n",
        "    #     self.actions = np.zeros((self.buffer_size, *self.action_shape), dtype=np.float32)\n",
        "    #     self.rewards = np.zeros(self.buffer_size, dtype=np.float32)\n",
        "    #     self.dones = np.zeros(self.buffer_size, dtype=bool)\n",
        "    #     self.log_probs = np.zeros(self.buffer_size, dtype=np.float32)\n",
        "    #     self.values = np.zeros(self.buffer_size, dtype=np.float32)\n",
        "    #     self.returns = np.zeros(self.buffer_size, dtype=np.float32)\n",
        "    #     self.advantages = np.zeros(self.buffer_size, dtype=np.float32)\n",
        "    #     self.ptr = 0\n",
        "\n",
        "\n",
        "    # # def add(self, state, action, reward, done, log_prob, value):\n",
        "    # #     # Adding a new experience to the buffer\n",
        "    # #     if self.ptr >= self.buffer_size:\n",
        "    # #         raise IndexError('RolloutBuffer is full, cannot add more samples.')\n",
        "    # #     self.states[self.ptr] = torch.tensor(state, device=self.device)\n",
        "    # #     self.actions[self.ptr] = torch.tensor(action, device=self.device)\n",
        "    # #     self.rewards[self.ptr] = reward\n",
        "    # #     self.dones[self.ptr] = done\n",
        "    # #     self.log_probs[self.ptr] = log_prob\n",
        "    # #     self.values[self.ptr] = value\n",
        "    # #     self.ptr += 1\n",
        "\n",
        "    # def add(self, state, action, reward, done, log_prob, value):\n",
        "    #     # Adding a new experience to the buffer, automatically detaching tensors if necessary\n",
        "    #     if self.ptr >= self.buffer_size:\n",
        "    #         raise IndexError('RolloutBuffer is full, cannot add more samples.')\n",
        "\n",
        "    #     # Automatically detach and convert to NumPy if input is a tensor\n",
        "    #     self.states[self.ptr] = state.detach().cpu().numpy() if isinstance(state, torch.Tensor) else state\n",
        "    #     self.actions[self.ptr] = action.detach().cpu().numpy() if isinstance(action, torch.Tensor) else action\n",
        "    #     self.rewards[self.ptr] = reward.detach().cpu().numpy() if isinstance(reward, torch.Tensor) else reward\n",
        "    #     self.dones[self.ptr] = done.detach().cpu().numpy() if isinstance(done, torch.Tensor) else done\n",
        "    #     self.log_probs[self.ptr] = log_prob.detach().cpu().numpy() if isinstance(log_prob, torch.Tensor) else log_prob\n",
        "    #     self.values[self.ptr] = value.detach().cpu().numpy() if isinstance(value, torch.Tensor) else value\n",
        "\n",
        "    #     self.ptr += 1\n",
        "\n",
        "    # # def compute_returns_and_advantage(self, last_value, gamma, lambda_gae):\n",
        "    # #     # Computing returns and advantages using GAE\n",
        "    # #     last_advantage = 0\n",
        "    # #     for i in reversed(range(self.buffer_size)):\n",
        "    # #         if i == self.buffer_size - 1:\n",
        "    # #             next_non_terminal = 1.0 - self.dones[i]\n",
        "    # #             next_value = last_value\n",
        "    # #         else:\n",
        "    # #             next_non_terminal = 1.0 - self.dones[i + 1]\n",
        "    # #             next_value = self.values[i + 1]\n",
        "\n",
        "    # #         delta = self.rewards[i] + gamma * next_value * next_non_terminal - self.values[i]\n",
        "    # #         last_advantage = delta + gamma * lambda_gae * next_non_terminal * last_advantage\n",
        "    # #         self.returns[i] = last_advantage + self.values[i]\n",
        "    # #         self.advantages[i] = last_advantage\n",
        "\n",
        "    # #     # Normalize the advantages\n",
        "    # #     self.advantages = (self.advantages - self.advantages.mean()) / (self.advantages.std() + 1e-8)\n",
        "    # def compute_returns_and_advantage(self, last_value, gamma, lambda_gae):\n",
        "    #     # Start modifications here\n",
        "    #     last_advantage = 0\n",
        "    #     # Loop through the buffer backwards, but only up to self.ptr\n",
        "    #     for i in reversed(range(self.ptr)):\n",
        "    #         if i == self.ptr - 1:\n",
        "    #             next_non_terminal = 1.0 - self.dones[i]\n",
        "    #             next_value = last_value\n",
        "    #         else:\n",
        "    #             next_non_terminal = 1.0 - self.dones[i + 1]\n",
        "    #             next_value = self.values[i + 1]\n",
        "\n",
        "    #         delta = self.rewards[i] + gamma * next_value * next_non_terminal - self.values[i]\n",
        "    #         last_advantage = delta + gamma * lambda_gae * next_non_terminal * last_advantage\n",
        "    #         self.returns[i] = last_advantage + self.values[i]\n",
        "    #         self.advantages[i] = last_advantage\n",
        "\n",
        "    #     # Normalize the advantages, but only for the filled part of the buffer\n",
        "    #     advantages_slice = self.advantages[:self.ptr]\n",
        "    #     advantages_mean = advantages_slice.mean()\n",
        "    #     advantages_std = advantages_slice.std() + 1e-8\n",
        "    #     self.advantages[:self.ptr] = (advantages_slice - advantages_mean) / advantages_std\n",
        "    # # def get_mini_batches(self, mini_batch_size):\n",
        "    # #     # Generating mini-batches for PPO updates\n",
        "    # #     batch_start = torch.randperm(self.ptr)\n",
        "    # #     for start in range(0, self.ptr, mini_batch_size):\n",
        "    # #         batch_indices = batch_start[start:start+mini_batch_size]\n",
        "    # #         yield {\n",
        "    # #             'states': self.states[batch_indices],\n",
        "    # #             'actions': self.actions[batch_indices],\n",
        "    # #             'rewards': self.rewards[batch_indices],\n",
        "    # #             'dones': self.dones[batch_indices],\n",
        "    # #             'log_probs': self.log_probs[batch_indices],\n",
        "    # #             'values': self.values[batch_indices],\n",
        "    # #             'returns': self.returns[batch_indices],\n",
        "    # #             'advantages': self.advantages[batch_indices],\n",
        "    # #         }\n",
        "    # def get_sequential_mini_batches(self, mini_batch_size):\n",
        "    #     # Sequentially generate mini-batches\n",
        "    #     for start in range(0, self.ptr, mini_batch_size):\n",
        "    #         end = start + mini_batch_size\n",
        "    #         yield self._create_batch(slice(start, end))\n",
        "\n",
        "    # def get_random_mini_batches(self, mini_batch_size):\n",
        "    #     # Randomly generate mini-batches\n",
        "    #     batch_indices = np.random.permutation(self.ptr)\n",
        "    #     for start in range(0, self.ptr, mini_batch_size):\n",
        "    #         end = start + mini_batch_size\n",
        "    #         selected_indices = batch_indices[start:end]\n",
        "    #         yield self._create_batch(selected_indices)\n",
        "\n",
        "    # def _create_batch(self, indices):\n",
        "    #     # Helper method to create a batch from indices\n",
        "    #     if isinstance(indices, slice):\n",
        "    #         batch_indices = range(indices.start or 0, min(indices.stop, self.ptr), indices.step or 1)\n",
        "    #     else:\n",
        "    #         batch_indices = indices\n",
        "    #     return {\n",
        "    #         'states': torch.tensor(self.states[batch_indices], dtype=torch.float32),\n",
        "    #         'actions': torch.tensor(self.actions[batch_indices], dtype=torch.float32),\n",
        "    #         'rewards': torch.tensor(self.rewards[batch_indices], dtype=torch.float32),\n",
        "    #         'dones': torch.tensor(self.dones[batch_indices], dtype=torch.bool),\n",
        "    #         'log_probs': torch.tensor(self.log_probs[batch_indices], dtype=torch.float32),\n",
        "    #         'values': torch.tensor(self.values[batch_indices], dtype=torch.float32),\n",
        "    #         'returns': torch.tensor(self.returns[batch_indices], dtype=torch.float32),\n",
        "    #         'advantages': torch.tensor(self.advantages[batch_indices], dtype=torch.float32),\n",
        "    #     }\n",
        "    # # def get_mini_batches(self, mini_batch_size):\n",
        "    # #     # Generating mini-batches with numpy arrays converted to PyTorch tensors\n",
        "    # #     batch_start = np.random.permutation(self.ptr)\n",
        "    # #     for start in range(0, self.ptr, mini_batch_size):\n",
        "    # #         batch_indices = batch_start[start:start+mini_batch_size]\n",
        "    # #         yield {\n",
        "    # #             'states': torch.tensor(self.states[batch_indices], device=self.device),\n",
        "    # #             'actions': torch.tensor(self.actions[batch_indices], device=self.device),\n",
        "    # #             'rewards': torch.tensor(self.rewards[batch_indices], device=self.device),\n",
        "    # #             'dones': torch.tensor(self.dones[batch_indices], dtype=torch.bool, device=self.device),\n",
        "    # #             'log_probs': torch.tensor(self.log_probs[batch_indices], device=self.device),\n",
        "    # #             'values': torch.tensor(self.values[batch_indices], device=self.device),\n",
        "    # #             'returns': torch.tensor(self.returns[batch_indices], device=self.device),\n",
        "    # #             'advantages': torch.tensor(self.advantages[batch_indices], device=self.device),\n",
        "    # #         }\n",
        "\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         logging.info(f'Starting Epoch: {epoch + 1}/{num_epochs}')\n",
        "\n",
        "#         # Initialize metrics\n",
        "#         episode_rewards = []\n",
        "#         episode_lengths = []\n",
        "#         all_drawdowns = []\n",
        "#         all_sharpe_ratios = []\n",
        "\n",
        "#         # Start training\n",
        "#         state = env.reset()\n",
        "#         episode_reward = 0\n",
        "#         timestep = 0\n",
        "#         progress_bar = tqdm(total=hyperparams['total_timesteps'])\n",
        "\n",
        "#         while timestep < hyperparams['total_timesteps']:\n",
        "#             # Sample an action from the policy network\n",
        "#             action, log_prob, value = actor_critic.act(state)\n",
        "#             action = action.cpu().numpy()  # Ensure action is a numpy array to be passed to env.step()\n",
        "\n",
        "#             # Step through the environment using the sampled action\n",
        "#             next_state, reward, done, _ = env.step(action)\n",
        "#             rollouts.add(state, action, reward, log_prob, value, done)\n",
        "\n",
        "#             episode_reward += reward\n",
        "#             state = next_state\n",
        "#             timestep += 1\n",
        "#             progress_bar.update(1)\n",
        "\n",
        "#             if done:\n",
        "#                 episode_rewards.append(episode_reward)\n",
        "#                 episode_lengths.append(timestep)  # Assuming timestep tracks the current step per episode\n",
        "\n",
        "#                 # Log episode details and calculate performance metrics\n",
        "#                 drawdown = calculate_drawdown(episode_rewards)\n",
        "#                 sharpe_ratio = calculate_sharpe_ratio(episode_rewards)\n",
        "#                 all_drawdowns.append(drawdown)\n",
        "#                 all_sharpe_ratios.append(sharpe_ratio)\n",
        "\n",
        "#                 logging.info(f'Episode finished. Reward: {episode_reward:.2f}, Length: {timestep}')\n",
        "#                 logging.info(f'Episode drawdown: {drawdown:.4f}, Sharpe Ratio: {sharpe_ratio:.4f}')\n",
        "\n",
        "#                 episode_reward = 0\n",
        "#                 state = env.reset()\n",
        "\n",
        "#         # Perform update if enough data is collected\n",
        "#             if done or len(rollouts.states) >= hyperparams['mini_batch_size'] * hyperparams['ppo_epoch']:\n",
        "#                 last_value = actor_critic.critic_forward(state)\n",
        "#                 rollouts.compute_returns_and_advantage(last_value, hyperparams['gamma'], hyperparams['gae_lambda'])\n",
        "#                 avg_actor_loss, avg_critic_loss, avg_entropy_loss = ppo.update(rollouts)\n",
        "#                 rollouts.reset()\n",
        "\n",
        "#                 logging.info(f'Update at timestep {timestep}, Actor Loss: {avg_actor_loss:.4f}, Critic Loss: {avg_critic_loss:.4f}, Entropy: {avg_entropy_loss:.4f}')\n",
        "\n",
        "#                 if done:\n",
        "#                     # Get the next starting point based on elapsed time\n",
        "#                     next_index = env.find_next_tick_index(tick_data, current_index, elapsed_time)\n",
        "#                     state = tick_data[next_index]['state']\n",
        "#                     timestep = next_index\n",
        "\n",
        "#             # Save and evaluate periodically\n",
        "#             if timestep % hyperparams['checkpoint_interval'] == 0:\n",
        "#                 checkpoint_path = f'ppo_checkpoint_{timestep}.pth'\n",
        "#                 torch.save(actor_critic.state_dict(), checkpoint_path)\n",
        "#                 logging.info(f'Model checkpoint saved at timestep {timestep}')\n",
        "\n",
        "#             if timestep % hyperparams['evaluation_interval'] == 0:\n",
        "#                 avg_reward = evaluate(actor_critic, env, hyperparams['num_evaluation_episodes'])\n",
        "#                 logging.info(f'Evaluation at timestep {timestep}, Average Reward: {avg_reward:.2f}')\n",
        "#                 progress_bar.set_postfix(avg_reward=avg_reward)\n",
        "\n",
        "#         progress_bar.close()\n",
        "#         logging.info(f'Training completed after {timestep} timesteps')\n",
        "#         logging.info(f'Average reward: {np.mean(episode_rewards):.2f} +/- {np.std(episode_rewards):.2f}')\n",
        "#         logging.info(f'Average episode length: {np.mean(episode_lengths)}')\n",
        "#         logging.info(f'Max drawdown during training: {min(all_drawdowns):.4f}')\n",
        "#         logging.info(f'Average Sharpe Ratio: {mstats.gmean(all_sharpe_ratios):.4f}')\n",
        "\n",
        "\n",
        "# def evaluate(actor_critic_network, env, num_episodes, deterministic=False):\n",
        "#     total_rewards = 0\n",
        "#     for episode in range(num_episodes):\n",
        "#         state = env.reset()\n",
        "#         done = False\n",
        "#         episode_reward = 0\n",
        "#         while not done:\n",
        "#             # Get the action from the network\n",
        "#             if deterministic:\n",
        "#                 # Assuming the network has a method to get the deterministic action\n",
        "#                 action, _ = actor_critic_network.get_deterministic_action(state)\n",
        "#             else:\n",
        "#                 # Or get the stochastic action if deterministic is False\n",
        "#                 action, _ = actor_critic_network.act(state)\n",
        "\n",
        "#             action = action.cpu().numpy()  # Convert to numpy array if necessary\n",
        "#             state, reward, done, _ = env.step(action)\n",
        "#             episode_reward += reward\n",
        "\n",
        "#         total_rewards += episode_reward\n",
        "#         logging.info(f'Episode: {episode}, Reward: {episode_reward}')\n",
        "\n",
        "#     average_reward = total_rewards / num_episodes\n",
        "#     logging.info(f'Average reward: {average_reward}')\n",
        "#     return average_reward\n",
        "\n",
        "\n",
        "\n",
        "class ContinuousTradingEnvironment(gym.Env):\n",
        "    \"\"\"\n",
        "    A continuous market making environment for reinforcement learning using tick data.\n",
        "\n",
        "    Attributes:\n",
        "        action_space: The space of possible actions. This is continuous and could represent\n",
        "                      the size and price of the orders you want to place or cancel.\n",
        "        observation_space: The space of possible states, which could include features derived from\n",
        "                           tick data such as smoothed prices, inventory levels, recent trade volumes, etc.\n",
        "        current_step: Current step in the simulation.\n",
        "        done: Indicator for when the environment should be reset.\n",
        "        state: The current state of the environment.\n",
        "        tick_data: The tick data for the trading environment.\n",
        "        inventory_level: The current level of inventory held.\n",
        "        cash_balance: The current cash balance from trading activities.\n",
        "    \"\"\"\n",
        "    def __init__(self, volatility, portfolio_manager, capital, trading_manager ):\n",
        "        super(ContinuousTradingEnvironment, self).__init__()\n",
        "\n",
        "        # Define the range for bid and ask price adjustments relative to some reference (e.g., mid-price)\n",
        "        self.bid_price_adjustment_range = [-0.0006, 0.0001]  # +/- 1% for bid price adjustment\n",
        "        self.ask_price_adjustment_range = [-0.0001, 0.0006]  # +/- 1% for ask price adjustment\n",
        "\n",
        "        # Define the range for the size of buy and sell orders\n",
        "        self.buy_order_size_range = [-0.001, 0.05]  # 1% to 10% for buy orders\n",
        "        self.sell_order_size_range = [-0.001, 0.05]  # 1% to 10% for sell orders\n",
        "\n",
        "        # Define the range for order cancellation intensity and strategy\n",
        "        self.cancellation_intensity_range = [0, 1]  # Range for how many orders to cancel\n",
        "        self.cancellation_strategy_range = [0, 1]  # Range for what type of orders to cancel\n",
        "\n",
        "        # Define the range for the hold action (0: not holding, 1: holding)\n",
        "        self.hold_range = [0, 1]\n",
        "\n",
        "        # Define the range for the target inventory level\n",
        "        self.target_inventory_level_range = [-0.35, 0.35]  # -50% to +50% of some reference value\n",
        "\n",
        "        # Define the continuous action space boundaries\n",
        "        self.action_space = gym.spaces.Box(\n",
        "            low=np.array([\n",
        "                self.bid_price_adjustment_range[0],\n",
        "                self.ask_price_adjustment_range[0],\n",
        "                self.buy_order_size_range[0],\n",
        "                self.sell_order_size_range[0],\n",
        "                self.hold_range[0],\n",
        "                self.target_inventory_level_range[0],\n",
        "                self.cancellation_intensity_range[0],\n",
        "                self.cancellation_strategy_range[0],\n",
        "            ]),\n",
        "            high=np.array([\n",
        "                self.bid_price_adjustment_range[1],\n",
        "                self.ask_price_adjustment_range[1],\n",
        "                self.buy_order_size_range[1],\n",
        "                self.sell_order_size_range[1],\n",
        "                self.hold_range[1],\n",
        "                self.target_inventory_level_range[1],\n",
        "                self.cancellation_intensity_range[1],\n",
        "                self.cancellation_strategy_range[1],\n",
        "            ]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "    # Other initialization steps...\n",
        "\n",
        "\n",
        "        # Define observation space\n",
        "        # Adjust the shape based on the number of features in your state representation\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf,\n",
        "            high=np.inf,\n",
        "            shape=(66,),  # Example size, should match your state representation\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        #self.split_order_threshold = 0.5  # Example threshold value\n",
        "        self.initial_capital = capital\n",
        "        # Initialize environment state\n",
        "        # self.tick_data = tick_data\n",
        "        self.one_hour_window = timedelta(hours=1)  # 1-hour window for data\n",
        "        self.price_ticks = deque(maxlen=35)  # Store (timestamp, price) tuples\n",
        "        self.tick_window = deque(maxlen=35)  # Additional window for tick data processing\n",
        "        self.last_ingestion_timestamp = None\n",
        "        self.last_exchange_timestamp = None\n",
        "        # self.latency_data = latency_data\n",
        "        #self.current_step = 0\n",
        "        self.done = False\n",
        "        self.inventory_level = 0\n",
        "        self.cash_balance = self.initial_capital\n",
        "        self.RELATIVE_ORDER_SIZE_THRESHOLD = 0.00005  # 0.005% of total balance\n",
        "\n",
        "        self.own_trades = []  # A list to keep track of the agent's trades\n",
        "        self.time_discount_factor = 0.99  # Example value for time discounting\n",
        "        self.trade_cost = 0.01  # Example fixed cost per trade, could also be a percentage\n",
        "        self.spread_cost = 0.01  # Spread cost as a percentage of the trade price\n",
        "        self.commission_rate = 0.002  # Commission rate per trade\n",
        "        # Initialize other attributes such as rate limiter\n",
        "        # max_num_orders, max_ratecount, ratecount_decay, decay_interval\n",
        "        self.rate_limiter = RateLimiter(max_num_orders=70, max_ratecount=55, ratecount_decay=-3.75, decay_interval=1) #the real mximum orders is 225 and the max ratecount is 180\n",
        "        self.optimal_time_window = 252  # Example for a one-year window in trading days\n",
        "        self.max_allowed_drawdown = 0.003  # .3% drawdown\n",
        "        #self.volatility_window = 30  # Example for a one-month window in trading days\n",
        "        #self.portfolio_values = []  # To keep track of portfolio values for drawdown calculation\n",
        "        #self.liquidity_reward_scaling_factor = 1.0  # Adjust as necessary\n",
        "        self.inventory = 0  # Current inventory level\n",
        "        self.inventory_target = 0  # Desired inventory level, which can be adaptive\n",
        "        self.max_inventory_risk = 0.3  # Maximum inventory risk tolerance (example: 10% of capital)\n",
        "        #self.volatility_window = 30  # Window for volatility calculation\n",
        "        #self.latency_manager = LatencyManager()\n",
        "        # self.model_computation_time_tracker = ModelComputationTimeTracker()\n",
        "        self.volatility_manager = volatility\n",
        "        self.portfolio_manager = portfolio_manager\n",
        "        self.order_manager = OrderManager(self.portfolio_manager)\n",
        "\n",
        "        self.orderbook = OrderBookManager()\n",
        "        self.trade_update_manager = trading_manager\n",
        "        self.market_data_transformation = MarketStateCalculator(self.rate_limiter, self.volatility_manager, self.order_manager, self.initial_capital)\n",
        "\n",
        "        self.reward_manager = Reward(self.volatility_manager, self.cash_balance, self.max_inventory_risk, self.order_manager, self.market_data_transformation, self.rate_limiter)\n",
        "\n",
        "\n",
        "        self.last_exchange_timestamp = None\n",
        "        self.last_ingestion_timestamp = None\n",
        "        self.last_order_execution_timestamp = None\n",
        "        self.model_calculation_time = None\n",
        "        '''\n",
        "         self.best_bid_price = None\n",
        "        self.best_ask_price = None\n",
        "        self.book_depth = None\n",
        "        self.bid_ask_spread = None\n",
        "        self.volume_imbalance = None\n",
        "        self.order_flow = None\n",
        "        self.last_traded_price = None\n",
        "        self.last_trade_volume = None\n",
        "        self.rolling_trade_volume = None\n",
        "        self.time_since_last_trade = None\n",
        "        self.volatility = None\n",
        "        self.inventory_level = None\n",
        "        self.unrealized_pnl = None\n",
        "        self.accumulated_profit_loss = None\n",
        "        self.time_since_last_action = None\n",
        "        self.historical_actions = None\n",
        "        self.api_call_count = None\n",
        "        self.rate_limit_window_reset_time = None\n",
        "        self.var = None\n",
        "        self.liquidity = None\n",
        "\n",
        "        '''\n",
        "\n",
        "        # Reset the environment to start\n",
        "        # self.reset()\n",
        "\n",
        "\n",
        "    # def reset(self):\n",
        "    #     \"\"\"\n",
        "    #     Reset the environment to an initial state.\n",
        "    #     \"\"\"\n",
        "    #     self.current_step = 0\n",
        "    #     self.done = False\n",
        "    #     self.inventory_level = 0\n",
        "    #     self.cash_balance = 0\n",
        "    #     self.state = self._get_initial_state()\n",
        "    #     return self.state\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the environment to an initial state\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "\n",
        "        self.inventory = 0\n",
        "        self.cash_balance = self.initial_capital\n",
        "        self.pending_actions.clear()\n",
        "        self.current_time = 0\n",
        "        self.order_book_window.clear()\n",
        "        self.state = self._get_initial_state()\n",
        "        return self.state\n",
        "\n",
        "    # def _ingest_data(self, data):\n",
        "    #     # Record the current time as ingestion timestamp\n",
        "    #     self.last_ingestion_timestamp = time.time()\n",
        "\n",
        "    #     # Record the exchange timestamp from the data\n",
        "    #     self.last_exchange_timestamp = data['exchange_timestamp']\n",
        "\n",
        "    # def _get_initial_state(self):\n",
        "    #     \"\"\"\n",
        "    #     Returns an initial state for the environment.\n",
        "    #     \"\"\"\n",
        "    #     # Initialize state, e.g., using the first few ticks or a fixed starting point\n",
        "    #     self.latency_feature = self._calculate_latency_feature(self.current_step)\n",
        "\n",
        "    #     return np.zeros(self.observation_space.shape)\n",
        "\n",
        "\n",
        "    # def check_if_done_post_penalty(self):\n",
        "    #     \"\"\"\n",
        "    #     Check if the environment should terminate after applying a rate limit penalty.\n",
        "    #     \"\"\"\n",
        "    #     # Example condition: if cash balance falls below a threshold\n",
        "    #     if self.cash_balance < self.minimum_cash_threshold:\n",
        "    #         return True  # Terminate the episode\n",
        "    #     # Add any additional terminal checks here as needed\n",
        "    #     return False  # Continue the episode\n",
        "\n",
        "    def calculate_order_size(self, market_depth, trade_imbalance, recent_trade_volume, current_price, target_inventory_level, order_size_adjustment):\n",
        "        # Calculate the inventory gap based on the target inventory level\n",
        "        inventory_gap = (self.max_inventory_capacity * target_inventory_level) - self.current_inventory\n",
        "\n",
        "        # Maximum order size based on a percentage of capital\n",
        "        max_order_size_as_percentage_of_capital = 0.05 * self.initial_capital / current_price\n",
        "\n",
        "        # Target order size considering inventory gap and capital constraints\n",
        "        target_order_size = min(abs(inventory_gap), max_order_size_as_percentage_of_capital)\n",
        "\n",
        "        # Minimum order size based on the current price\n",
        "        min_order_size = 0.0001 * current_price\n",
        "        target_order_size = max(target_order_size, min_order_size)\n",
        "\n",
        "        # Adjust the order size based on the action's size adjustment\n",
        "        adjustment_scale = (order_size_adjustment + 1) / 2  # Normalize from [-1, 1] to [0, 1]\n",
        "        adjusted_order_size = min_order_size + (max_order_size_as_percentage_of_capital - min_order_size) * adjustment_scale\n",
        "\n",
        "        # Final order size is the lesser of the risk-adjusted size and the adjusted size\n",
        "        final_order_size = min(adjusted_order_size, target_order_size)\n",
        "\n",
        "        # Determine the direction of the order: buy, sell, or hold\n",
        "        order_direction = 1 if inventory_gap > 0 else -1 if inventory_gap < 0 else 0\n",
        "\n",
        "        # Implement the hold logic: if direction is hold, set the order size to zero\n",
        "        if order_direction == 0:\n",
        "            final_order_size = 0\n",
        "\n",
        "        # Apply the direction to the final order size\n",
        "        final_order_size *= order_direction\n",
        "\n",
        "    #     return final_order_size\n",
        "\n",
        "\n",
        "\n",
        "    def process_cancellation(self, model, intensity, strategy, current_simulation_time):\n",
        "        # Access active orders from OrderManager\n",
        "        active_orders = model.environment.order_manager.active_orders\n",
        "\n",
        "        # Determine the number of orders to cancel\n",
        "        num_orders_to_cancel = int(intensity * len(active_orders))\n",
        "\n",
        "        # Advanced order selection based on strategy\n",
        "        orders_to_cancel = self.select_orders_for_cancellation( strategy, num_orders_to_cancel, active_orders)\n",
        "\n",
        "        # Cancel the selected orders\n",
        "        for order in orders_to_cancel:\n",
        "            self.cancel_order(model, order, current_simulation_time)\n",
        "            # Update the rate limiter for each canceled order\n",
        "            order_age = current_simulation_time - order.time_placed\n",
        "            model.environment.rate_limiter.can_cancel_order(order_age, current_simulation_time)\n",
        "\n",
        "# Other methods remain the same\n",
        "\n",
        "\n",
        "    def select_orders_for_cancellation(self, strategy, num_orders_to_cancel, active_orders):\n",
        "        if strategy <= 0.80:\n",
        "            print(\"Executing cancellation logic: Selecting least profitable orders\")\n",
        "            return self.select_least_profitable_orders(num_orders_to_cancel, active_orders)\n",
        "        else:\n",
        "            print(\"Executing cancellation logic: Selecting orders furthest from market\")\n",
        "            return self.select_orders_furthest_from_market(num_orders_to_cancel, active_orders)\n",
        "        # else:\n",
        "            #return self.select_mix_of_old_and_new_orders( num_orders_to_cancel, active_orders, current_time)\n",
        "\n",
        "    # Implement the remaining selection methods similarly, using 'active_orders' parameter\n",
        "\n",
        "    def cancel_order(self, model, order, current_simulation_time):\n",
        "        # Logic to cancel the order in the model's LOB instance and OrderManager\n",
        "        model.lob_instance.remove_order(order.order_id)\n",
        "        model.environment.order_manager.cancel_order(order.order_id, current_simulation_time)\n",
        "\n",
        "    def select_least_profitable_orders(self, num_orders_to_cancel, active_orders):\n",
        "        if len(active_orders) <= 2:\n",
        "            print(\"Not enough orders to cancel while maintaining at least one order per side.\")\n",
        "            return []\n",
        "\n",
        "        # Split orders by side\n",
        "        buy_orders = [order for order in active_orders if order.side == 'buy']\n",
        "        sell_orders = [order for order in active_orders if order.side == 'sell']\n",
        "\n",
        "        # Ensure not to cancel all orders of one side\n",
        "        if len(buy_orders) == 1 or len(sell_orders) == 1:\n",
        "            num_orders_to_cancel = min(num_orders_to_cancel, len(active_orders) - 2)\n",
        "\n",
        "        current_market_price = self.market_data_transformation.cached_mid_price\n",
        "        orders_with_profitability = [(order, (current_market_price - order.price) * order.size) for order in active_orders]\n",
        "        orders_sorted_by_profitability = sorted(orders_with_profitability, key=lambda x: x[1])\n",
        "        least_profitable_orders = [order for order, _ in orders_sorted_by_profitability[:num_orders_to_cancel]]\n",
        "\n",
        "        return least_profitable_orders\n",
        "\n",
        "    def select_orders_furthest_from_market(self, num_orders_to_cancel, active_orders):\n",
        "        if len(active_orders) <= 2:\n",
        "            print(\"Not enough orders to cancel while maintaining at least one order per side.\")\n",
        "            return []\n",
        "\n",
        "        # Split orders by side\n",
        "        buy_orders = [order for order in active_orders if order.is_buy == 'buy']\n",
        "        sell_orders = [order for order in active_orders if order.is_buy == 'sell']\n",
        "\n",
        "        # Ensure not to cancel all orders of one side\n",
        "        if len(buy_orders) == 1 or len(sell_orders) == 1:\n",
        "            num_orders_to_cancel = min(num_orders_to_cancel, len(active_orders) - 2)\n",
        "\n",
        "        current_mid_price = self.market_data_transformation.cached_mid_price\n",
        "        orders_with_distance = [(order, abs(order.price - current_mid_price)) for order in active_orders]\n",
        "        orders_sorted_by_distance = sorted(orders_with_distance, key=lambda x: x[1], reverse=True)\n",
        "        furthest_orders = [order for order, _ in orders_sorted_by_distance[:num_orders_to_cancel]]\n",
        "\n",
        "        return furthest_orders\n",
        "\n",
        "\n",
        "\n",
        "    def select_mix_of_old_and_new_orders(self, num_orders_to_cancel, active_orders):\n",
        "        old_orders = [order for order in active_orders if self.calculate_order_age(order) > 300]\n",
        "        # strategically_important_orders = self.identify_strategically_important_orders(old_orders)\n",
        "        return old_orders\n",
        "\n",
        "\n",
        "    # def calculate_order_age(self, order):\n",
        "    #     #current_time = datetime.utcnow()\n",
        "\n",
        "    #     print(f\"Debug: Current time: {current_time}, Order placed time: {order.time_placed}, Order age: {order_age} seconds\")\n",
        "\n",
        "    #     return (current_time - order.time_placed)\n",
        "\n",
        "    def calculate_recent_price_change(self):\n",
        "        if len(self.price_data) < 2:\n",
        "            return 0\n",
        "        return (self.price_data[-1] - self.price_data[-2]) / self.price_data[-2] * 100\n",
        "\n",
        "\n",
        "\n",
        "    def _calculate_pnl(self):\n",
        "        # Calculate the profit or loss since the last action\n",
        "        # Assuming we have a self.last_trade_price and self.current_trade_price\n",
        "        pnl = (self.current_trade_price - self.last_trade_price) * self.inventory_level\n",
        "        return pnl\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def render(self, mode='human', close=False):\n",
        "    #     \"\"\"\n",
        "    #     Render the environment for human viewing.\n",
        "\n",
        "    #     The rendering can be in different modes; if 'human', it prints the current state's\n",
        "    #     summary to the console. If 'system', it logs these details to a file. Additional\n",
        "    #     modes like 'graphical' can be added for more complex visualizations, such as using\n",
        "    #     matplotlib for plotting the portfolio value over time.\n",
        "    #     \"\"\"\n",
        "    #     if close:\n",
        "    #         # Close any existing renderings\n",
        "    #         plt.close() if self.fig else None\n",
        "    #         return\n",
        "\n",
        "    #     if mode == 'human':\n",
        "    #         # Print out a summary of the current state for human understanding\n",
        "    #         print(f\"Step: {self.current_step}\")\n",
        "    #         print(f\"Current Portfolio Value: {self.cash_balance + self.inventory_level * self.current_price}\")\n",
        "    #         print(f\"Current Inventory Level: {self.inventory_level}\")\n",
        "    #         print(f\"Current Cash Balance: {self.cash_balance}\")\n",
        "    #         # Optionally, add more detailed summaries such as recent trades, etc.\n",
        "\n",
        "    #     elif mode == 'system':\n",
        "    #         # For system mode, you could log these details to a file instead\n",
        "    #         with open('render_log.txt', 'a') as f:\n",
        "    #             f.write(f\"Step: {self.current_step}, Portfolio Value: {self.cash_balance + self.inventory_level * self.current_price}\\n\")\n",
        "\n",
        "    #     elif mode == 'graphical':\n",
        "    #         # For graphical mode, render the state using matplotlib or another plotting library\n",
        "    #         if not hasattr(self, 'fig') or self.fig is None:\n",
        "    #             self.fig, self.ax = plt.subplots(1, 1)\n",
        "    #             plt.ion()\n",
        "    #             plt.show()\n",
        "\n",
        "    #         # Update the plot for the current step\n",
        "    #         self.ax.clear()\n",
        "    #         self.ax.plot(self.portfolio_values, label='Portfolio Value')\n",
        "    #         self.ax.set_title(f\"Current Step: {self.current_step}\")\n",
        "    #         self.ax.set_xlabel('Step')\n",
        "    #         self.ax.set_ylabel('Portfolio Value')\n",
        "    #         self.ax.legend()\n",
        "    #         plt.draw()\n",
        "    #         plt.pause(1)  # Pause briefly to allow the plot to be updated\n",
        "\n",
        "\n",
        "class Order:\n",
        "    def __init__(self, order_id, size, price, placement_time, is_buy):\n",
        "        self.order_id = order_id\n",
        "        self.size = size\n",
        "        self.price = price\n",
        "        self.time_placed = placement_time\n",
        "        self.is_buy = is_buy\n",
        "        self.filled = 0\n",
        "        self.canceled = False  # Track if the order was canceled\n",
        "\n",
        "\n",
        "class OrderManager:\n",
        "    def __init__(self, portfolio_manager):\n",
        "        self.active_orders = []  # Track active orders\n",
        "        self.cancelled_orders = deque()  # Use deque for cancelled orders\n",
        "        self.cancellation_window = timedelta(minutes=6)  # 6-minute window for cancellations\n",
        "\n",
        "        self.target_inventory = 0  # Target inventory level to maintain\n",
        "\n",
        "        self.inventory = 0  # Track the current inventory level\n",
        "        self.average_buy_price = 0  # Average buy price of the inventory\n",
        "        self.average_sell_price = 0  # Average sell price of the inventory\n",
        "        self.realized_pnl = 0  # Realized PnL\n",
        "        self.unrealized_pnl = 0  # Unrealized PnL\n",
        "        self.maker_fee_percentage = 0.0016  # Maker fee of 0.16%\n",
        "        self.portfolio_manager = portfolio_manager\n",
        "\n",
        "    def update_target_inventory(self, target):\n",
        "        self.target_inventory = target\n",
        "\n",
        "    def get_target_inventory(self):\n",
        "        return self.target_inventory\n",
        "\n",
        "    def cancel_order(self, order_id, current_time_microseconds):\n",
        "            print(f\"Attempting to cancel order with order_id: {order_id}. Received current_time (UNIX timestamp in microseconds): {current_time_microseconds}\")\n",
        "\n",
        "            order = self.find_order_by_id(order_id)\n",
        "            if order:\n",
        "                order.canceled = True  # Mark the order as canceled\n",
        "                self.active_orders.remove(order)\n",
        "                # Record the cancellation with its timestamp (in microseconds)\n",
        "                self.cancelled_orders.append({'order_id': order_id, 'cancel_time': current_time_microseconds})\n",
        "\n",
        "            # Remove cancellations older than the cancellation window\n",
        "            # Convert self.cancellation_window to microseconds for comparison\n",
        "            cancellation_window_microseconds = self.cancellation_window.total_seconds() * 1e6\n",
        "            print(f'Cancel_order function cancellation_window:{cancellation_window_microseconds}')\n",
        "\n",
        "            while self.cancelled_orders and current_time_microseconds - self.cancelled_orders[0]['cancel_time'] > cancellation_window_microseconds:\n",
        "                self.cancelled_orders.popleft()\n",
        "\n",
        "\n",
        "    def calculate_recent_cancellations_weight(self, current_time_microseconds, decay_rate):\n",
        "        weight = 0\n",
        "        for cancellation in self.cancelled_orders:\n",
        "            time_since_cancellation_microseconds = current_time_microseconds - cancellation['cancel_time']\n",
        "            time_since_cancellation_seconds = time_since_cancellation_microseconds / 1e6\n",
        "            decayed_weight = np.exp(-decay_rate * time_since_cancellation_seconds)\n",
        "            weight += decayed_weight\n",
        "        return weight\n",
        "\n",
        "\n",
        "    def calculate_cancellation_penalty(self, order, recent_cancellations_weight):\n",
        "        cancellation_penalty_coefficient = 10  # Example coefficient, adjust as needed\n",
        "        # Apply a higher penalty for a higher weight of recent cancellations\n",
        "        penalty = cancellation_penalty_coefficient * recent_cancellations_weight\n",
        "        # Cap the penalty to avoid excessively high values\n",
        "\n",
        "        max_penalty = 50 # Example maximum penalty value\n",
        "        return min(penalty, max_penalty)\n",
        "\n",
        "    # def calculate_time_in_queue_reward(self ,order, current_time):\n",
        "    #     time_in_queue = current_time - order.placement_time\n",
        "    #     # Use a non-linear function for reward calculation (e.g., logarithmic)\n",
        "    #     time_in_queue_coefficient = 0.05  # Example coefficient, adjust as needed\n",
        "    #     reward = time_in_queue_coefficient * np.log(1 + time_in_queue)\n",
        "    #     # Cap the reward to avoid excessively high values\n",
        "    #     max_reward = 100  # Example maximum reward value\n",
        "    #     return min(reward, max_reward)\n",
        "\n",
        "\n",
        "    def calculate_time_in_queue_reward(self, order, current_time_microseconds):\n",
        "        print(f\"Debug: current_time (microseconds): {current_time_microseconds}, order.placement_time (microseconds): {order.placement_time}\")\n",
        "\n",
        "        time_in_queue_seconds = (current_time_microseconds - order.placement_time) / 1e6\n",
        "        print(f\"Debug: time_in_queue (in seconds): {time_in_queue_seconds}\")\n",
        "\n",
        "        time_in_queue_coefficient = 0.7\n",
        "        reward = time_in_queue_coefficient * np.log(1 + time_in_queue_seconds)\n",
        "        print(f\"Debug: Calculated reward before capping: {reward}\")\n",
        "\n",
        "        max_reward = 100\n",
        "        final_reward = min(reward, max_reward)\n",
        "        print(f\"Debug: Final reward after capping: {final_reward}\")\n",
        "        sys.exit()\n",
        "        return final_reward\n",
        "\n",
        "    def calculate_order_stability_reward(self, order, current_time, recent_cancellations_weight):\n",
        "        time_in_queue_reward = self.calculate_time_in_queue_reward(order, current_time)\n",
        "        cancellation_penalty = self.calculate_cancellation_penalty(order, recent_cancellations_weight)\n",
        "\n",
        "        total_reward = time_in_queue_reward - cancellation_penalty\n",
        "        return total_reward\n",
        "\n",
        "\n",
        "\n",
        "    def place_order(self, order_id, size, price, is_buy, time):\n",
        "\n",
        "        order = Order(order_id, size, price, time, is_buy)\n",
        "        self.active_orders.append(order)\n",
        "        return order\n",
        "\n",
        "    def remove_order(self, order_to_remove):\n",
        "        self.active_orders = [order for order in self.active_orders if order.order_id != order_to_remove.order_id]\n",
        "\n",
        "    #order_id, matched_volume, matched_price, is_buy\n",
        "\n",
        "    def process_order_execution(self, order_id, filled_size, current_market_price):\n",
        "        order = self.find_order_by_id(order_id)\n",
        "        if order:\n",
        "            previous_filled = order.filled\n",
        "            order.filled += filled_size\n",
        "            filled_this_execution = filled_size - previous_filled\n",
        "            self.update_inventory(order, filled_this_execution,current_market_price)\n",
        "            self.update_realized_pnl(order, filled_this_execution, current_market_price)\n",
        "            if order.filled == order.size:\n",
        "                self.active_orders.remove(order)\n",
        "            self.update_positions_and_pnl(current_market_price)\n",
        "\n",
        "    def update_realized_pnl(self, order, filled_size, current_market_price):\n",
        "        maker_fee = current_market_price * filled_size * self.maker_fee_percentage\n",
        "\n",
        "        if order.is_buy == 'buy':\n",
        "            # Buying to close a short position or adding to a long position.\n",
        "            if self.inventory < 0:\n",
        "                # Closing or reducing a short position.\n",
        "                pnl_change = (self.average_sell_price - current_market_price) * filled_size\n",
        "            else:\n",
        "                # Adding to a long position doesn't realize PnL.\n",
        "                # Realized PnL occurs when selling, so no PnL change here for buys that don't close shorts.\n",
        "                pnl_change = 0\n",
        "        else:\n",
        "            # Selling to open a short position or closing a long position.\n",
        "            if self.inventory > 0:\n",
        "                # Closing or reducing a long position.\n",
        "                pnl_change = (current_market_price - self.average_buy_price) * filled_size\n",
        "            else:\n",
        "                # Opening or adding to a short position.\n",
        "                # For simplicity, we'll not calculate PnL change here since it's realized when the position is closed.\n",
        "                # However, if you want to track unrealized PnL for short positions, additional logic would be needed.\n",
        "                pnl_change = 0\n",
        "\n",
        "        # Adjust the PnL change by subtracting the maker fee.\n",
        "        if pnl_change != 0:\n",
        "            pnl_change -= maker_fee\n",
        "\n",
        "        # Update the realized PnL.\n",
        "        self.realized_pnl = pnl_change\n",
        "        # Update the portfolio value based on the PnL change.\n",
        "        self.portfolio_manager.update_portfolio_value(pnl_change)\n",
        "\n",
        "    def update_inventory(self, order, filled_size, current_market_price):\n",
        "        # Calculate the cost of the filled portion of the order\n",
        "        cost = filled_size * current_market_price\n",
        "\n",
        "        if order.is_buy:\n",
        "            # If buying, increase inventory\n",
        "            new_inventory = self.inventory + filled_size\n",
        "            if self.inventory >= 0:\n",
        "                # If previously long or flat, adjust average buy price\n",
        "                total_cost = self.average_buy_price * self.inventory + cost\n",
        "                self.average_buy_price = total_cost / new_inventory if new_inventory != 0 else 0\n",
        "            else:\n",
        "                # If previously short, cover the short position\n",
        "                self.average_sell_price = (self.average_sell_price * -self.inventory - cost) / new_inventory if new_inventory != 0 else 0\n",
        "        else:\n",
        "            # If selling, decrease inventory\n",
        "            new_inventory = self.inventory - filled_size\n",
        "            if self.inventory <= 0:\n",
        "                # If previously short or flat, adjust average sell price\n",
        "                total_cost = self.average_sell_price * -self.inventory + cost\n",
        "                self.average_sell_price = total_cost / -new_inventory if new_inventory != 0 else 0\n",
        "            else:\n",
        "                # If previously long, reduce the long position\n",
        "                self.average_buy_price = (self.average_buy_price * self.inventory - cost) / new_inventory if new_inventory != 0 else 0\n",
        "\n",
        "        self.inventory = new_inventory\n",
        "\n",
        "\n",
        "    # def update_inventory(self, order, filled_size, current_market_price):\n",
        "    #     if order.is_buy:\n",
        "    #         total_buy_value = self.average_buy_price * max(self.inventory, 0) + current_market_price * filled_size\n",
        "    #         new_buy_inventory = max(self.inventory, 0) + filled_size\n",
        "    #         self.average_buy_price = total_buy_value / new_buy_inventory if new_buy_inventory else 0\n",
        "    #     else:\n",
        "    #         total_sell_value = self.average_sell_price * max(-self.inventory, 0) + current_market_price * filled_size\n",
        "    #         new_sell_inventory = max(-self.inventory, 0) + filled_size\n",
        "    #         self.average_sell_price = total_sell_value / new_sell_inventory if new_sell_inventory else 0\n",
        "\n",
        "    #     self.inventory += filled_size if order.is_buy else -filled_size\n",
        "    # def update_inventory(self, order, filled_size, current_market_price):\n",
        "    #     if order.is_buy:\n",
        "    #         if self.inventory >= 0:\n",
        "    #             # Buying to open or add to a long position\n",
        "    #             total_buy_value = self.average_buy_price * self.inventory + current_market_price * filled_size\n",
        "    #             self.inventory += filled_size\n",
        "    #             self.average_buy_price = total_buy_value / self.inventory if self.inventory > 0 else 0\n",
        "    #         else:\n",
        "    #             # Buying to cover a short position or flipping to long\n",
        "    #             if filled_size <= abs(self.inventory):\n",
        "    #                 # Partially covering a short position\n",
        "    #                 self.inventory += filled_size\n",
        "    #             else:\n",
        "    #                 # Flipping from short to long\n",
        "    #                 over_covered = filled_size - abs(self.inventory)\n",
        "    #                 self.inventory = over_covered\n",
        "    #                 self.average_buy_price = current_market_price  # New long position\n",
        "    #                 # Reset average sell price as we no longer have a short position\n",
        "    #                 self.average_sell_price = 0\n",
        "    #     else:\n",
        "    #         # Selling\n",
        "    #         if self.inventory > 0:\n",
        "    #             # Selling part of a long position or flipping to short\n",
        "    #             if filled_size <= self.inventory:\n",
        "    #                 self.inventory -= filled_size\n",
        "    #             else:\n",
        "    #                 # Flipping from long to short\n",
        "    #                 over_sold = filled_size - self.inventory\n",
        "    #                 self.inventory = -over_sold  # New short position\n",
        "    #                 self.average_sell_price = current_market_price  # New short position\n",
        "    #                 # Reset average buy price as we no longer have a long position\n",
        "    #                 self.average_buy_price = 0\n",
        "    #         else:\n",
        "    #             # Adding to a short position or opening a new short position\n",
        "    #             total_sell_value = self.average_sell_price * abs(self.inventory) + current_market_price * filled_size\n",
        "    #             self.inventory -= filled_size\n",
        "    #             self.average_sell_price = total_sell_value / abs(self.inventory) if self.inventory < 0 else 0\n",
        "\n",
        "        # No need to update positions and PnL here\n",
        "\n",
        "\n",
        "\n",
        "    def update_positions_and_pnl(self, current_market_price):\n",
        "        if self.inventory > 0:\n",
        "            self.unrealized_pnl = (current_market_price - self.average_buy_price) * self.inventory\n",
        "        elif self.inventory < 0:\n",
        "            self.unrealized_pnl = (self.average_sell_price - current_market_price) * (-self.inventory)\n",
        "        else:\n",
        "            self.unrealized_pnl = 0\n",
        "\n",
        "\n",
        "    def calculate_total_active_orders_value(self):\n",
        "        total_order_value = 0\n",
        "        for order in self.active_orders:\n",
        "            if not order.canceled:\n",
        "                order_value = order.price * order.size\n",
        "                total_order_value += order_value\n",
        "        return total_order_value\n",
        "\n",
        "    def calculate_combined_inventory_and_orders_value(self):\n",
        "        inventory_value = self.calculate_inventory_value()\n",
        "        active_orders_value = self.calculate_total_active_orders_value()\n",
        "        return inventory_value + active_orders_value\n",
        "\n",
        "    def calculate_inventory_value(self):\n",
        "        if self.inventory > 0:  # Long position\n",
        "            inventory_value = self.inventory * self.average_buy_price\n",
        "        elif self.inventory < 0:  # Short position\n",
        "            inventory_value = abs(self.inventory) * self.average_sell_price\n",
        "        else:  # No position\n",
        "            inventory_value = 0\n",
        "        return inventory_value\n",
        "\n",
        "    # def calculate_inventory_percentage(self, aum):\n",
        "    #     inventory_value = self.calculate_inventory_value()\n",
        "    #     if aum == 0:\n",
        "    #         return 0\n",
        "    #     return (inventory_value / aum) * 100\n",
        "\n",
        "\n",
        "\n",
        "    def find_order_by_id(self, order_id):\n",
        "        for order in self.active_orders:\n",
        "            if order.order_id == order_id:\n",
        "                return order\n",
        "        return None\n",
        "\n",
        "\n",
        "    def get_average_price(self):\n",
        "        # Assuming you're tracking average price in some way\n",
        "        return self.average_price\n",
        "\n",
        "    def get_realized_pnl(self):\n",
        "        return self.realized_pnl\n",
        "\n",
        "    def get_average_buy_price(self):\n",
        "        return self.average_buy_price\n",
        "\n",
        "    def get_average_sell_price(self):\n",
        "        return self.average_sell_price\n",
        "\n",
        "    def get_best_and_worst_bid_with_total_volume(self):\n",
        "        \"\"\"\n",
        "        Get the highest and lowest bid prices among active orders, along with the total volume of the highest bid.\n",
        "        \"\"\"\n",
        "        bid_orders = [(order.price, order.size) for order in self.active_orders if order.is_buy and not order.canceled]\n",
        "        if not bid_orders:\n",
        "            return (None, None, None)  # No bids\n",
        "\n",
        "        # Aggregate volumes by price\n",
        "        bid_volumes_by_price = {}\n",
        "        for price, volume in bid_orders:\n",
        "            bid_volumes_by_price[price] = bid_volumes_by_price.get(price, 0) + volume\n",
        "\n",
        "        if bid_volumes_by_price:\n",
        "            best_bid_price = max(bid_volumes_by_price.keys())\n",
        "            worst_bid_price = min(bid_volumes_by_price.keys())\n",
        "            best_bid_volume = bid_volumes_by_price[best_bid_price]\n",
        "        else:\n",
        "            return (None, None, None)\n",
        "\n",
        "        return best_bid_price, worst_bid_price, best_bid_volume\n",
        "\n",
        "\n",
        "    def get_best_and_worst_ask_with_total_volume(self):\n",
        "        \"\"\"\n",
        "        Get the lowest and highest ask prices among active orders, along with the total volume of the lowest ask.\n",
        "        \"\"\"\n",
        "        ask_orders = [(order.price, order.size) for order in self.active_orders if not order.is_buy and not order.canceled]\n",
        "        if not ask_orders:\n",
        "            return (None, None, None)  # No asks\n",
        "\n",
        "        # Aggregate volumes by price\n",
        "        ask_volumes_by_price = {}\n",
        "        for price, volume in ask_orders:\n",
        "            ask_volumes_by_price[price] = ask_volumes_by_price.get(price, 0) + volume\n",
        "\n",
        "        if ask_volumes_by_price:\n",
        "            best_ask_price = min(ask_volumes_by_price.keys())\n",
        "            worst_ask_price = max(ask_volumes_by_price.keys())\n",
        "            best_ask_volume = ask_volumes_by_price[best_ask_price]\n",
        "        else:\n",
        "            return (None, None, None)\n",
        "\n",
        "        return best_ask_price, worst_ask_price, best_ask_volume\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ... Additional methods as needed ...\n",
        "\n",
        "    # ... Additional methods as needed ...\n",
        "\n",
        "\n",
        "class PortfolioManager:\n",
        "    def __init__(self, initial_capital):\n",
        "        self.initial_capital = initial_capital\n",
        "        self.portfolio_values = deque()  # Store (timestamp, portfolio value) tuples\n",
        "        self.realized_pnl = 0\n",
        "        self.current_capital = initial_capital\n",
        "        self.time_window = timedelta(minutes=30)\n",
        "\n",
        "    def update_portfolio_value(self, pnl_change):\n",
        "        \"\"\"\n",
        "        Update the portfolio value with the realized PnL change.\n",
        "        \"\"\"\n",
        "        current_time = datetime.now()\n",
        "        self.realized_pnl += pnl_change\n",
        "        self.current_capital += pnl_change\n",
        "        new_portfolio_value = self.get_latest_portfolio_value() + pnl_change\n",
        "        self.portfolio_values.append((current_time, new_portfolio_value))\n",
        "\n",
        "        # Remove old data outside the specified time window\n",
        "        while self.portfolio_values and self.portfolio_values[0][0] < current_time - self.time_window:\n",
        "            self.portfolio_values.popleft()\n",
        "\n",
        "    def get_latest_portfolio_value(self):\n",
        "        \"\"\"\n",
        "        Get the most recent portfolio value.\n",
        "        \"\"\"\n",
        "        return self.portfolio_values[-1][1] if self.portfolio_values else self.initial_capital\n",
        "\n",
        "    def get_realized_pnl(self):\n",
        "        \"\"\"\n",
        "        Get the total realized PnL.\n",
        "        \"\"\"\n",
        "        return self.realized_pnl\n",
        "    def get_AUM(self):\n",
        "        \"\"\"\n",
        "        Calculate and return the current AUM.\n",
        "        \"\"\"\n",
        "        # Implement the logic to calculate AUM\n",
        "        # For simplicity, let's assume AUM is equal to current capital in this example\n",
        "        return self.current_capital\n",
        "\n",
        "class VolatilityManager:\n",
        "    def __init__(self, one_hour_window=timedelta(hours=1),one_minute_window=timedelta(minutes=1), seven_minute_window=timedelta(minutes=7),thirty_five_minute_window=timedelta(minutes=35)):\n",
        "        self.price_ticks = deque()  # Store (timestamp, price) tuples\n",
        "        self.one_hour_window = one_hour_window  # Time window for price ticks\n",
        "        self.mad_window_sizes = [timedelta(minutes=1), timedelta(minutes=7), timedelta(minutes=60)]\n",
        "        self.mad_volatilities = {}  # Store the latest MAD volatility measures\n",
        "\n",
        "\n",
        "        # New functionality for DEMA\n",
        "        self.one_minute_window = one_minute_window\n",
        "        self.seven_minute_window = seven_minute_window\n",
        "        self.thirty_five_minute_window = thirty_five_minute_window\n",
        "        self.one_minute_trades = deque()\n",
        "        self.seven_minute_trades = deque()\n",
        "        self.thirty_five_minute_trades = deque()\n",
        "\n",
        "\n",
        "\n",
        "    def update_tick_data(self, new_trade_data, current_time):\n",
        "        print(\"new_trade_data:\", new_trade_data)\n",
        "\n",
        "        # Check if new_trade_data is a pandas DataFrame\n",
        "        if isinstance(new_trade_data, pd.DataFrame):\n",
        "            for index, trade in new_trade_data.iterrows():\n",
        "                price = trade.get('price')\n",
        "                timestamp = trade.get('local_timestamp', current_time)\n",
        "                if pd.notnull(price) and pd.notnull(timestamp):\n",
        "                    self.price_ticks.append((timestamp, price))\n",
        "                else:\n",
        "                    print(\"Trade data format not recognized or data is incomplete\")\n",
        "\n",
        "        # Check if new_trade_data is a pandas Series (single trade)\n",
        "        elif isinstance(new_trade_data, pd.Series):\n",
        "            price = new_trade_data.get('price')\n",
        "            timestamp = new_trade_data.get('local_timestamp', current_time)\n",
        "            if pd.notnull(price) and pd.notnull(timestamp):\n",
        "                self.price_ticks.append((timestamp, price))\n",
        "            else:\n",
        "                print(\"Trade data format not recognized or data is incomplete\")\n",
        "\n",
        "        # Check if new_trade_data is a single dictionary (single trade)\n",
        "        elif isinstance(new_trade_data, dict):\n",
        "            price = new_trade_data.get('price')\n",
        "            timestamp = new_trade_data.get('local_timestamp', current_time)\n",
        "            if price is not None and timestamp is not None:\n",
        "                self.price_ticks.append((timestamp, price))\n",
        "            else:\n",
        "                print(\"Trade data format not recognized or data is incomplete\")\n",
        "\n",
        "        # Check if new_trade_data is a list (multiple trades)\n",
        "        elif isinstance(new_trade_data, list):\n",
        "            for trade in new_trade_data:\n",
        "                price = trade.get('price')\n",
        "                timestamp = trade.get('local_timestamp', current_time)\n",
        "                if price is not None and timestamp is not None:\n",
        "                    self.price_ticks.append((timestamp, price))\n",
        "                else:\n",
        "                    print(\"Trade data format not recognized or data is incomplete\")\n",
        "\n",
        "        # Handle unexpected data types\n",
        "        else:\n",
        "            print(\"Unexpected data type for new_trade_data\")\n",
        "    #    return\n",
        "\n",
        "        #self.price_ticks.append((timestamp, price))\n",
        "        # Print statements for debugging\n",
        "        print(\"Debugging update_tick_data method:\")\n",
        "        print(f\"Timestamp (float): {timestamp}\")\n",
        "        print(f\"Type of timestamp: {type(timestamp)}\")\n",
        "        print(f\"One hour window (timedelta): {self.one_hour_window}\")\n",
        "        print(f\"Type of one_hour_window: {type(self.one_hour_window)}\")\n",
        "\n",
        "        # Convert one_hour_window from timedelta to microseconds\n",
        "        one_hour_window_microseconds = self.one_hour_window.total_seconds() * 1e6  # 1e6 microseconds in one second\n",
        "\n",
        "        # Remove ticks outside the one-hour window\n",
        "        while self.price_ticks and self.price_ticks[0][0] < timestamp - one_hour_window_microseconds:\n",
        "            self.price_ticks.popleft()\n",
        "\n",
        "# ,\n",
        "#         # Remove old data outside the specified time window\n",
        "#         while self.price_ticks and self.price_ticks[0][0] < timestamp - self.one_hour_window:\n",
        "#             self.price_ticks.popleft()\n",
        "\n",
        "        # Update MAD volatility measures\n",
        "        #self.update_mad_volatility_measures(timestamp)\n",
        "         # Update the one_minute_trades and five_minute_trades queues\n",
        "        self._update_ema_trades(new_trade_data, current_time, self.one_minute_trades, self.one_minute_window)\n",
        "        self._update_ema_trades(new_trade_data, current_time, self.seven_minute_trades, self.seven_minute_window)\n",
        "\n",
        "        self._update_ema_trades(new_trade_data, current_time, self.thirty_five_minute_trades, self.thirty_five_minute_window)\n",
        "\n",
        "\n",
        "    # def _update_ema_trades(self, new_trade_data, current_time, trade_queue, time_window):\n",
        "    #     \"\"\"\n",
        "    #     Update the trade queue with new data and remove outdated trades.\n",
        "    #     \"\"\"\n",
        "    #     if isinstance(new_trade_data, dict):\n",
        "    #         price = new_trade_data.get('price')\n",
        "    #         timestamp = new_trade_data.get('local_timestamp', current_time)\n",
        "    #     elif isinstance(new_trade_data, list) and len(new_trade_data) >= 2:\n",
        "    #         price_index = 4\n",
        "    #         timestamp_index = 2\n",
        "    #         price = new_trade_data[price_index]\n",
        "    #         timestamp = new_trade_data[timestamp_index]\n",
        "    #     else:\n",
        "    #         return\n",
        "\n",
        "    #     trade_queue.append((timestamp, price))\n",
        "    #     while trade_queue and trade_queue[0][0] < timestamp - time_window.total_seconds() * 1e6:\n",
        "    #         trade_queue.popleft()\n",
        "\n",
        "    def _update_ema_trades(self, new_trade_data, current_time, trade_queue, time_window):\n",
        "        \"\"\"\n",
        "        Update the trade queue with new data and remove outdated trades.\n",
        "        \"\"\"\n",
        "        print(f\"Updating EMA trades with new_trade_data: {new_trade_data}\")\n",
        "\n",
        "        # Check if new_trade_data is a list of dictionaries\n",
        "        if isinstance(new_trade_data, list) and all(isinstance(item, dict) for item in new_trade_data):\n",
        "            for trade in new_trade_data:\n",
        "                price = trade.get('price')\n",
        "                timestamp = trade.get('local_timestamp', current_time)\n",
        "                print(f\"Adding trade to queue: Timestamp: {timestamp}, Price: {price}\")\n",
        "                if price is not None and timestamp is not None:\n",
        "                    # Convert timestamp to the appropriate format if necessary\n",
        "                    # Assuming timestamp is already in the correct format\n",
        "                    trade_queue.append((timestamp, price))\n",
        "                else:\n",
        "                    print(\"Some trades in the list have incomplete data\")\n",
        "        # Check if new_trade_data is a pandas Series\n",
        "        elif isinstance(new_trade_data, pd.Series):\n",
        "            price = new_trade_data.get('price')\n",
        "            timestamp = new_trade_data.get('local_timestamp', current_time)\n",
        "            if price is not None and timestamp is not None:\n",
        "                trade_queue.append((timestamp, price))\n",
        "            else:\n",
        "                print(\"Trade data in pandas Series is incomplete\")\n",
        "        else:\n",
        "            print(\"new_trade_data format not recognized or data is incomplete\")\n",
        "            return\n",
        "\n",
        "        # print(f\"Adding trade to queue: Timestamp: {timestamp}, Price: {price}\")\n",
        "        # trade_queue.append((timestamp, price))\n",
        "\n",
        "        print(f\"Trade queue before removal: {list(trade_queue)}\")\n",
        "        while trade_queue and trade_queue[0][0] < timestamp - time_window.total_seconds() * 1e6:\n",
        "            removed_trade = trade_queue.popleft()\n",
        "            print(f\"Removed outdated trade: {removed_trade}\")\n",
        "\n",
        "        print(f\"Trade queue after removal: {list(trade_queue)}\")\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_ema(self, trade_queue, window_size):\n",
        "        if not trade_queue:\n",
        "            return 0\n",
        "        if len(trade_queue) < window_size:\n",
        "            # Return the last available EMA if insufficient data\n",
        "            return trade_queue[-1][1]\n",
        "\n",
        "        alpha = 2 / (window_size + 1)\n",
        "        ema = trade_queue[0][1]  # Initial EMA value is the first price\n",
        "        for timestamp, price in trade_queue:\n",
        "            ema = (price * alpha) + (ema * (1 - alpha))\n",
        "        return ema\n",
        "\n",
        "    def calculate_dema(self, trade_queue, window_size):\n",
        "        ema = self.calculate_ema(trade_queue, window_size)\n",
        "        if ema == 0:\n",
        "            return 0\n",
        "\n",
        "        ema_of_ema = self.calculate_ema_of_ema(trade_queue, window_size)\n",
        "        dema = 2 * ema - ema_of_ema\n",
        "        return dema\n",
        "\n",
        "    def calculate_ema_of_ema(self, trade_queue, window_size):\n",
        "        if not trade_queue:\n",
        "            return 0\n",
        "        if len(trade_queue) < window_size:\n",
        "            # Return the last available EMA of EMA if insufficient data\n",
        "            return trade_queue[-1][1]\n",
        "\n",
        "        alpha = 2 / (window_size + 1)\n",
        "        ema_values = self.calculate_ema(trade_queue, window_size, ema_only=True)\n",
        "        ema_of_ema = ema_values[0]\n",
        "        for ema in ema_values:\n",
        "            ema_of_ema = (ema * alpha) + (ema_of_ema * (1 - alpha))\n",
        "        return ema_of_ema\n",
        "\n",
        "    def calculate_ema(self, trade_queue, window_size, ema_only=False):\n",
        "        if not trade_queue:\n",
        "            return 0\n",
        "\n",
        "        alpha = 2 / (window_size + 1)\n",
        "        ema_values = []\n",
        "        ema = trade_queue[0][1]  # Initial EMA value is the first price\n",
        "        for timestamp, price in trade_queue:\n",
        "            ema = (price * alpha) + (ema * (1 - alpha))\n",
        "            ema_values.append(ema)\n",
        "\n",
        "        return ema_values if ema_only else ema\n",
        "\n",
        "\n",
        "    def update_mad_volatility_measures(self, current_time):\n",
        "        for window_size in self.mad_window_sizes:\n",
        "            mad_volatility = self.calculate_mad_volatility(window_size, current_time)\n",
        "            window_minutes = int(window_size.total_seconds() / 60)\n",
        "            self.mad_volatilities[f\"{window_minutes}m\"] = mad_volatility\n",
        "            print(f\"MAD volatility for {window_minutes} minutes: {mad_volatility}\")\n",
        "\n",
        "    def calculate_mad_volatility(self, window_size, current_time):\n",
        "        \"\"\"\n",
        "        Calculate the MAD volatility for the specified window size.\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert window_size from timedelta to microseconds\n",
        "        window_size_in_units = window_size.total_seconds() * 1e6  # Convert to microseconds if necessary\n",
        "\n",
        "        # Filter prices within the window\n",
        "        window_prices = [price for (time, price) in self.price_ticks if current_time - time <= window_size_in_units]\n",
        "        print(f\"Window prices: {window_prices}\")\n",
        "        print(f\"price ticks: {self.price_ticks}\")\n",
        "\n",
        "\n",
        "        # # Calculate\n",
        "        # window_prices = [price for time, price in self.price_ticks if time >= current_time - window_size]\n",
        "\n",
        "        if len(window_prices) < 2:\n",
        "            return 0\n",
        "\n",
        "        return self.preprocess_feature_to_single_value(window_prices)\n",
        "\n",
        "\n",
        "    def preprocess_feature_to_single_value(self, feature):\n",
        "        median = np.median(feature)\n",
        "        mad = np.median([np.abs(val - median) for val in feature])\n",
        "        print(f\"MAD: {mad}\")\n",
        "\n",
        "        if mad != 0:\n",
        "            normalized_feature = [0.6745 * (val - median) / mad for val in feature]\n",
        "            return np.median(normalized_feature)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def get_mad_volatility_measures(self):\n",
        "        return self.mad_volatilities\n",
        "\n",
        "    def calculate_hourly_volatility(self):\n",
        "        \"\"\"\n",
        "        Calculate volatility based on the last hour's price data.\n",
        "        \"\"\"\n",
        "        if not self.price_ticks or len(self.price_ticks) < 2:\n",
        "            return None  # Not enough data to calculate volatility\n",
        "\n",
        "        # Extract prices from the tick data\n",
        "        recent_prices = np.array([price for _, price in self.price_ticks])\n",
        "        returns = np.diff(np.log(recent_prices))\n",
        "        hourly_volatility = np.std(returns)\n",
        "        return hourly_volatility\n",
        "\n",
        "    def get_hourly_volatility(self):\n",
        "        return self.calculate_hourly_volatility()\n",
        "\n",
        "    def get_seven_minute_dema(self):\n",
        "        \"\"\"\n",
        "        Calculate and return the 5-minute Double Exponential Moving Average (DEMA).\n",
        "        \"\"\"\n",
        "        if not self.seven_minute_trades:\n",
        "            return None  # Return None if there is no trade data\n",
        "\n",
        "        window_size = 1000  # The window size for 5-minute DEMA\n",
        "        return self.calculate_dema(self.seven_minute_trades, window_size)\n",
        "    def get_one_minute_dema(self):\n",
        "        \"\"\"\n",
        "        Calculate and return the one-minute Double Exponential Moving Average (DEMA).\n",
        "        \"\"\"\n",
        "        if not self.one_minute_trades:\n",
        "            return None  # Return None if there is no trade data\n",
        "\n",
        "        # Determine an appropriate window size for the one-minute DEMA calculation\n",
        "        # This could be based on the number of trades you expect in one minute, for example:\n",
        "        window_size = 1000  # Adjust this based on your expected number of trades per minute\n",
        "        return self.calculate_dema(self.one_minute_trades, window_size)\n",
        "\n",
        "    def get_thirty_five_minute_dema(self):\n",
        "        \"\"\"\n",
        "        Calculate and return the 35-minute Double Exponential Moving Average (DEMA).\n",
        "        \"\"\"\n",
        "        if not self.thirty_five_minute_trades:\n",
        "            return None  # Return None if there is no trade data\n",
        "\n",
        "        # Determine an appropriate window size for the 35-minute DEMA calculation\n",
        "        # This could be based on the number of trades you expect in 35 minutes, for example:\n",
        "        window_size = 10000  # Example, adjust based on your expected number of trades per minute\n",
        "        return self.calculate_dema(self.thirty_five_minute_trades, window_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Reward:\n",
        "    pnl_bounds = (-5000, 5000)  # Example range for PnL\n",
        "    drawdown_penalty_bounds = (-500, 0)  # Drawdowns can only penalize, not reward\n",
        "    liquidity_reward_bounds = (0, 500)  # Rewards for liquidity provision\n",
        "    inventory_penalty_bounds = (-500, 0)  # Penalties for inventory mismanagement\n",
        "    queue_position_reward_bounds = (0, 500)  # Rewards for good queue positioning\n",
        "    market_share_reward_bounds = (0, 100)  # Rewards for increased market share\n",
        "    rate_limit_penalty_bounds = (-2000, 0)  # Significant penalty for hitting rate limit\n",
        "    def __init__(self, volatility_manager, initial_capital, max_inventory_risk, order_manager, market_state_calculator, rate_limiter):\n",
        "\n",
        "        self.volatility_manager = volatility_manager\n",
        "        self.initial_capital = initial_capital\n",
        "        self.max_inventory_risk = max_inventory_risk\n",
        "        #self.max_rate_limit_penalty = max_rate_limit_penalty\n",
        "        self.order_manager = order_manager  # Instance of OrderManager\n",
        "        self.decay_rate = 0.1  # Example decay rate for cancellation weight calculation\n",
        "        self.time_in_queue_coefficient = 0.7\n",
        "        self.cancellation_penalty_coefficient = 2\n",
        "        self.max_cancellation_penalty = 50\n",
        "        self.max_time_in_queue_reward = 2\n",
        "        self.market_state_calculator = market_state_calculator\n",
        "\n",
        "        self.drawdon_max = .007\n",
        "        # Initialize weights for each reward component\n",
        "        self.weights = {\n",
        "            'pnl': 0.20,\n",
        "            'realized_pnl': 0.35,\n",
        "            'drawdown': 0.20,\n",
        "            'liquidity': 0.10,\n",
        "            'inventory': 0.15,\n",
        "            'queue_position': 0.15,\n",
        "           # 'market_share': 0.05\n",
        "        }\n",
        "        self.drawdown_threshold = 0.003  # Default threshold for drawdown penalty\n",
        "        self.penalty_multiplier = 10  # Default multiplier for the drawdown penalty\n",
        "        self.five_min_window = timedelta(minutes=5)  # 1-hour window\n",
        "        #self.price_ticks = deque()  # Store (timestamp, price) tuples\n",
        "        self.volatility = 0\n",
        "        self.volatility_threshold = 0.013\n",
        "        self.window_size = 500 # drawdown window\n",
        "        self.rate_limiter = rate_limiter\n",
        "        self.realized_pnl = 0  # Initialize realized PnL\n",
        "        self.realized_pnl_multiplier = 10\n",
        "        self.rate_limit_hits = 0  # Counter for rate limit breaches\n",
        "        self.initial_rate_limit_penalty = -1000 # Initial penalty for hitting the rate limit\n",
        "        #self.max_rate_limit_penalty = max_rate_limit_penalty\n",
        "        # self.order_window_size = order_window_size\n",
        "        self.filled_limit_orders_window = deque()  # Initialize deque for filled limit orders\n",
        "        self.total_limit_orders_window = deque()  # Initialize deque for total limit orders\n",
        "\n",
        "        # self.filled_limit_orders_window = deque(maxlen=order_window_size)\n",
        "        # self.total_limit_orders_window = deque(maxlen=order_window_size)\n",
        "        self.liquidity_reward_scaling_factor = 1.0\n",
        "        self.inventory_penalty_scaling_factor = 2  # Adjustable scaling factor for inventory penalty\n",
        "\n",
        "        #self.portfolio_values = [initial_capital] * window_size\n",
        "        # Initialize other necessary attributes\n",
        "        self.max_inventory_risk = max_inventory_risk\n",
        "        self.inventory_target = 0  # Updated dynamically\n",
        "        self.current_inventory = 0  # This should be updated with the actual inventory level\n",
        "\n",
        "\n",
        "    # Reward function components\n",
        "    # ... [Other methods for PnL, liquidity reward, etc.] ...\n",
        "    # def _calculate_queue_position_reward(self):\n",
        "    #     # Assuming you have a method to get the current state of the order book and your order details\n",
        "    #     order_details = self.get_order_details()\n",
        "    #     order_book_state = self.get_order_book_state()\n",
        "\n",
        "    #     # Weights for each queue position metric\n",
        "    #     time_weight = 0.5  # Weight for the time since order placement\n",
        "    #     volume_weight = 0.3  # Weight for the relative volume\n",
        "    #     events_weight = 0.2  # Weight for the order book events\n",
        "\n",
        "    #     # Calculate metrics that contribute to the queue position\n",
        "    #     order_time_since_placement = self.calculate_time_since_placement(order_details.timestamp)\n",
        "    #     relative_volume = self.calculate_relative_volume(order_details.volume, order_book_state.total_volume_at_price)\n",
        "    #     order_book_events = self.calculate_order_book_events(order_book_state.recent_changes)\n",
        "\n",
        "    #     # Combining the metrics into a queue position score with weights\n",
        "    #     queue_position_score = (\n",
        "    #         time_weight * order_time_since_placement +\n",
        "    #         volume_weight * (1 - relative_volume) +\n",
        "    #         events_weight * order_book_events\n",
        "    #     )\n",
        "\n",
        "    #     # Normalize the combined score to be between 0 and 1\n",
        "    #     normalized_queue_position_score = self.normalize_metric(queue_position_score, min_value=0, max_value=time_weight + volume_weight + events_weight)\n",
        "\n",
        "    #     # Invert the score for the reward: a higher score (closer to the front of the queue) yields a higher reward\n",
        "    #     queue_position_reward = 1 - normalized_queue_position_score\n",
        "\n",
        "    #     return queue_position_reward\n",
        "    def calculate_recent_cancellations_weight(self, current_time_microseconds, decay_rate):\n",
        "        weight = 0\n",
        "        for cancellation in self.order_manager.cancelled_orders:\n",
        "            time_since_cancellation_microseconds = current_time_microseconds - cancellation['cancel_time']\n",
        "            print(f'time_since_cancellation_microseconds: {time_since_cancellation_microseconds}')\n",
        "            #time_since_cancellation_seconds = time_since_cancellation_microseconds / 1e6\n",
        "            decayed_weight = np.exp(-decay_rate * time_since_cancellation_microseconds)\n",
        "            weight += decayed_weight\n",
        "        return weight\n",
        "\n",
        "\n",
        "    def calculate_cancellation_penalty(self, recent_cancellations_weight):\n",
        "        penalty = self.cancellation_penalty_coefficient * recent_cancellations_weight\n",
        "        return min(penalty, self.max_cancellation_penalty)\n",
        "\n",
        "    # def calculate_time_in_queue_reward(self, order, current_time):\n",
        "    #     time_in_queue = current_time - order.time_placed\n",
        "    #     reward = self.time_in_queue_coefficient * np.log(1 + time_in_queue)\n",
        "    #     return min(reward, self.max_time_in_queue_reward)\n",
        "\n",
        "    def calculate_time_in_queue_reward(self, order, current_time):\n",
        "        # Log the types and values for debugging\n",
        "        print(f\"Current time (type: {type(current_time)}): {current_time}\")\n",
        "        print(f\"Order time placed (type: {type(order.time_placed)}): {order.time_placed}\")\n",
        "\n",
        "        # Convert Unix timestamp in microseconds to seconds\n",
        "        current_time_seconds = current_time / 1e6\n",
        "        order_time_placed_seconds = order.time_placed / 1e6\n",
        "\n",
        "        # Calculate the time in queue in seconds\n",
        "        time_in_queue_seconds = current_time_seconds - order_time_placed_seconds\n",
        "        print(f\"Time in queue (seconds): {time_in_queue_seconds}\")\n",
        "\n",
        "        # Convert seconds to hours or your desired unit of time\n",
        "        #time_in_queue_hours = time_in_queue_seconds / 3600\n",
        "        reward = self.time_in_queue_coefficient * np.log(1 + time_in_queue_seconds)\n",
        "        reward = min(reward, self.max_time_in_queue_reward)\n",
        "        print(f\"Calculated reward: {reward}\")\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def calculate_order_stability_reward(self, order, current_time):\n",
        "        recent_cancellations_weight = self.calculate_recent_cancellations_weight(current_time,  0.01)\n",
        "        time_in_queue_reward = self.calculate_time_in_queue_reward(order, current_time)\n",
        "        cancellation_penalty = self.calculate_cancellation_penalty(recent_cancellations_weight)\n",
        "        total_reward = time_in_queue_reward - cancellation_penalty\n",
        "        return total_reward\n",
        "\n",
        "    def _calculate_queue_position_reward(self, current_time):\n",
        "        \"\"\"\n",
        "        Calculate rewards for queue position stability for each active order.\n",
        "        \"\"\"\n",
        "        # current_time = datetime.now()\n",
        "        total_queue_reward = 0\n",
        "        for order in self.order_manager.active_orders:\n",
        "            order_stability_reward = self.calculate_order_stability_reward(order, current_time)\n",
        "            total_queue_reward += order_stability_reward\n",
        "        return total_queue_reward\n",
        "\n",
        "    def apply_penalty_for_rate_limit(self):\n",
        "        \"\"\"\n",
        "        Apply a progressively increasing penalty for each rate limit breach.\n",
        "\n",
        "        \"\"\"\n",
        "        usage_percentage = self.rate_limiter.get_usage_percentage()\n",
        "\n",
        "        # Define the maximum penalty\n",
        "        max_penalty = -1 # Maximum penalty\n",
        "\n",
        "        # Calculate penalty based on usage\n",
        "        penalty = (usage_percentage / 100) * max_penalty\n",
        "        # penalty = np.clip(penalty, max_penalty, 0)  # Ensure the penalty does not exceed the maximum\n",
        "\n",
        "        return penalty\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Volatility calculations\n",
        "    # def _calculate_price_volatility(self):\n",
        "    #     log_returns = np.diff(np.log(self.recent_prices))\n",
        "    #     price_volatility = np.std(log_returns)\n",
        "    #     return price_volatility\n",
        "\n",
        "    # def _calculate_volume_volatility(self):\n",
        "    #     volume_changes = np.diff(self.recent_volumes) / self.recent_volumes[:-1]\n",
        "    #     volume_volatility = np.std(volume_changes)\n",
        "    #     return volume_volatility\n",
        "\n",
        "    # def _calculate_spread_volatility(self):\n",
        "    #     spread_changes = np.diff(self.recent_spreads) / self.recent_spreads[:-1]\n",
        "    #     spread_volatility = np.std(spread_changes)\n",
        "    #     return spread_volatility\n",
        "\n",
        "    # def _calculate_multifactor_volatility(self):\n",
        "    #     weights = {'price': 0.6, 'volume': 0.2, 'spread': 0.2}\n",
        "    #     multifactor_volatility = (weights['price'] * self._calculate_price_volatility() +\n",
        "    #                               weights['volume'] * self._calculate_volume_volatility() +\n",
        "    #                               weights['spread'] * self._calculate_spread_volatility())\n",
        "    #     return multifactor_volatility\n",
        "\n",
        "    # Inventory-related calculations\n",
        "    def _calculate_inventory_deviation(self):\n",
        "        current_inventory = self.order_manager.inventory\n",
        "        deviation = abs(current_inventory - self.order_manager.target_inventory)\n",
        "        print(f\"Current inventory: {current_inventory}\")\n",
        "        print(f\"Inventory target: {self.order_manager.target_inventory}\")\n",
        "        print(f\"Inventory deviation: {deviation}\")\n",
        "        return deviation\n",
        "\n",
        "    def _calculate_liquidity_factor(self):\n",
        "        # Retrieve the latest sophisticated liquidity value\n",
        "        liquidity = self.market_state_calculator.liquidity\n",
        "        if liquidity is not None and liquidity != 0:\n",
        "            liquidity_factor = 1 / liquidity\n",
        "        else:\n",
        "            liquidity_factor = 0  # Handle cases where liquidity is not available or zero\n",
        "        return liquidity_factor\n",
        "\n",
        "    def _calculate_adaptive_inventory_penalty(self):\n",
        "        deviation = self._calculate_inventory_deviation()\n",
        "        #liquidity_factor = self._calculate_liquidity_factor()\n",
        "\n",
        "        # Amplify penalty using a non-linear function like quadratic\n",
        "        #amplified_deviation = deviation ** 2\n",
        "\n",
        "        # Apply the scaling factor and liquidity factor\n",
        "        inventory_penalty =   deviation\n",
        "        return -inventory_penalty\n",
        "\n",
        "\n",
        "    def set_inventory_target(self, target):\n",
        "        self.inventory_target = target\n",
        "\n",
        "    # def _adjust_inventory_target(self, volatility):\n",
        "    #     base_target = self._base_inventory_target()\n",
        "    #     adjusted_target = base_target * (1 - volatility)\n",
        "    #     adjusted_target = max(min(adjusted_target, base_target), 0)\n",
        "    #     return adjusted_target\n",
        "\n",
        "    def update_order_window(self, filled_orders, total_orders):\n",
        "        \"\"\"\n",
        "        Update the windows of filled and total limit orders with the latest data and timestamps.\n",
        "        \"\"\"\n",
        "        current_time = datetime.now()  # Get the current time\n",
        "\n",
        "        # Append the new data along with the timestamp\n",
        "        self.filled_limit_orders_window.append((current_time, filled_orders))\n",
        "        self.total_limit_orders_window.append((current_time, total_orders))\n",
        "\n",
        "        # Remove old data outside the specified time window from filled orders\n",
        "        while self.filled_limit_orders_window and self.filled_limit_orders_window[0][0] < current_time - self.five_min_window:\n",
        "            self.filled_limit_orders_window.popleft()\n",
        "\n",
        "        # Remove old data outside the specified time window from total orders\n",
        "        while self.total_limit_orders_window and self.total_limit_orders_window[0][0] < current_time - self.five_min_window:\n",
        "            self.total_limit_orders_window.popleft()\n",
        "\n",
        "    def _calculate_liquidity_reward(self):\n",
        "        \"\"\"\n",
        "        Calculate the liquidity reward based on filled limit orders and their proximity to the mid-price,\n",
        "        normalized by the proximity of all limit orders.\n",
        "        \"\"\"\n",
        "        filled_proximity_rewards = []\n",
        "        total_proximity_values = []\n",
        "\n",
        "        for order in self.filled_limit_orders_window:\n",
        "            filled_proximity_reward = self._calculate_proximity_reward(order)\n",
        "            filled_proximity_rewards.append(filled_proximity_reward)\n",
        "\n",
        "        for order in self.total_limit_orders_window:\n",
        "            total_proximity_value = self._calculate_proximity_reward(order, filled=False)\n",
        "            total_proximity_values.append(total_proximity_value)\n",
        "\n",
        "        # Aggregate proximity rewards and normalize\n",
        "        if filled_proximity_rewards and total_proximity_values:\n",
        "            liquidity_reward = sum(filled_proximity_rewards) / sum(total_proximity_values) if sum(total_proximity_values) > 0 else 0\n",
        "        else:\n",
        "            liquidity_reward = 0\n",
        "\n",
        "        return liquidity_reward\n",
        "\n",
        "    def _calculate_decay_rate(self):\n",
        "        # Higher volatility can lead to a higher decay rate,\n",
        "        # meaning distance from the mid-price becomes more significant\n",
        "        base_decay_rate = 0.1  # Base decay rate\n",
        "        volatility_factor = self.volatility / self.volatility_threshold  # self.volatility_threshold defined elsewhere\n",
        "        decay_rate = base_decay_rate * volatility_factor\n",
        "        return max(0.01, min(decay_rate, 1))  # Ensure decay rate is within reasonable bounds\n",
        "\n",
        "    def _calculate_proximity_reward(self, order, filled=True):\n",
        "        \"\"\"\n",
        "        Calculate the proximity reward for an order.\n",
        "        \"\"\"\n",
        "        # Calculate the distance from the mid-price\n",
        "        distance_from_mid_price = abs(order['price'] - self.mid_price)\n",
        "\n",
        "        # Define a decay rate based on market volatility or other factors\n",
        "        decay_rate = self._calculate_decay_rate()  # Implement this method\n",
        "\n",
        "        # Calculate proximity score\n",
        "        proximity_score = np.exp(-decay_rate * distance_from_mid_price)\n",
        "\n",
        "        if filled:\n",
        "            # Adjust the score based on filled proportion of the order\n",
        "            filled_proportion = order['filled_quantity'] / order['total_quantity']\n",
        "            adjusted_proximity_score = proximity_score * filled_proportion\n",
        "            # Calculate final reward for the order\n",
        "            reward = adjusted_proximity_score * order['filled_quantity']\n",
        "            return reward\n",
        "        else:\n",
        "            # For total orders, consider the order quantity instead of filled quantity\n",
        "            return proximity_score * order['total_quantity']\n",
        "\n",
        "\n",
        "\n",
        "    def _calculate_hourly_volatility(self):\n",
        "        \"\"\"\n",
        "        Retrieve the 60-minute MAD volatility from the VolatilityManager.\n",
        "        \"\"\"\n",
        "        mad_volatilities = self.volatility_manager.price_ticks\n",
        "        return mad_volatilities  # Retrieve the 60-minute MAD volatility\n",
        "\n",
        "\n",
        "    # Method to calculate the current rolling drawdown\n",
        "    def _calculate_adjusted_drawdown(self):\n",
        "        \"\"\"\n",
        "        Calculate the adjusted drawdown considering market conditions.\n",
        "        \"\"\"\n",
        "        ##print(market_volatility)\n",
        "        # if not isinstance(market_volatility, (float, int)):\n",
        "        #     raise ValueError(f\"Unexpected market_volatility type: {type(market_volatility)}. Expected float or int.\")\n",
        "\n",
        "        if not self.order_manager.portfolio_manager.portfolio_values:\n",
        "            return 0\n",
        "\n",
        "        peak_value = max(value for _, value in self.order_manager.portfolio_manager.portfolio_values)\n",
        "        current_value = self.order_manager.portfolio_manager.get_latest_portfolio_value()\n",
        "\n",
        "        # Calculate standard deviation of volatility measurements\n",
        "        # std_dev = np.std(market_volatility)\n",
        "        # print(std_dev)\n",
        "\n",
        "        raw_drawdown = (peak_value - current_value) / peak_value\n",
        "        adjusted_drawdown = raw_drawdown * 10\n",
        "        # sys.exit()\n",
        "        return adjusted_drawdown\n",
        "        # raw_drawdown = (peak_value - current_value) / peak_value if peak_value else 0\n",
        "\n",
        "        # adjusted_drawdown = raw_drawdown * market_volatility\n",
        "        # return adjusted_drawdown\n",
        "\n",
        "\n",
        "    def _non_linear_drawdown_penalty(self):\n",
        "        \"\"\"\n",
        "        Calculate a non-linear penalty for drawdowns exceeding a threshold.\n",
        "        \"\"\"\n",
        "        penalty = self._calculate_adjusted_drawdown()\n",
        "        # if adjusted_drawdown > self.drawdown_threshold:\n",
        "        #     exp_argument = self.penalty_multiplier * (adjusted_drawdown - self.drawdown_threshold)\n",
        "        #     exp_argument_capped = max(exp_argument, -1)  # Example cap to prevent -inf\n",
        "        #     penalty = -np.exp(exp_argument_capped)\n",
        "        # else:\n",
        "        #     penalty = 0\n",
        "        return -penalty\n",
        "\n",
        "\n",
        "\n",
        "    def _calculate_position_penalty(self):\n",
        "\n",
        "        total_position = self.order_manager.calculate_combined_inventory_and_orders_value() #inventory_value + active_orders_value\n",
        "        position_ratio = total_position / self.order_manager.portfolio_manager.get_AUM()\n",
        "\n",
        "        penalty_threshold = 0.50  # 50% of AUM\n",
        "        if position_ratio > penalty_threshold:\n",
        "            # Calculate penalty based on how much the threshold is exceeded\n",
        "            penalty = (position_ratio - penalty_threshold) * 20\n",
        "            return penalty\n",
        "        else:\n",
        "            # No penalty if below threshold\n",
        "            return 0\n",
        "\n",
        "    def reset_reward_function(self):\n",
        "        # Reset realized PnL\n",
        "        self.realized_pnl = 0\n",
        "\n",
        "        # Reinitialize the portfolio values with the initial capital\n",
        "        self.portfolio_values.clear()\n",
        "        self.portfolio_values.append((datetime.now(), self.initial_capital))\n",
        "\n",
        "        # Reset the rate limit hit counter\n",
        "        self.rate_limit_hits = 0\n",
        "\n",
        "        # Reset other reward components as necessary\n",
        "        # For example, resetting metrics related to market share, liquidity, etc.\n",
        "        self.liquidity_rewards = 0\n",
        "        self.inventory_penalties = 0\n",
        "        # self.queue_position_rewards = 0\n",
        "        # self.market_share_rewards = 0\n",
        "        self.drawdown_penalties = 0\n",
        "\n",
        "        # Any other state variables that contribute to the reward calculation\n",
        "        # should be reset or reinitialized here as well\n",
        "\n",
        "\n",
        "\n",
        "    # # The main reward function that combines all components\n",
        "    # def _get_reward(self,current_time):\n",
        "    #     # Fetch PnL from OrderManager\n",
        "    #     self.pnl = self.order_manager.unrealized_pnl  # Unrealized PnL\n",
        "    #     self.realized_pnl = self.order_manager.get_realized_pnl()  # Assuming this method exists\n",
        "\n",
        "    #     # Calculate and store reward components\n",
        "    #     self.drawdown_penalty = self._non_linear_drawdown_penalty()\n",
        "    #     self.liquidity_reward = self._calculate_liquidity_reward()\n",
        "    #     self.inventory_penalty = self._calculate_adaptive_inventory_penalty()\n",
        "    #     #self.queue_position_reward = self._calculate_queue_position_reward()\n",
        "    #     self.queue_position_reward = self._calculate_queue_position_reward(current_time)\n",
        "\n",
        "    #     # self.market_share_reward = self._calculate_market_share_reward()\n",
        "    #     self.rate_limit_penalty = self.apply_penalty_for_rate_limit()\n",
        "    #     self.calculate_position_penalty = self._calculate_position_penalty()\n",
        "\n",
        "    #     # Combine the components into a final reward\n",
        "    #     total_reward = (\n",
        "    #         self.weights['pnl'] * self.pnl * 20 +\n",
        "    #         self.weights['realized_pnl'] * self.realized_pnl * 500 +\n",
        "    #         self.weights['drawdown'] * self.drawdown_penalty +\n",
        "    #         self.weights['liquidity'] * self.liquidity_reward +\n",
        "    #         self.weights['inventory'] * self.inventory_penalty +\n",
        "    #         self.weights['queue_position'] * self.queue_position_reward +\n",
        "    #         self.calculate_position_penalty +\n",
        "    #         # self.weights['market_share'] * self.market_share_reward +\n",
        "    #         self.rate_limit_penalty\n",
        "    #     )\n",
        "\n",
        "    #     return total_reward\n",
        "    # The main reward function that combines all components\n",
        "    def _get_reward(self, current_time):\n",
        "        # Fetch PnL from OrderManager\n",
        "        self.pnl = self.order_manager.unrealized_pnl  # Unrealized PnL\n",
        "        self.realized_pnl = self.order_manager.get_realized_pnl()  # Assuming this method exists\n",
        "\n",
        "        # Calculate and store reward components\n",
        "        self.drawdown_penalty = self._non_linear_drawdown_penalty()\n",
        "        self.liquidity_reward = self._calculate_liquidity_reward()\n",
        "        self.inventory_penalty = self._calculate_adaptive_inventory_penalty()\n",
        "        self.queue_position_reward = self._calculate_queue_position_reward(current_time)\n",
        "        self.rate_limit_penalty = self.apply_penalty_for_rate_limit()\n",
        "        self.position_penalty = self._calculate_position_penalty()\n",
        "\n",
        "        # Debug prints for each component\n",
        "        print(f\"Unrealized PnL: {self.pnl}\")\n",
        "        print(f\"Realized PnL: {self.realized_pnl}\")\n",
        "        print(f\"Drawdown Penalty: {self.drawdown_penalty}\")\n",
        "        print(f\"Liquidity Reward: {self.liquidity_reward}\")\n",
        "        print(f\"Inventory Penalty: {self.inventory_penalty}\")\n",
        "        print(f\"Queue Position Reward: {self.queue_position_reward}\")\n",
        "        print(f\"Rate Limit Penalty: {self.rate_limit_penalty}\")\n",
        "        print(f\"Position Penalty: {self.position_penalty}\")\n",
        "        print(f\"directional reward: {self.market_state_calculator.alignment_reward}\")\n",
        "\n",
        "        # Combine the components into a final reward\n",
        "        total_reward = (\n",
        "            self.weights['pnl'] * self.pnl * 10 +\n",
        "            self.weights['realized_pnl'] * self.realized_pnl * 200 +\n",
        "            self.weights['drawdown'] * self.drawdown_penalty +\n",
        "            self.weights['liquidity'] * self.liquidity_reward +\n",
        "            self.weights['inventory'] * self.inventory_penalty / 100+\n",
        "            self.weights['queue_position'] * self.queue_position_reward  +\n",
        "            self.market_state_calculator.alignment_reward +\n",
        "            self.position_penalty +\n",
        "            self.rate_limit_penalty\n",
        "        )\n",
        "\n",
        "        # Debug print for total reward\n",
        "        print(f\"Total Reward: {total_reward}\")\n",
        "\n",
        "        return total_reward\n",
        "\n",
        "\n",
        "    # Getter methods for each reward component\n",
        "    def get_pnl(self):\n",
        "        return self.pnl\n",
        "\n",
        "    def get_realized_pnl(self):\n",
        "        return self.realized_pnl\n",
        "\n",
        "    def get_drawdown_penalty(self):\n",
        "        return self.drawdown_penalty\n",
        "\n",
        "    def get_liquidity_reward(self):\n",
        "        return self.liquidity_reward\n",
        "\n",
        "    def get_inventory_penalty(self):\n",
        "        return self.inventory_penalty\n",
        "\n",
        "    def get_queue_position_reward(self):\n",
        "        return self.queue_position_reward\n",
        "\n",
        "    def get_rate_limit_penalty(self):\n",
        "        return self.rate_limit_penalty\n",
        "\n",
        "\n",
        "\n",
        "# class OrderBookCache:\n",
        "#     def __init__(self, max_length=100):\n",
        "#         self.order_book_data_cache = deque(maxlen=max_length)\n",
        "#         self.trades_data_cache = deque(maxlen=max_length)\n",
        "#         self.exchange_timestamps = deque(maxlen=max_length)\n",
        "#         self.local_timestamps = deque(maxlen=max_length)\n",
        "\n",
        "#         self.latest_order_book_data = np.zeros((20, 4))  # Example dimensions for order book\n",
        "#         self.latest_trades_data = np.zeros((10, 4))  # Example dimensions for trades data\n",
        "\n",
        "#     def add_order_book_data(self, order_book_data, exchange_timestamp, local_timestamp=None):\n",
        "#         if local_timestamp is None:\n",
        "#             local_timestamp = time.time()\n",
        "#         self.latest_order_book_data = order_book_data\n",
        "#         self.order_book_data_cache.append({'order_book': order_book_data, 'timestamp': exchange_timestamp, 'local_timestamp': local_timestamp})\n",
        "#         self.exchange_timestamps.append(exchange_timestamp)\n",
        "#         self.local_timestamps.append(local_timestamp)\n",
        "\n",
        "#     def update_with_order_book_handler_data(self, order_book_handler, exchange_timestamp, local_timestamp=None):\n",
        "#         if local_timestamp is None:\n",
        "#             local_timestamp = time.time()\n",
        "#         order_book_array = order_book_handler.get_order_book_array()\n",
        "#         self.add_order_book_data(order_book_array, exchange_timestamp, local_timestamp)\n",
        "\n",
        "\n",
        "#     def add_trades_data(self, trades_data, exchange_timestamp, local_timestamp=None):\n",
        "#         if local_timestamp is None:\n",
        "#             local_timestamp = time.time()\n",
        "#         self.latest_trades_data = trades_data\n",
        "#         self.trades_data_cache.append({'trades': trades_data, 'timestamp': exchange_timestamp, 'local_timestamp': local_timestamp})\n",
        "#         self.exchange_timestamps.append(exchange_timestamp)\n",
        "#         self.local_timestamps.append(local_timestamp)\n",
        "\n",
        "#     def get_latest_order_book_data(self):\n",
        "#         return self.latest_order_book_data\n",
        "\n",
        "#     def get_latest_trades_data(self):\n",
        "#         return self.latest_trades_data\n",
        "\n",
        "#     def copy_to_3d_arrays(self):\n",
        "#         # Adjust the dimensions as necessary\n",
        "#         num_order_book_slices = len(self.order_book_data_cache)\n",
        "#         num_trades_slices = len(self.trades_data_cache)\n",
        "\n",
        "#         order_book_3d = np.zeros((20, 4, num_order_book_slices))\n",
        "#         trades_data_3d = np.zeros((10, 4, num_trades_slices))\n",
        "#         exchange_ts_array = np.array(self.exchange_timestamps)\n",
        "#         local_ts_array = np.array(self.local_timestamps)\n",
        "\n",
        "#         for i, data in enumerate(self.order_book_data_cache):\n",
        "#             order_book_3d[:, :, i] = data['order_book']\n",
        "#         for i, data in enumerate(self.trades_data_cache):\n",
        "#             trades_data_3d[:, :, i] = data['trades']\n",
        "\n",
        "#         return order_book_3d, trades_data_3d, exchange_ts_array, local_ts_array\n",
        "# # Usage example\n",
        "# cache = OrderBookCache(max_length=100)\n",
        "# cache.add_order_book_data(new_order_book_data, exchange_timestamp=time.time(), local_timestamp=time.time())\n",
        "# cache.add_trades_data(new_trades_data, exchange_timestamp=time.time(), local_timestamp=time.time())\n",
        "# # ... add more data over time ...\n",
        "\n",
        "# # When needed, copy the cached data to 3D arrays for analysis\n",
        "# order_book_3d, trades_data_3d, exchange_ts, local_\n",
        "\n",
        "class OrderBookManager:\n",
        "    def __init__(self, depth=10, max_updates=2):\n",
        "        self.bid_order_book = []\n",
        "        self.ask_order_book = []\n",
        "        self.depth = depth\n",
        "        self.order_book_history = deque(maxlen=max_updates)\n",
        "\n",
        "    def update_order_book(self, order_book_data):\n",
        "        bid_updates = order_book_data.get('bids', [])\n",
        "        ask_updates = order_book_data.get('asks', [])\n",
        "\n",
        "        self._update_order_book_side(self.bid_order_book, bid_updates, 'buy')\n",
        "        self._update_order_book_side(self.ask_order_book, ask_updates, 'sell')\n",
        "\n",
        "        current_state = self.get_top_bids_and_asks()\n",
        "        self.order_book_history.append(current_state)\n",
        "\n",
        "    def _update_order_book_side(self, order_book, updates, side):\n",
        "        # Update or append orders\n",
        "        for price, volume in updates:\n",
        "            self._update_or_append_order(order_book, price, volume, side)\n",
        "\n",
        "        # Sort and trim the order book\n",
        "        if side == 'buy':\n",
        "            # Sort bids in descending order and keep the top 'self.depth' bids\n",
        "            order_book.sort(key=lambda x: x[0], reverse=True)\n",
        "            order_book[:] = order_book[:self.depth]\n",
        "        elif side == 'sell':\n",
        "            # Sort asks in ascending order and keep the top 'self.depth' asks\n",
        "            order_book.sort(key=lambda x: x[0])\n",
        "            order_book[:] = order_book[:self.depth]\n",
        "\n",
        "    def _update_or_append_order(self, order_book, price, volume, side):\n",
        "        for i, (p, v) in enumerate(order_book):\n",
        "            if p == price:\n",
        "                if volume > 0:\n",
        "                    # Replace the volume of the existing order\n",
        "                    order_book[i] = (price, volume)\n",
        "                else:\n",
        "                    # Remove the order if the new volume is zero\n",
        "                    del order_book[i]\n",
        "                return\n",
        "        if volume > 0:\n",
        "            # Append a new order if the price is not found and volume is non-zero\n",
        "            order_book.append((price, volume))\n",
        "\n",
        "    def get_top_bids_and_asks(self):\n",
        "        top_bids = sorted(self.bid_order_book, key=lambda x: x[0], reverse=True)[:self.depth]\n",
        "        top_asks = sorted(self.ask_order_book, key=lambda x: x[0])[:self.depth]\n",
        "        return top_bids, top_asks\n",
        "\n",
        "    def get_order_book_history(self):\n",
        "        return list(self.order_book_history)\n",
        "\n",
        "    def update_from_lob_instance(self, lob_instance):\n",
        "        bids, asks = lob_instance.get_current_book()\n",
        "\n",
        "        # Replace the current bid and ask order books with the new data\n",
        "        self.bid_order_book = sorted(bids, key=lambda x: x[0], reverse=True)[:self.depth]\n",
        "        self.ask_order_book = sorted(asks, key=lambda x: x[0])[:self.depth]\n",
        "\n",
        "        # Create a new snapshot of the top bids and asks\n",
        "        current_state = (self.bid_order_book, self.ask_order_book)\n",
        "\n",
        "        # Append the new snapshot to the order book history\n",
        "        self.order_book_history.append(current_state)\n",
        "\n",
        "        # Optional: Debugging information\n",
        "\n",
        "class TradeUpdateManager:\n",
        "    def __init__(self, max_updates=15):\n",
        "        self.trade_history = deque(maxlen=max_updates)\n",
        "\n",
        "    def update_trades(self, trades_data):\n",
        "        \"\"\"\n",
        "        Update the trades history with the latest trades data.\n",
        "\n",
        "        :param trades_data: A list of trade updates. Each update is expected to be a dictionary\n",
        "                            with keys like 'price', 'volume', and 'timestamp'.\n",
        "        \"\"\"\n",
        "        # for trade in trades_data:\n",
        "        self.trade_history.append(trades_data)\n",
        "\n",
        "    def format_and_append_trade_data(self, data, current_unix_timestamp):\n",
        "        # Check if data is a list containing dictionaries for trades\n",
        "        #current_unix_timestamp = current_unix_timestamp * 1e6\n",
        "        if isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
        "            # Assume the first item in the list represents the trade data we want to format\n",
        "            trade_data = data[0]\n",
        "\n",
        "            formatted_data = {\n",
        "                'event': 2.0,  # Assuming 'event' is always 2 for trade data\n",
        "                'local_timestamp': current_unix_timestamp,  # Use the current UNIX timestamp\n",
        "                'side': 1.0 if trade_data['side'] == 'buy' else -1.0,\n",
        "                'price': trade_data['price'],\n",
        "                'volume': trade_data['volume']\n",
        "            }\n",
        "\n",
        "            # Convert to pd.Series for consistency\n",
        "            formatted_series = pd.Series(formatted_data)\n",
        "\n",
        "            # Append the formatted data to the trade history\n",
        "            self.trade_history.append(formatted_series)\n",
        "        else:\n",
        "            print(\"Input data format not recognized or not supported.\")\n",
        "            sys.exit()\n",
        "\n",
        "\n",
        "    def get_latest_trades(self):\n",
        "        \"\"\"\n",
        "        Get the latest trades from the history.\n",
        "\n",
        "        :return: A list of the latest trade updates.\n",
        "        \"\"\"\n",
        "        return list(self.trade_history)\n",
        "\n",
        "\n",
        "class MarketStateCalculator:\n",
        "    def __init__(self, rate_limiter, volatility_manager, order_manager, initial_capital):\n",
        "        # Inventory and price metrics\n",
        "        self.inventory_level = 0\n",
        "        self.average_buy_price = 0\n",
        "        self.average_sell_price = 0\n",
        "        self.initial_capital = initial_capital\n",
        "        # Placeholders for data arrays\n",
        "        self.trades_data = np.array([])\n",
        "        #self.order_book = np.zeros((20, 4), dtype=np.float64)\n",
        "\n",
        "        # Historical and other metrics\n",
        "        self.historical_returns = np.array([])\n",
        "        self.api_call_count = 0\n",
        "        self.rate_limit_window_reset_time = None\n",
        "\n",
        "        self.liquidity = 0\n",
        "        # Cached metrics\n",
        "\n",
        "        self.cached_trades_data = 0.0\n",
        "        self.cached_order_book = 0.0\n",
        "        self.cached_vwap = 0.0\n",
        "        self.cached_price_impact = 0.0\n",
        "        self.cached_var = 0.0\n",
        "        self.cached_order_flow_ratio = 0.0\n",
        "        self.cached_order_flow = 0.0\n",
        "        self.cached_trading_volumes = 0.0\n",
        "        self.cached_weighted_price_volatility = 0.0\n",
        "        self.cached_time_weighted_volume_variability = 0.0\n",
        "        self.cached_bid_depth = 0.0\n",
        "        self.cached_order_flow_rate = 0.0\n",
        "        self.cached_ask_depth = 0.0\n",
        "        self.cached_total_bid_volume = 0.0\n",
        "        self.cached_market_depth = 0.0\n",
        "        self.cached_bid_ask_spread = 0.0\n",
        "        self.cached_ema_buy = 0.0\n",
        "        self.cached_ema_sell = 0.0\n",
        "        self.cached_cv_buy = 0.0\n",
        "        self.cached_cv_sell = 0.0\n",
        "        self.cached_bid_skewness = 0.0\n",
        "        self.cached_ask_skewness = 0.0\n",
        "        self.cached_bid_slope = 0.0\n",
        "        self.cached_ask_slope = 0.0\n",
        "        self.cached_best_ask_volume = 0.0\n",
        "        self.cached_best_bid_volume = 0.0\n",
        "        self.cached_best_bid_price = 0.0\n",
        "        self.cached_best_ask_price = 0.0\n",
        "        self.cached_half_spread = 0.0\n",
        "        self.cached_mid_price = 0.0\n",
        "        self.cached_total_ask_volume = 0.0\n",
        "        self.cached_top_two_bid_levels_volume = 0.0\n",
        "        self.cached_top_two_ask_levels_volume = 0.0\n",
        "        self.cached_buy_order_flow_rate = 0.0\n",
        "        self.cached_sell_order_flow_rate = 0.0\n",
        "        self.alignment_reward = 0.0\n",
        "\n",
        "        self.volatility_manager = volatility_manager\n",
        "\n",
        "        # Last trade metrics\n",
        "        self.last_traded_price = 0\n",
        "        self.last_trade_volume = 0\n",
        "        self.rolling_trade_volume = deque(maxlen=9)\n",
        "        self.last_trade_timestamp = 0\n",
        "        self.time_since_last_trade = 0\n",
        "\n",
        "        # State vector preparation\n",
        "        # self.previous_state = np.zeros(num_features)\n",
        "        # self.state_mean = np.zeros(num_features)\n",
        "        # self.state_std = np.ones(num_features)\n",
        "\n",
        "        # External dependencies\n",
        "        self.rate_limiter = rate_limiter\n",
        "        self.order_manager = order_manager\n",
        "\n",
        "        # Data update flags\n",
        "        self.is_trade_data_updated = False\n",
        "        self.is_order_book_updated = False\n",
        "\n",
        "    # Other methods for calculation and updates...\n",
        "\n",
        "\n",
        "        '''\n",
        "         def __init__(self):\n",
        "        self.inventory_level = 0  # Current inventory level\n",
        "        self.average_buy_price = 0  # Average buy price of the inventory\n",
        "        # Cached metrics (initialized as needed)\n",
        "        self.cached_bid_depth = 0\n",
        "        self.cached_ask_depth = 0\n",
        "        self.cached_market_imbalance = 0\n",
        "        self.cached_market_depth = 0\n",
        "        self.cached_bid_ask_spread = 0\n",
        "        self.cached_vwap = 0\n",
        "        self.cached_price_impact = 0\n",
        "        self.cached_var = 0\n",
        "        self.cached_order_flow_ratio = 0\n",
        "        self.cached_order_flow = 0\n",
        "        self.cached_trading_volumes = 0\n",
        "        self.cached_weighted_price_volatility = 0\n",
        "        self.cached_time_weighted_volume_variability = 0\n",
        "        # Flags for data updates\n",
        "        self.is_trade_data_updated = False\n",
        "        self.is_order_book_updated = False\n",
        "        '''\n",
        "\n",
        "    def get_current_position(self):\n",
        "        return self.order_manager.inventory\n",
        "\n",
        "    def get_average_buy_price(self):\n",
        "        return self.order_manager.average_buy_price\n",
        "    def get_average_sell_price(self):\n",
        "        return self.order_manager.average_sell_price\n",
        "\n",
        "    def get_unrealized_pnl(self):\n",
        "        return self.order_manager.unrealized_pnl\n",
        "\n",
        "\n",
        "    # def calculate_vwap(self):\n",
        "    #     if self.cached_trades_data is not None:\n",
        "    #         return np.average(self.cached_trades_data[:, 0], weights=self.cached_trades_data[:, 1])\n",
        "    #     return None\n",
        "\n",
        "    def calculate_vwap_multi_snapshot(self, trades_data_snapshots):\n",
        "        print(\"trades_data_snapshots:\", trades_data_snapshots)  # Print the contents of trades_data_snapshots\n",
        "        vwap_numerator = 0\n",
        "        total_volume = 0\n",
        "\n",
        "        # Iterate through each trade snapshot (pandas Series)\n",
        "        for trade_data in trades_data_snapshots:\n",
        "            # Extract the 'price' and 'volume' from each Series\n",
        "            price = trade_data.get('price')\n",
        "            volume = trade_data.get('volume')\n",
        "\n",
        "            # Update the vwap numerator and total volume\n",
        "            if price is not None and volume is not None:\n",
        "                vwap_numerator += price * volume\n",
        "                total_volume += volume\n",
        "\n",
        "        # Calculate the VWAP if total_volume is greater than 0\n",
        "        if total_volume > 0:\n",
        "            vwap = vwap_numerator / total_volume\n",
        "        else:\n",
        "            print(\"Total volume is 0, unable to calculate VWAP.\")\n",
        "            vwap = None\n",
        "\n",
        "        return vwap\n",
        "\n",
        "    # def calculate_price_impact(self):\n",
        "    #     if self.cached_trades_data is not None:\n",
        "    #         price_changes = np.diff(self.cached_trades_data[:, 0])\n",
        "    #         volumes = self.cached_trades_data[1:, 1]\n",
        "    #         return price_changes / volumes\n",
        "    #     return None\n",
        "    def calculate_price_impact_multi_snapshot(self, trades_data_snapshots):\n",
        "        price_impacts = []\n",
        "        for i in range(1, len(trades_data_snapshots)):\n",
        "            if isinstance(trades_data_snapshots[i], pd.Series) and isinstance(trades_data_snapshots[i - 1], pd.Series):\n",
        "                price_change = trades_data_snapshots[i]['price'] - trades_data_snapshots[i - 1]['price']\n",
        "                volume = trades_data_snapshots[i]['volume']\n",
        "                price_impacts.append(price_change / volume if volume != 0 else 0)\n",
        "            else:\n",
        "                price_impacts.append(None)\n",
        "        return price_impacts\n",
        "\n",
        "\n",
        "    # ... Additional metrics calculations like order flow ratio, book depth, skewness, etc. ...\n",
        "    # def calculate_order_flow_ratio(self):\n",
        "    #     if self.cached_trades_data is not None:\n",
        "    #         buy_volume = np.sum(self.cached_trades_data[self.cached_trades_data[:, 3] == 1, 1])\n",
        "    #         sell_volume = np.sum(self.cached_trades_data[self.cached_trades_data[:, 3] == -1, 1])\n",
        "    #         order_flow_ratio = buy_volume / sell_volume if sell_volume != 0 else float('inf')\n",
        "    #         return order_flow_ratio\n",
        "    #     return None\n",
        "\n",
        "    def calculate_trade_flow_ratio(self, trades_data_snapshots):\n",
        "        total_buy_volume = 0\n",
        "        total_sell_volume = 0\n",
        "\n",
        "        for trade_data in trades_data_snapshots:\n",
        "            if 'side' in trade_data and 'volume' in trade_data:\n",
        "                trade_side = trade_data['side']\n",
        "                trade_volume = trade_data['volume']\n",
        "\n",
        "                if trade_side == 1:  # Buy trade\n",
        "                    total_buy_volume += trade_volume\n",
        "                elif trade_side == -1:  # Sell trade\n",
        "                    total_sell_volume += trade_volume\n",
        "\n",
        "        # Calculate the trade flow ratio\n",
        "        if total_sell_volume != 0:\n",
        "            trade_flow_ratio = total_buy_volume / total_sell_volume\n",
        "        else:\n",
        "            trade_flow_ratio = 999999 # Avoid division by zero\n",
        "\n",
        "        return trade_flow_ratio\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_book_depth(self):\n",
        "    #     if self.cached_order_book is not None:\n",
        "    #         bid_depth = np.count_nonzero(self.cached_order_book[:, 1])  # Count non-zero bid volumes\n",
        "    #         ask_depth = np.count_nonzero(self.cached_order_book[:, 3])  # Count non-zero ask volumes\n",
        "    #         return bid_depth, ask_depth\n",
        "    #     return None, None\n",
        "\n",
        "    def calculate_most_recent_book_depth(self, order_book_snapshots):\n",
        "        # Directly use the most recent snapshot, assuming it's always present\n",
        "        most_recent_snapshot = order_book_snapshots[-1]\n",
        "        bids, asks = most_recent_snapshot\n",
        "\n",
        "        # Directly calculate depth and volumes, assuming bids and asks are always present\n",
        "        bid_depth = len(bids) if bids else 0\n",
        "        ask_depth = len(asks) if asks else 0\n",
        "        total_depth = bid_depth + ask_depth\n",
        "        best_bid_volume = bids[0][1] if bids else 0\n",
        "        best_ask_volume = asks[0][1] if asks else 0\n",
        "\n",
        "        return {\n",
        "            'total_depth': total_depth,\n",
        "            'bid_depth': bid_depth,\n",
        "            'ask_depth': ask_depth,\n",
        "            'best_bid_volume': best_bid_volume,\n",
        "            'best_ask_volume': best_ask_volume\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_historical_returns(self, prices):\n",
        "    #     returns = np.diff(prices) / prices[:-1]\n",
        "    #     return returns\n",
        "\n",
        "    # # Function to calculate Value at Risk (VaR)\n",
        "    # def calculate_var(self, confidence_level=0.95):\n",
        "    #     if len(self.historical_returns) > 0:\n",
        "    #         sorted_returns = np.sort(self.historical_returns)\n",
        "    #         index = int((1 - confidence_level) * len(sorted_returns))\n",
        "    #         var = sorted_returns[index]\n",
        "    #         return var\n",
        "    #     return None\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_top_two_volumes(self,order_book_snapshots):\n",
        "        most_recent_snapshot = order_book_snapshots[-1]\n",
        "        bids, asks = most_recent_snapshot\n",
        "\n",
        "        # Calculate the volume for the top two levels of bids and asks\n",
        "        # Ensure there are at least two bids and two asks before accessing\n",
        "        bid_volume_top_two = sum(bid[1] for bid in bids[:2]) if len(bids) >= 2 else sum(bid[1] for bid in bids)\n",
        "        ask_volume_top_two = sum(ask[1] for ask in asks[:2]) if len(asks) >= 2 else sum(ask[1] for ask in asks)\n",
        "\n",
        "        return bid_volume_top_two, ask_volume_top_two\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_bid_ask_spread(self):\n",
        "    #     if self.cached_order_book is not None:\n",
        "    #         return self.cached_order_book[0, 2] - self.cached_order_book[0, 0]  # ask - bid\n",
        "    #     return None\n",
        "    def calculate_most_recent_bid_ask_spread(self, order_book_snapshots):\n",
        "        # Directly use the most recent snapshot, assuming it's always present\n",
        "        most_recent_snapshot = order_book_snapshots[-1]\n",
        "        bids, asks = most_recent_snapshot\n",
        "\n",
        "        # Assume bids and asks are always present in the most recent snapshot\n",
        "        best_bid = bids[0][0] if bids else 0\n",
        "        best_ask = asks[0][0] if asks else 0\n",
        "        spread = best_ask - best_bid if bids and asks else 0\n",
        "        half_spread = spread / 2 if spread is not None else 0\n",
        "        mid_price = (best_bid + best_ask) / 2 if bids and asks else 0\n",
        "\n",
        "        return {\n",
        "            'spread': spread,\n",
        "            'best_bid': best_bid,\n",
        "            'best_ask': best_ask,\n",
        "            'half_spread': half_spread,\n",
        "            'mid_price': mid_price\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_order_flow(self):\n",
        "        if self.cached_trades_data is not None:\n",
        "            return np.sum(self.cached_trades_data[:, 1])  # Sum of trade volumes\n",
        "        return None\n",
        "\n",
        "    def calculate_trading_volumes(self):\n",
        "        # Example: Sum of trade volumes over the last N trades\n",
        "        if self.cached_trades_data is not None:\n",
        "            return np.sum(self.cached_trades_data[:, 1][-10:])  # Last 10 trades\n",
        "        return None\n",
        "\n",
        "    # def calculate_weighted_price_volatility(self):\n",
        "    #     # Volatility measure, weighted by volume\n",
        "    #     if self.cached_trades_data is not None:\n",
        "    #         price_changes = np.diff(self.cached_trades_data[:, 0])\n",
        "    #         volumes = self.cached_trades_data[1:, 1]\n",
        "    #         return np.sum(np.abs(price_changes) * volumes)\n",
        "    #     return None\n",
        "\n",
        "    def calculate_weighted_price_volatility_multi_snapshot(self, trades_data_snapshots):\n",
        "        volatilities = []\n",
        "        for i in range(1, len(trades_data_snapshots)):\n",
        "            if isinstance(trades_data_snapshots[i], pd.Series) and isinstance(trades_data_snapshots[i - 1], pd.Series):\n",
        "                price_change = trades_data_snapshots[i]['price'] - trades_data_snapshots[i - 1]['price']\n",
        "                volume = trades_data_snapshots[i]['volume']\n",
        "                volatility = np.abs(price_change) * volume\n",
        "                volatilities.append(volatility)\n",
        "            else:\n",
        "                volatilities.append(None)\n",
        "        return volatilities\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_time_weighted_volume_variability(self):\n",
        "    #     # Variability in volume over time\n",
        "    #     if self.cached_trades_data is not None:\n",
        "    #         average_volume = np.mean(self.cached_trades_data[:, 1])\n",
        "    #         return np.sum(np.abs(self.cached_trades_data[:, 1] - average_volume))\n",
        "    #     return None\n",
        "    def calculate_time_weighted_volume_variability_multi_snapshot(self, trades_data_snapshots):\n",
        "        variabilities = []\n",
        "        for i in range(1, len(trades_data_snapshots)):\n",
        "            if isinstance(trades_data_snapshots[i], pd.Series) and isinstance(trades_data_snapshots[i - 1], pd.Series):\n",
        "                time_diff = trades_data_snapshots[i]['local_timestamp'] - trades_data_snapshots[i - 1]['local_timestamp']\n",
        "                volume_change = trades_data_snapshots[i]['volume'] - trades_data_snapshots[i - 1]['volume']\n",
        "                weighted_variability = np.abs(volume_change) / time_diff if time_diff != 0 else 0\n",
        "                variabilities.append(weighted_variability)\n",
        "            else:\n",
        "                variabilities.append(None)\n",
        "        return variabilities\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_market_imbalance(self):\n",
        "    #     if self.cached_order_book is not None:\n",
        "    #         # Assuming order book format: [bid price, bid volume, ask price, ask volume]\n",
        "    #         total_bid_volume = np.sum(self.cached_order_book[:, 1])  # Sum of all bid volumes\n",
        "    #         total_ask_volume = np.sum(self.cached_order_book[:, 3])  # Sum of all ask volumes\n",
        "\n",
        "    #         market_imbalance = total_bid_volume - total_ask_volume\n",
        "    #         return market_imbalance\n",
        "        # return 0  # Return zero if there's no order book data available\n",
        "    def calculate_market_imbalance_for_recent_snapshot(self, order_book_snapshots):\n",
        "        # Directly use the most recent snapshot, assuming it's always present and valid\n",
        "        recent_order_book = order_book_snapshots[-1]\n",
        "        bids, asks = recent_order_book\n",
        "\n",
        "        total_bid_volume = sum(volume for _, volume in bids) if bids else 0\n",
        "        total_ask_volume = sum(volume for _, volume in asks) if asks else 0\n",
        "\n",
        "        print(f\"Debug: Total Bid Volume for most recent snapshot: {total_bid_volume}\")\n",
        "        print(f\"Debug: Total Ask Volume for most recent snapshot: {total_ask_volume}\")\n",
        "\n",
        "        imbalance = total_bid_volume - total_ask_volume\n",
        "        ratio = total_bid_volume / total_ask_volume if total_ask_volume != 0 else float('inf')\n",
        "\n",
        "        print(f\"Debug: Imbalance for most recent snapshot: {imbalance}\")\n",
        "        print(f\"Debug: Imbalance Ratio for most recent snapshot: {ratio}\")\n",
        "\n",
        "        # Return total bid and ask volume for the most recent snapshot\n",
        "        return total_bid_volume, total_ask_volume\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_sophisticated_liquidity_multi_snapshot(self):\n",
        "        lambda_params = {'alpha': 0.1, 'beta': 0.2, 'gamma': 0.15, 'delta': 0.25, 'epsilon': 0.2, 'zeta': 0.1}\n",
        "\n",
        "        # Get the latest values from each cached metric, default to 0 if not available\n",
        "        market_depth = self.cached_market_depth[-1] if self.cached_market_depth else 0\n",
        "        bid_ask_spread = self.cached_bid_ask_spread[-1] if self.cached_bid_ask_spread else 0\n",
        "        order_flow = self.cached_order_flow[-1] if self.cached_order_flow else 0\n",
        "        market_imbalance = self.cached_market_imbalance[-1] if self.cached_market_imbalance else 0\n",
        "        weighted_price_volatility = self.cached_weighted_price_volatility[-1] if self.cached_weighted_price_volatility else 0\n",
        "        time_weighted_volume_variability = self.cached_time_weighted_volume_variability[-1] if self.cached_time_weighted_volume_variability else 0\n",
        "\n",
        "        # Calculate sophisticated liquidity\n",
        "        L = 1 / (lambda_params['alpha'] * market_depth +\n",
        "                lambda_params['beta'] * bid_ask_spread +\n",
        "                lambda_params['gamma'] * order_flow +\n",
        "                lambda_params['delta'] * market_imbalance +\n",
        "                lambda_params['epsilon'] * weighted_price_volatility +\n",
        "                lambda_params['zeta'] * time_weighted_volume_variability)\n",
        "        return L\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_sophisticated_liquidity(self):\n",
        "    #     if self.cached_order_book is not None:\n",
        "    #         # Define lambda parameters for liquidity calculation\n",
        "    #         lambda_params = {\n",
        "    #             'alpha': 0.1,  # Weight for market depth\n",
        "    #             'beta': 0.2,   # Weight for bid-ask spread\n",
        "    #             'gamma': 0.15, # Weight for order flow\n",
        "    #             'delta': 0.25, # Weight for market imbalance\n",
        "    #             'epsilon': 0.2,# Weight for weighted price volatility\n",
        "    #             'zeta': 0.1    # Weight for time-weighted volume variability\n",
        "    #         }\n",
        "\n",
        "    #         # Calculate individual components of the liquidity measure\n",
        "    #         market_depth = self.calculate_market_depth()\n",
        "    #         bid_ask_spread = self.calculate_bid_ask_spread()\n",
        "    #         order_flow = self.calculate_order_flow()\n",
        "    #         market_imbalance = self.calculate_market_imbalance()\n",
        "    #         weighted_price_volatility = self.calculate_weighted_price_volatility()\n",
        "    #         time_weighted_volume_variability = self.calculate_time_weighted_volume_variability()\n",
        "\n",
        "    #         # Combine terms into the liquidity equation\n",
        "    #         L = 1 / (lambda_params['alpha'] * market_depth +\n",
        "    #                  lambda_params['beta'] * bid_ask_spread +\n",
        "    #                  lambda_params['gamma'] * order_flow +\n",
        "    #                  lambda_params['delta'] * market_imbalance +\n",
        "    #                  lambda_params['epsilon'] * weighted_price_volatility +\n",
        "    #                  lambda_params['zeta'] * time_weighted_volume_variability)\n",
        "\n",
        "    #         return L\n",
        "    #     return None\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_order_flow_rate(self, trades_data, time_interval_seconds):\n",
        "    #     if trades_data.size == 0:\n",
        "    #         return 0\n",
        "\n",
        "    #     sorted_trades = trades_data[trades_data[:, 2].argsort()]\n",
        "    #     time_diffs = np.diff(sorted_trades[:, 2])\n",
        "    #     volume_changes = np.diff(sorted_trades[:, 1])\n",
        "\n",
        "    #     if np.sum(time_diffs) == 0:\n",
        "    #         return 0\n",
        "\n",
        "    #     return np.sum(volume_changes) / np.sum(time_diffs)\n",
        "\n",
        "    def calculate_order_flow_rate_multi_snapshot(self, trades_data_snapshots, time_interval_seconds):\n",
        "        buy_flow_rates = []\n",
        "        sell_flow_rates = []\n",
        "\n",
        "        for i in range(1, len(trades_data_snapshots)):\n",
        "            if isinstance(trades_data_snapshots[i], pd.Series) and isinstance(trades_data_snapshots[i - 1], pd.Series):\n",
        "                time_diff = trades_data_snapshots[i]['local_timestamp'] - trades_data_snapshots[i - 1]['local_timestamp']\n",
        "\n",
        "                if trades_data_snapshots[i]['side'] == 1:  # Buy side\n",
        "                    buy_volume_change = trades_data_snapshots[i]['volume'] - trades_data_snapshots[i - 1]['volume']\n",
        "                    buy_flow_rate = buy_volume_change / time_diff if time_diff != 0 else 0\n",
        "                    buy_flow_rates.append(buy_flow_rate)\n",
        "\n",
        "                elif trades_data_snapshots[i]['side'] == -1:  # Sell side\n",
        "                    sell_volume_change = trades_data_snapshots[i]['volume'] - trades_data_snapshots[i - 1]['volume']\n",
        "                    sell_flow_rate = sell_volume_change / time_diff if time_diff != 0 else 0\n",
        "                    sell_flow_rates.append(sell_flow_rate)\n",
        "\n",
        "        # Append to the deques\n",
        "        self.cached_buy_order_flow_rate.extend(buy_flow_rates)\n",
        "        self.cached_sell_order_flow_rate.extend(sell_flow_rates)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_order_book_skewness(self):\n",
        "    #     if self.cached_order_book is not None:\n",
        "    #         # Assuming order book format: [bid price, bid volume, ask price, ask volume]\n",
        "    #         bid_price_skewness = skew(self.cached_order_book[:, 0])\n",
        "    #         ask_price_skewness = skew(self.cached_order_book[:, 2])\n",
        "    #         return bid_price_skewness, ask_price_skewness\n",
        "    #     return 0, 0  # Return zeros if there's no order book data\n",
        "\n",
        "    # def calculate_order_book_slope(self):\n",
        "    #     if self.cached_order_book is not None:\n",
        "    #         # Calculate slopes for bid and ask sides\n",
        "    #         bid_slope = self._calculate_slope(self.cached_order_book[:, 0], self.cached_order_book[:, 1])\n",
        "    #         ask_slope = self._calculate_slope(self.cached_order_book[:, 2], self.cached_order_book[:, 3])\n",
        "    #         return bid_slope, ask_slope\n",
        "    #     return 0, 0  # Return zeros if there's no order book data\n",
        "\n",
        "\n",
        "    def calculate_order_book_skewness_slope_multi_snapshot(self, order_book_snapshots):\n",
        "        skewnesses, slopes = [], []\n",
        "\n",
        "        for order_book in order_book_snapshots:\n",
        "            if isinstance(order_book, tuple) and len(order_book) == 2:\n",
        "                bids, asks = order_book\n",
        "                bid_prices, bid_volumes = zip(*bids) if bids else ([], [])\n",
        "                ask_prices, ask_volumes = zip(*asks) if asks else ([], [])\n",
        "\n",
        "                bid_skewness = skew(bid_prices) if bid_prices else 0\n",
        "                ask_skewness = skew(ask_prices) if ask_prices else 0\n",
        "                bid_slope = self._calculate_slope(bid_prices, bid_volumes) if bid_prices else 0\n",
        "                ask_slope = self._calculate_slope(ask_prices, ask_volumes) if ask_prices else 0\n",
        "\n",
        "                skewnesses.append((bid_skewness, ask_skewness))\n",
        "                slopes.append((bid_slope, ask_slope))\n",
        "            else:\n",
        "                skewnesses.append((0, 0))\n",
        "                slopes.append((0, 0))\n",
        "\n",
        "        print(\"Debugging calculate_order_book_skewness_slope_multi_snapshot method:\")\n",
        "        print(f\"Skewnesses: {skewnesses}\")\n",
        "        print(f\"Slopes: {slopes}\")\n",
        "        return skewnesses, slopes\n",
        "\n",
        "\n",
        "    def _calculate_slope(self, prices, volumes):\n",
        "        # Linear regression to calculate slope\n",
        "        if len(prices) > 1:\n",
        "            A = np.vstack([prices, np.ones(len(prices))]).T\n",
        "            slope, _ = np.linalg.lstsq(A, volumes, rcond=None)[0]\n",
        "            return slope\n",
        "        return 0\n",
        "\n",
        "\n",
        "    # def update_trade_metrics(self):\n",
        "    #     if self.cached_trades_data is not None:\n",
        "    #         self.last_traded_price = self.cached_trades_data[-1, 0]\n",
        "    #         self.last_trade_volume = self.cached_trades_data[-1, 1]\n",
        "\n",
        "    #         rolling_window_size = 10  # Last 10 trades\n",
        "    #         self.rolling_trade_volume = np.sum(self.cached_trades_data[-rolling_window_size:, 1])\n",
        "\n",
        "    #         current_time = time.time()\n",
        "    #         self.last_trade_timestamp = self.cached_trades_data[-1, 2]\n",
        "    #         self.time_since_last_trade = current_time - self.last_trade_timestamp\n",
        "\n",
        "    #         self.order_flow_rate = self.calculate_order_flow_rate(self.cached_trades_data, time_interval_seconds=60)\n",
        "    def calculate_order_flow_multi_snapshot(self, trades_data_snapshots):\n",
        "        order_flows = []\n",
        "        for trades_data in trades_data_snapshots:\n",
        "            if isinstance(trades_data, pd.DataFrame) and not trades_data.empty:\n",
        "                # Sum the 'volume' column to get the total order flow for this snapshot\n",
        "                total_order_flow = trades_data['volume'].sum()\n",
        "                order_flows.append(total_order_flow)\n",
        "            else:\n",
        "                # If there are no trades in this snapshot, the order flow is 0\n",
        "                order_flows.append(0)\n",
        "        return order_flows\n",
        "\n",
        "\n",
        "\n",
        "    # def calculate_historical_returns_multi_snapshot(self, prices_snapshots):\n",
        "    #     historical_returns = []\n",
        "    #     for prices in prices_snapshots:\n",
        "    #         if len(prices) > 1:\n",
        "    #             returns = np.diff(prices) / prices[:-1]\n",
        "    #             historical_returns.append(returns)\n",
        "    #         else:\n",
        "    #             historical_returns.append(None)\n",
        "    #     return historical_returns\n",
        "\n",
        "    # def calculate_var_multi_snapshot(self, historical_returns_snapshots, confidence_level=0.95):\n",
        "    #     vars = []\n",
        "    #     for returns in historical_returns_snapshots:\n",
        "    #         if len(returns) > 0:\n",
        "    #             sorted_returns = np.sort(returns)\n",
        "    #             index = int((1 - confidence_level) * len(sorted_returns))\n",
        "    #             var = sorted_returns[index]\n",
        "    #             vars.append(var)\n",
        "    #         else:\n",
        "    #             vars.append(None)\n",
        "    #     return vars\n",
        "\n",
        "\n",
        "    # def update_cached_metrics(self):\n",
        "    #     self.cached_trades_data = self.order_book_cache.latest_trades_data\n",
        "\n",
        "    #     if self.is_trade_data_updated:\n",
        "    #         # Update trade-related metrics\n",
        "    #         self.cached_vwap = self.calculate_vwap()\n",
        "    #         self.cached_price_impact = self.calculate_price_impact()\n",
        "    #         self.cached_var = self.calculate_var(0.95)  # Example: 95% confidence level\n",
        "    #         self.cached_order_flow_ratio = self.calculate_order_flow_ratio()\n",
        "    #         self.update_trade_metrics()\n",
        "\n",
        "    #         # Additional metrics calculations\n",
        "    #         self.cached_order_flow = self.calculate_order_flow()\n",
        "    #         self.cached_trading_volumes = self.calculate_trading_volumes()\n",
        "    #         self.cached_weighted_price_volatility = self.calculate_weighted_price_volatility()\n",
        "    #         self.cached_time_weighted_volume_variability = self.calculate_time_weighted_volume_variability()\n",
        "\n",
        "    #         # Reset the flag\n",
        "    #         self.is_trade_data_updated = False\n",
        "\n",
        "    def update_trade_metrics(self, trades_data_snapshots):\n",
        "        # Assuming each item in trades_data_snapshots is a pandas Series representing a trade\n",
        "        if len(trades_data_snapshots) == 0:\n",
        "            print(\"No trades in this batch\")\n",
        "            return 0\n",
        "\n",
        "        # Process the trade data\n",
        "        prices = []\n",
        "        volumes = []\n",
        "        for trade_data in trades_data_snapshots:\n",
        "            trade_price = trade_data['price']  # Accessing price directly\n",
        "            trade_volume = trade_data['volume']  # Accessing volume directly\n",
        "            prices.append(trade_price)\n",
        "            volumes.append(trade_volume)\n",
        "\n",
        "        # Calculate metrics based on prices and volumes\n",
        "        # ...\n",
        "\n",
        "        # Example: Calculate metrics based on the last two trades\n",
        "        if len(prices) >= 2:\n",
        "            last_price = prices[-1]\n",
        "            last_volume = volumes[-1]\n",
        "            second_last_price = prices[-2]\n",
        "            second_last_volume = volumes[-2]\n",
        "\n",
        "            if second_last_price != 0 and second_last_volume != 0:\n",
        "                self.difference_traded_price = ((last_price - second_last_price) / second_last_price) * 100\n",
        "                self.difference_trade_volume = ((last_volume - second_last_volume) / second_last_volume) * 100\n",
        "            else:\n",
        "                self.difference_traded_price = None\n",
        "                self.difference_trade_volume = None\n",
        "        else:\n",
        "            self.difference_traded_price = None\n",
        "            self.difference_trade_volume = None\n",
        "\n",
        "        # Calculate and append additional metrics\n",
        "        # ...\n",
        "        self.cached_vwap = self.calculate_vwap_multi_snapshot(trades_data_snapshots)\n",
        "        # price_impacts = self.calculate_price_impact_multi_snapshot(trades_data_snapshots)\n",
        "        # #order_flow_ratios = self.calculate_order_flow_ratio_multi_snapshot(trades_data_snapshots)\n",
        "        # time_weighted_volume_variabilities = self.calculate_time_weighted_volume_variability_multi_snapshot(trades_data_snapshots)\n",
        "        # weighted_price_volatilities = self.calculate_weighted_price_volatility_multi_snapshot(trades_data_snapshots)\n",
        "        self.calculate_order_flow_rate_features(trades_data_snapshots, time_interval_seconds=60)\n",
        "        # order_flows = self.calculate_order_flow_multi_snapshot(trades_data_snapshots)\n",
        "\n",
        "        # # Append to the deques\n",
        "        # self.cached_vwap.extend(vwaps)\n",
        "        # self.cached_price_impact.extend(price_impacts)\n",
        "        # #self.cached_order_flow_ratio.extend(order_flow_ratios)\n",
        "        # self.cached_time_weighted_volume_variability.extend(time_weighted_volume_variabilities)\n",
        "        # self.cached_weighted_price_volatility.extend(weighted_price_volatilities)\n",
        "        # #self.cached_order_flow_rate.extend(order_flow_rates)\n",
        "        # # self.cached_order_flow.extend(order_flows)\n",
        "\n",
        "        # Calculate rolling trade volume for a window of 5 snapshots\n",
        "\n",
        "        # rolling_trade_volumes = []\n",
        "\n",
        "        # for i in range(len(trades_data_snapshots)):\n",
        "        #     if i >= 4:  # Ensure there are at least 5 data points\n",
        "        #         start_index = i - 4  # Fixed window size of 5 data points\n",
        "        #         rolling_window = trades_data_snapshots[start_index:i + 1]\n",
        "\n",
        "        #         # Calculate the total trade volume within the rolling window\n",
        "        #         total_volume = sum(trades_data['volume'] for trades_data in rolling_window if not trades_data.empty)\n",
        "\n",
        "        #         # Calculate rolling average\n",
        "        #         rolling_average = total_volume / 5  # Fixed size of the rolling window\n",
        "        #         rolling_trade_volumes.append(rolling_average)\n",
        "\n",
        "\n",
        "\n",
        "        #         print(f\"Debug: Window {start_index}-{i}, Rolling Average Volume: {rolling_average}\")  # Debugging line\n",
        "\n",
        "        # self.rolling_trade_volume.extend(rolling_trade_volumes)\n",
        "\n",
        "\n",
        "        print(f\"Difference traded price: {self.difference_traded_price}, Difference trade volume: {self.difference_trade_volume}\")\n",
        "        print(\"Finished updating trade metrics\")\n",
        "        return 1, last_price\n",
        "\n",
        "\n",
        "    # def update_cached_order_book_metrics(self):\n",
        "    #     self.cached_order_book = self.order_book_cache.latest_order_book_data\n",
        "\n",
        "    #     if self.is_order_book_updated:\n",
        "    #         # Update order book-related metrics\n",
        "    #         bid_depth, ask_depth = self.calculate_book_depth()\n",
        "    #         self.cached_bid_depth = bid_depth\n",
        "    #         self.cached_ask_depth = ask_depth\n",
        "    #         self.best_bid_price = self.cached_order_book[0, 0] if self.cached_order_book is not None else 0\n",
        "    #         self.best_ask_price = self.cached_order_book[0, 2] if self.cached_order_book is not None else 0\n",
        "\n",
        "\n",
        "    #         # Additional market metrics\n",
        "    #         self.cached_market_imbalance = self.calculate_market_imbalance()\n",
        "    #         self.cached_market_depth = self.calculate_market_depth()\n",
        "    #         self.cached_bid_ask_spread = self.calculate_bid_ask_spread()\n",
        "\n",
        "    #         # Reset the flag\n",
        "    #         self.is_order_book_updated = False\n",
        "    import sys\n",
        "    def update_cached_order_book_metrics(self, order_book_snapshots):\n",
        "\n",
        "        book_depth_data = self.calculate_most_recent_book_depth(order_book_snapshots)\n",
        "        # Extracting additional data from book_depth_data\n",
        "        total_depths = book_depth_data['total_depth']\n",
        "        bid_depths = book_depth_data['bid_depth']\n",
        "        ask_depths = book_depth_data['ask_depth']\n",
        "        best_bid_volumes = book_depth_data['best_bid_volume']\n",
        "        best_ask_volumes = book_depth_data['best_ask_volume']\n",
        "\n",
        "        bid_ask_spread_data = self.calculate_most_recent_bid_ask_spread(order_book_snapshots)\n",
        "        spreads = bid_ask_spread_data['spread']\n",
        "        best_bids = bid_ask_spread_data['best_bid']\n",
        "        best_asks = bid_ask_spread_data['best_ask']\n",
        "        half_spreads = bid_ask_spread_data['half_spread']\n",
        "        mid_prices = bid_ask_spread_data['mid_price']\n",
        "\n",
        "        # Additional calculations\n",
        "        total_bid_volume, total_ask_volume = self.calculate_market_imbalance_for_recent_snapshot(order_book_snapshots)\n",
        "\n",
        "        top_two_bid_levels_volume, top_two_ask_levels_volume = self.calculate_top_two_volumes(order_book_snapshots)\n",
        "\n",
        "        # Calculate skewness and slope for bids and asks\n",
        "\n",
        "        # skewness_slope_output = self.calculate_order_book_skewness_slope_multi_snapshot(order_book_snapshots)\n",
        "\n",
        "        # # Unpack the skewness and slope data\n",
        "        # bid_ask_skewnesses, bid_ask_slopes = skewness_slope_output\n",
        "        # bid_skewnesses, ask_skewnesses = zip(*bid_ask_skewnesses)\n",
        "        # bid_slopes, ask_slopes = zip(*bid_ask_slopes)\n",
        "\n",
        "        # # Append the bid and ask skewnesses and slopes to the deques\n",
        "        # self.cached_bid_skewness.extend(bid_skewnesses)\n",
        "        # self.cached_ask_skewness.extend(ask_skewnesses)\n",
        "        # self.cached_bid_slope.extend(bid_slopes)\n",
        "        # self.cached_ask_slope.extend(ask_slopes)\n",
        "\n",
        "        # Append to the deques (assuming these deques are defined elsewhere in your class)\n",
        "        self.cached_market_depth= total_depths\n",
        "        self.cached_best_bid_volume = best_bid_volumes\n",
        "        self.cached_best_ask_volume = best_ask_volumes\n",
        "\n",
        "        self.cached_bid_depth = bid_depths\n",
        "        self.cached_ask_depth = ask_depths\n",
        "        self.cached_bid_ask_spread = spreads\n",
        "        self.cached_total_bid_volume = total_bid_volume\n",
        "        self.cached_total_ask_volume= total_ask_volume\n",
        "        #self.cached_order_book_skewness.extend(book_skewnesses)\n",
        "        #self.cached_order_book_slope.extend(book_slopes)\n",
        "        self.cached_best_bid_price = best_bids\n",
        "        self.cached_best_ask_price = best_asks\n",
        "        self.cached_half_spread = half_spreads\n",
        "        self.cached_mid_price = mid_prices\n",
        "\n",
        "        self.cached_top_two_ask_levels_volume = top_two_ask_levels_volume\n",
        "        self.cached_top_two_bid_levels_volume = top_two_bid_levels_volume\n",
        "\n",
        "\n",
        "    def update_position(self, trade_volume, trade_price, is_buy):\n",
        "        if is_buy:\n",
        "            total_cost = self.average_buy_price * self.inventory_level\n",
        "            total_cost += trade_volume * trade_price\n",
        "            self.inventory_level += trade_volume\n",
        "            self.average_buy_price = total_cost / self.inventory_level if self.inventory_level else 0\n",
        "        else:\n",
        "            # Update for sell transaction\n",
        "            self.inventory_level -= trade_volume\n",
        "            self.total_sell_revenue += trade_volume * trade_price\n",
        "            self.average_sell_price = self.total_sell_revenue / (self.original_inventory_level - self.inventory_level) if self.inventory_level < self.original_inventory_level else 0\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_unrealized_pnl(self, current_market_price):\n",
        "        market_value = self.inventory_level * current_market_price\n",
        "        cost_basis = self.inventory_level * self.average_buy_price\n",
        "        return market_value - cost_basis\n",
        "\n",
        "    # def calculate_time_since_last_trade(self, trades_data):\n",
        "    #     if trades_data.size > 0:\n",
        "    #         # Assuming the timestamp is in the third column\n",
        "    #         last_trade_timestamp = trades_data[-1, 2]\n",
        "    #         current_time = time.time()\n",
        "    #         time_since_last_trade = current_time - last_trade_timestamp\n",
        "    #         return time_since_last_trade\n",
        "    #     else:\n",
        "    #         return None  # Or a suitable default value if there are no trades\n",
        "\n",
        "    def calculate_time_between_last_two_trades(self, trades_data):\n",
        "        if trades_data.shape[0] >= 2:\n",
        "            # Assuming the timestamp is in the third column\n",
        "            last_trade_timestamp = trades_data[-1, 2]\n",
        "            second_last_trade_timestamp = trades_data[-2, 2]\n",
        "            time_diff = last_trade_timestamp - second_last_trade_timestamp\n",
        "            return time_diff\n",
        "        else:\n",
        "            return None  # Return None or a suitable default if there are fewer than two trades\n",
        "\n",
        "    # def preprocess_feature(self, feature, index):\n",
        "    #     if index in [8, 9, 10]:  # Price features\n",
        "    #         return np.log(feature / self.previous_state[index])\n",
        "    #     elif index in [0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17]:  # Volume and other features\n",
        "    #         return (feature - self.state_mean[index]) / self.state_std[index]\n",
        "    #     else:\n",
        "    #         return feature  # Other features that don't need preprocessing\n",
        "    # def preprocess_feature(self, feature):\n",
        "    #     median = np.median(feature)\n",
        "    #     mad = np.median([np.abs(val - median) for val in feature])\n",
        "\n",
        "    #     # Avoid division by zero\n",
        "    #     if mad != 0:\n",
        "    #         modified_z_score = [0.6745 * (val - median) / mad for val in feature]\n",
        "    #     else:\n",
        "    #         modified_z_score = feature  # or handle as needed\n",
        "\n",
        "    #     return modified_z_score\n",
        "    # def preprocess_feature_with_robust_scaling(self, feature, feature_name):\n",
        "\n",
        "    #     # Check and print if the feature is None\n",
        "    #     if feature is None:\n",
        "    #         print(f\"Feature '{feature_name}' is None\")\n",
        "    #         return []\n",
        "\n",
        "\n",
        "    #     # Calculate the median\n",
        "    #     median = np.median(feature)\n",
        "\n",
        "    #     # Calculate the interquartile range (IQR)\n",
        "    #     Q1 = np.percentile(feature, 25)\n",
        "    #     Q3 = np.percentile(feature, 75)\n",
        "    #     IQR = Q3 - Q1\n",
        "\n",
        "    #     # Avoid division by zero in IQR\n",
        "    #     if IQR != 0:\n",
        "    #         scaled_feature = [(val - median) / IQR for val in feature]\n",
        "    #     else:\n",
        "    #         scaled_feature = feature  # or handle as needed\n",
        "\n",
        "    #     return scaled_feature\n",
        "    def calculate_ema(self,data, period):\n",
        "        alpha = 2 / (period + 1)\n",
        "        ema = data[0]  # Initialize EMA with the first data point\n",
        "        for value in data[1:]:\n",
        "            ema = (value * alpha) + (ema * (1 - alpha))\n",
        "        return ema\n",
        "\n",
        "    def calculate_cv(self,data):\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "        return std_dev / mean if mean != 0 else 0  # Using 0 instead of float('inf') for practicality\n",
        "\n",
        "    def calculate_order_flow_rate_features(self, trades_data_snapshots, time_interval_seconds):\n",
        "        buy_flow_rates = []\n",
        "        sell_flow_rates = []\n",
        "\n",
        "        if not trades_data_snapshots:\n",
        "            print(\"Debug: trades_data_snapshots is empty\")\n",
        "            return\n",
        "\n",
        "        print(f\"Debug: Processing {len(trades_data_snapshots)} trades data snapshots\")\n",
        "\n",
        "        for i in range(1, len(trades_data_snapshots)):\n",
        "            time_diff = (trades_data_snapshots[i]['local_timestamp'] - trades_data_snapshots[i - 1]['local_timestamp']) / 1000\n",
        "\n",
        "            if time_diff == 0:\n",
        "                print(f\"Debug: Time difference is 0 at index {i}\")\n",
        "\n",
        "            if trades_data_snapshots[i]['side'] == 1:  # Buy side\n",
        "                buy_volume_change = trades_data_snapshots[i]['volume'] - trades_data_snapshots[i - 1].get('volume', 0)\n",
        "                if time_diff != 0:\n",
        "                    buy_flow_rate = buy_volume_change / time_diff\n",
        "                    buy_flow_rates.append(buy_flow_rate)\n",
        "                    print(f\"Debug: Added buy flow rate {buy_flow_rate} at index {i}\")\n",
        "\n",
        "            elif trades_data_snapshots[i]['side'] == -1:  # Sell side\n",
        "                sell_volume_change = trades_data_snapshots[i]['volume'] - trades_data_snapshots[i - 1].get('volume', 0)\n",
        "                if time_diff != 0:\n",
        "                    sell_flow_rate = sell_volume_change / time_diff\n",
        "                    sell_flow_rates.append(sell_flow_rate)\n",
        "                    print(f\"Debug: Added sell flow rate {sell_flow_rate} at index {i}\")\n",
        "\n",
        "        if not buy_flow_rates:\n",
        "            print(\"Debug: buy_flow_rates list is empty\")\n",
        "\n",
        "        if not sell_flow_rates:\n",
        "            print(\"Debug: sell_flow_rates list is empty\")\n",
        "\n",
        "        # Proceed with EMA and CV calculations\n",
        "        self.cached_ema_buy = self.calculate_ema(buy_flow_rates, len(buy_flow_rates)) if buy_flow_rates else None\n",
        "        self.cached_ema_sell = self.calculate_ema(sell_flow_rates, len(sell_flow_rates)) if sell_flow_rates else None\n",
        "        self.cached_cv_buy = self.calculate_cv(buy_flow_rates) if buy_flow_rates else None\n",
        "        self.cached_cv_sell = self.calculate_cv(sell_flow_rates) if sell_flow_rates else None\n",
        "\n",
        "        print(f\"Debug: Cached EMA/CV values calculated for buy and sell flow rates\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_avg_entry_price_deviation_ratio(self, avg_entry_price, reference_price, nameoffeature):\n",
        "        \"\"\"\n",
        "        Calculate the ratio of the average entry price deviation to a given reference price.\n",
        "\n",
        "        :param avg_entry_price: The average entry price of positions.\n",
        "        :param reference_price: The reference price for comparison.\n",
        "        :return: Ratio of average entry price deviation to the reference price.\n",
        "        \"\"\"\n",
        "        print(f\"Name of Feature: {nameoffeature}\")\n",
        "        if avg_entry_price is None or  avg_entry_price == 0:\n",
        "            print(f\"Average entry price: {avg_entry_price}\")\n",
        "            print(f\"Reference price: {reference_price}\")\n",
        "            return 0\n",
        "\n",
        "        # Calculate the absolute deviation and deviation ratio\n",
        "        print(f\"Average entry price: {avg_entry_price}\")\n",
        "        print(f\"Reference price: {reference_price}\")\n",
        "        absolute_deviation = abs(avg_entry_price - reference_price)\n",
        "        deviation_ratio = absolute_deviation / reference_price if reference_price != 0 else 0\n",
        "        return deviation_ratio\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def normalized_log_distance(self, x, y, feature_name, min_possible_distance=0, max_possible_distance=20):\n",
        "        epsilon = 1e-10  # Small positive value to avoid log(0)\n",
        "        print(f\"feature_name: {feature_name}, x: {x}, y: {y}\")\n",
        "\n",
        "        # Ensure x and y are positive for logarithm; use epsilon as a substitute for non-positive values\n",
        "        x_safe = max(x, epsilon)\n",
        "        y_safe = max(y, epsilon)\n",
        "        log_distance = abs(np.log(x_safe) - np.log(y_safe))\n",
        "        print(f\"log_distance: {log_distance}\")\n",
        "\n",
        "        # Normalize and ensure within [0, 1]\n",
        "        normalized_distance = (log_distance - min_possible_distance) / (max_possible_distance - min_possible_distance)\n",
        "        normalized_distance = max(0, min(1, normalized_distance))\n",
        "\n",
        "        return normalized_distance\n",
        "\n",
        "\n",
        "    def calculate_normalized_weighted_avg_price_spread(self, average_buy_price, average_sell_price, current_mid_price):\n",
        "        \"\"\"\n",
        "        Calculate the normalized weighted spread between the average buy price and average sell price,\n",
        "        expressed as a percentage of the current mid-price.\n",
        "        \"\"\"\n",
        "        if current_mid_price != 0:\n",
        "            normalized_buy_spread = (average_buy_price - current_mid_price) / current_mid_price\n",
        "            normalized_sell_spread = (average_sell_price - current_mid_price) / current_mid_price\n",
        "\n",
        "            # Calculate the normalized weighted spread as the average of buy and sell spreads\n",
        "            weighted_spread = self.normalized_log_distance(normalized_buy_spread, normalized_sell_spread, 'normalized_weighted_avg_price_spread')\n",
        "\n",
        "            # Calculate the weighted spread as a percentage of the current mid-price\n",
        "\n",
        "        else:\n",
        "            weighted_spread = float('inf')\n",
        "\n",
        "        return weighted_spread\n",
        "\n",
        "    def ema_calculate_aggregated_features(self, data):\n",
        "        \"\"\"\n",
        "        Calculate aggregated statistical features for a given list of data points.\n",
        "        Return all zeros if any nan values are detected after calculations.\n",
        "        :param data: List of data points (e.g., price ticks, trade volumes)\n",
        "        :return: Array of aggregated features with individual quantiles\n",
        "        \"\"\"\n",
        "        data = np.array(data)  # Ensure data is a NumPy array for processing\n",
        "        ema = self.calculate_ema_for_aggregation(data, .7)\n",
        "        std_dev = np.std(data)\n",
        "        cv = std_dev / ema if ema != 0 else 0\n",
        "        skewness = skew(data, nan_policy='omit')\n",
        "        kurt = kurtosis(data, nan_policy='omit')\n",
        "        q25, q50, q75 = np.percentile(data, [25, 50, 75])\n",
        "        min_value = np.min(data)\n",
        "        max_value = np.max(data)\n",
        "        min_max_ratio = min_value / max_value if max_value != 0 else 0\n",
        "\n",
        "        aggregated_features = [\n",
        "            ema,\n",
        "            std_dev,\n",
        "            cv,\n",
        "            skewness,\n",
        "            kurt,\n",
        "            q25,\n",
        "            q50,\n",
        "            q75,\n",
        "            min_max_ratio\n",
        "        ]\n",
        "\n",
        "        # Check if any value in aggregated_features is nan and return zeros if true\n",
        "        if np.isnan(aggregated_features).any():\n",
        "            return [0] * 9\n",
        "        else:\n",
        "            return aggregated_features\n",
        "\n",
        "\n",
        "    def calculate_aggregated_features(self,data):\n",
        "        \"\"\"\n",
        "        Calculate aggregated statistical features for a given list of data points.\n",
        "        :param data: List of data points (e.g., price ticks, trade volumes)\n",
        "        :return: Array of aggregated features with individual quantiles\n",
        "        \"\"\"\n",
        "        if not data:\n",
        "            return [0] * 9  # Return an array of None values for each feature\n",
        "\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "        cv = std_dev / mean if mean != 0 else 0  # Coefficient of Variation\n",
        "        skewness = skew(data)\n",
        "        kurt = kurtosis(data)\n",
        "\n",
        "        # Calculate individual quantiles\n",
        "        q25, q50, q75 = np.percentile(data, [25, 50, 75])  # 25th, 50th, 75th percentile\n",
        "        min_value = np.min(data)\n",
        "        max_value = np.max(data)\n",
        "        min_max_ratio = min_value / max_value if max_value != 0 else 0\n",
        "\n",
        "        return [\n",
        "            mean,\n",
        "            std_dev,\n",
        "            cv,\n",
        "            skewness,\n",
        "            kurt,\n",
        "            q25,\n",
        "            q50,\n",
        "            q75,\n",
        "            min_max_ratio\n",
        "        ]\n",
        "\n",
        "    def calculate_ema_for_aggregation(self, data, alpha):\n",
        "        \"\"\"Calculate the Exponential Moving Average (EMA) for a given list of data points.\"\"\"\n",
        "        ema = data[0]\n",
        "        for value in data[1:]:\n",
        "            ema = alpha * value + (1 - alpha) * ema\n",
        "        return ema\n",
        "\n",
        "    def preprocess_feature_with_robust_scaling(self, feature, feature_name):\n",
        "        # Print the entire feature and its name\n",
        "        print(f\"Feature '{feature_name}': {feature}\")\n",
        "\n",
        "        # Check and print if the entire feature is None\n",
        "        if feature is None:\n",
        "            print(f\"Feature '{feature_name}' is None\")\n",
        "            return []\n",
        "\n",
        "        # Filter out None values from the feature list\n",
        "        filtered_feature = [f for f in feature if f is not None]\n",
        "\n",
        "        # Print the filtered feature\n",
        "        print(f\"Filtered '{feature_name}': {filtered_feature}\")\n",
        "\n",
        "        if len(filtered_feature) > 0:\n",
        "            # Calculate the median of the filtered feature\n",
        "            median = np.median(filtered_feature)\n",
        "\n",
        "            # Calculate the interquartile range (IQR)\n",
        "            q75, q25 = np.percentile(filtered_feature, [75, 25])\n",
        "            iqr = q75 - q25\n",
        "\n",
        "            # Scale features using robust scaling\n",
        "            scaled_feature = [(f - median) / iqr if iqr != 0 else 0 for f in filtered_feature]\n",
        "            print(f\"Scaled '{feature_name}': {scaled_feature}\")\n",
        "            return scaled_feature\n",
        "        else:\n",
        "            # Return an empty list if all values were None or feature was empty\n",
        "            return []\n",
        "\n",
        "    def z_score_normalize(self, value, mean, std_dev):\n",
        "        return (value - mean) / std_dev if std_dev != 0 else 0\n",
        "\n",
        "    def extend_to_length(self, value, length):\n",
        "        \"\"\"Extend a scalar value to a list of a specified length.\"\"\"\n",
        "        return [value] * length\n",
        "\n",
        "    def replace_nans_with_zeros(self, array):\n",
        "        \"\"\"\n",
        "        Replace nan values in the array with zeros.\n",
        "        \"\"\"\n",
        "        clean_array = np.nan_to_num(array)\n",
        "        return clean_array\n",
        "\n",
        "    def construct_state_vector(self, current_order_book, current_trades, current_time):\n",
        "        # Update metrics based on the type of data\n",
        "        print(f\"Current Order_Book: {current_order_book}\")\n",
        "        print(f\"Current Trades: {current_trades}\")\n",
        "        print(f\"Current Time: {current_time}\")\n",
        "        self.update_cached_order_book_metrics(current_order_book)\n",
        "        check, last_price = self.update_trade_metrics(current_trades)\n",
        "        if check == 0:\n",
        "            print(\"No trades in this batch\")\n",
        "            return 0, None\n",
        "        else:\n",
        "\n",
        "            current_position = self.get_current_position()\n",
        "\n",
        "            if current_position == 0:\n",
        "                inventory_side = 0\n",
        "            elif current_position > 0:\n",
        "                inventory_side = 1\n",
        "            else :\n",
        "                inventory_side = -1\n",
        "\n",
        "            current_inventory = self.order_manager.inventory\n",
        "            total_active_order_value = self.order_manager.calculate_combined_inventory_and_orders_value()\n",
        "            # Calculate the mean and standard deviation of the price\n",
        "            average_buy_price = self.get_average_buy_price()\n",
        "            average_sell_price = self.get_average_sell_price()\n",
        "            #order_flow_ratio = self.calculate_order_flow_ratio(current_trades)\n",
        "\n",
        "            # unrealized_pnl = self.get_unrealized_pnl()\n",
        "            rate_percentage = self.rate_limiter.get_usage_percentage()\n",
        "\n",
        "            # one_minute_mad = self.volatility_manager.get_mad_volatility_measures().get(\"1m\", 0)\n",
        "            # seven_minute_mad = self.volatility_manager.get_mad_volatility_measures().get(\"7m\", 0)\n",
        "            # sixty_minute_mad = self.volatility_manager.get_mad_volatility_measures().get(\"60m\", 0)\n",
        "            # print(f\"MADs: {one_minute_mad}, {seven_minute_mad}, {sixty_minute_mad}\")\n",
        "            # Example data retrieval (assuming you have methods to get these values)\n",
        "\n",
        "            own_best_bid, own_worst_bid, own_best_bid_volume = self.order_manager.get_best_and_worst_bid_with_total_volume()\n",
        "            if own_best_bid is None:\n",
        "                own_best_bid = 0\n",
        "                own_best_bid_volume = 0\n",
        "            own_best_ask, own_worst_ask, own_best_ask_volume = self.order_manager.get_best_and_worst_ask_with_total_volume()\n",
        "            if own_best_ask is None:\n",
        "                own_best_ask = 0\n",
        "                own_best_ask_volume = 0\n",
        "\n",
        "            if own_worst_bid is None:\n",
        "                own_worst_bid = 0\n",
        "            if own_worst_ask is None:\n",
        "                own_worst_ask = 0\n",
        "\n",
        "            # Calculate the ratio\n",
        "\n",
        "\n",
        "            # Calculate the ratio\n",
        "            #\n",
        "            state = []\n",
        "\n",
        "            AUM_unit_size = self.initial_capital / last_price\n",
        "\n",
        "            # top_two_ask_levels_volume = self.calculate_top_two_volumes()\n",
        "            # top_two_bid_levels_volume = self.calculate_top_two_volumes()\n",
        "\n",
        "            # Calculate the ratios\n",
        "\n",
        "            current_best_bid = self.cached_best_bid_price\n",
        "            current_best_ask = self.cached_best_ask_price\n",
        "            print(\"Checking DEMAs and MADs:\")\n",
        "\n",
        "            # DEMAs Checks\n",
        "            one_minute_dema = self.volatility_manager.get_one_minute_dema()\n",
        "            print(f\"Initial one_minute_dema: {one_minute_dema}\")\n",
        "            if not one_minute_dema:  # Checks if one_minute_dema is None or 0\n",
        "                one_minute_dema = last_price\n",
        "                print(\"one_minute_dema was None or 0, replaced with last_price:\", last_price)\n",
        "\n",
        "            seven_minute_dema = self.volatility_manager.get_seven_minute_dema()\n",
        "            print(f\"Initial seven_minute_dema: {seven_minute_dema}\")\n",
        "            if not seven_minute_dema:  # Checks if seven_minute_dema is None or 0\n",
        "                seven_minute_dema = last_price\n",
        "                print(\"seven_minute_dema was None or 0, replaced with last_price:\", last_price)\n",
        "\n",
        "            thirty_five_minute_dema = self.volatility_manager.get_thirty_five_minute_dema()\n",
        "            print(f\"Initial thirty_five_minute_dema: {thirty_five_minute_dema}\")\n",
        "            if not thirty_five_minute_dema:  # Checks if thirty_five_minute_dema is None or 0\n",
        "                thirty_five_minute_dema = last_price\n",
        "                print(\"thirty_five_minute_dema was None or 0, replaced with last_price:\", last_price)\n",
        "\n",
        "            trend_direction = 1 if seven_minute_dema > thirty_five_minute_dema else -1\n",
        "            deviation =(seven_minute_dema/thirty_five_minute_dema - 1) * 100\n",
        "            if inventory_side == trend_direction:\n",
        "                # Example: scale reward by deviation, with a minimum deviation threshold\n",
        "                min_deviation_threshold = 0.17  # Example threshold for considering the trend\n",
        "                if deviation > min_deviation_threshold:\n",
        "                    self.alignment_reward = abs(current_inventory) * last_price * deviation * 0.17  # Example scaling\n",
        "                else:\n",
        "                    self.alignment_reward = 0\n",
        "            else:\n",
        "                self.alignment_reward = 0\n",
        "\n",
        "            # MADs Checks\n",
        "            # Getting MAD volatilities\n",
        "            mad_volatilities = self.volatility_manager.get_mad_volatility_measures()\n",
        "\n",
        "            # Print statements for MADs\n",
        "            print(\"Retrieved MAD Volatilities:\")\n",
        "            for time_frame, mad in mad_volatilities.items():\n",
        "                print(f\"{time_frame} MAD: {mad if mad is not None else 0}\")\n",
        "\n",
        "            my_best_bid_to_ask_volume_ratio = self.calculate_avg_entry_price_deviation_ratio(own_best_bid_volume, own_best_ask_volume, 'my_best_bid_to_ask_volume_ratio')\n",
        "            my_best_bid_to_ask_volume_log_distance = self.normalized_log_distance(own_best_bid_volume, own_best_ask_volume, 'my_best_bid_to_ask_volume_log_distance')\n",
        "            state.append(my_best_bid_to_ask_volume_log_distance)\n",
        "            state.append(my_best_bid_to_ask_volume_ratio)\n",
        "\n",
        "            my_best_bid_volume_to_market_best_volume = self.normalized_log_distance(own_best_bid_volume, self.cached_best_bid_volume, 'log_distance_my_best_bid_volume_to_market_best_volume')\n",
        "            my_best_ask_volume_to_market_best_volume = self.normalized_log_distance(own_best_ask_volume, self.cached_best_ask_volume, 'log_distance_my_best_ask_volume_to_market_best_volume')\n",
        "            state.append(my_best_bid_volume_to_market_best_volume)\n",
        "            state.append(my_best_ask_volume_to_market_best_volume)\n",
        "\n",
        "            my_worst_bid_to_market_best_bid_log_distance = self.normalized_log_distance(own_worst_bid, self.cached_best_bid_price, 'my_worst_bid_to_market_best_bid_log_distance')\n",
        "            my_worst_ask_to_market_best_ask_log_distance = self.normalized_log_distance(own_worst_ask, self.cached_best_ask_price, 'my_worst_ask_to_market_best_ask_log_distance')\n",
        "            state.append(my_worst_bid_to_market_best_bid_log_distance)\n",
        "            state.append(my_worst_ask_to_market_best_ask_log_distance)\n",
        "            my_worst_bid_to_my_best_bid_log_distance = self.normalized_log_distance(own_worst_bid, own_best_bid, 'my_worst_bid_to_my_best_bid_log_distance')\n",
        "            my_worst_ask_to_my_best_ask_log_distance = self.normalized_log_distance(own_worst_ask, own_best_ask, 'my_worst_ask_to_my_best_ask_log_distance')\n",
        "            state.append(my_worst_bid_to_my_best_bid_log_distance)\n",
        "            state.append(my_worst_ask_to_my_best_ask_log_distance)\n",
        "            my_best_bid_to_current_log_distance = self.normalized_log_distance(own_best_bid, current_best_bid, 'my_best_bid_to_current_log_distance')\n",
        "            my_best_ask_to_current_log_distance = self.normalized_log_distance(own_best_ask, current_best_ask, 'my_best_ask_to_current_log_distance')\n",
        "            state.append(my_best_bid_to_current_log_distance)\n",
        "            state.append(my_best_ask_to_current_log_distance)\n",
        "\n",
        "            #\n",
        "            average_buy_to_best_bid_ratio = self.calculate_avg_entry_price_deviation_ratio(average_buy_price, current_best_bid, 'average_buy_to_best_bid_ratio')\n",
        "            average_sell_to_best_ask_ratio = self.calculate_avg_entry_price_deviation_ratio(average_sell_price, current_best_ask, 'average_sell_to_best_ask_ratio')\n",
        "            state.append(average_buy_to_best_bid_ratio)\n",
        "            state.append(average_sell_to_best_ask_ratio)\n",
        "\n",
        "            #\n",
        "            average_buy_to_best_bid_log_distance = self.normalized_log_distance(average_buy_price, current_best_bid, 'average_buy_to_best_bid_log_distance')\n",
        "            average_sell_to_best_ask_log_distance = self.normalized_log_distance(average_sell_price, current_best_ask, 'average_sell_to_best_ask_log_distance')\n",
        "            state.append(average_buy_to_best_bid_log_distance)\n",
        "            state.append(average_sell_to_best_ask_log_distance)\n",
        "\n",
        "            #\n",
        "\n",
        "\n",
        "            #\n",
        "            average_sell_to_worst_ask_log_distance = self.normalized_log_distance(own_worst_ask, average_sell_price, 'average_sell_to_worst_ask_log_distance')\n",
        "            average_buy_to_worst_bid_log_distance= self.normalized_log_distance(own_worst_bid, average_buy_price, 'average_buy_to_worst_bid_log_distance')\n",
        "            state.append(average_sell_to_worst_ask_log_distance)\n",
        "            state.append(average_buy_to_worst_bid_log_distance)\n",
        "\n",
        "\n",
        "            weighted_avg_price_spread = self.calculate_normalized_weighted_avg_price_spread(average_buy_price, average_sell_price, self.cached_mid_price)\n",
        "            active_orders_to_aum_ratio = self.calculate_avg_entry_price_deviation_ratio(total_active_order_value, self.initial_capital, 'active_orders_to_aum_ratio')\n",
        "            state.append(weighted_avg_price_spread)\n",
        "            state.append(active_orders_to_aum_ratio)\n",
        "            active_orders_to_aum_log_distance = self.normalized_log_distance(total_active_order_value, self.initial_capital, 'active_orders_to_aum_log_distance')\n",
        "            state.append(active_orders_to_aum_log_distance)\n",
        "            #\n",
        "            inventory_target = self.order_manager.get_target_inventory()\n",
        "\n",
        "            inventory_target_ratio = self.calculate_avg_entry_price_deviation_ratio(current_inventory, inventory_target, 'inventory_target_ratio')\n",
        "            inventory_target_log_distance = self.normalized_log_distance(current_inventory, inventory_target, 'inventory_target_log_distance')\n",
        "            state.append(inventory_target_ratio)\n",
        "            state.append(inventory_target_log_distance)\n",
        "\n",
        "            #\n",
        "            dema_1_7_ratio = self.calculate_avg_entry_price_deviation_ratio(one_minute_dema, seven_minute_dema, 'dema_1_7_ratio')\n",
        "            dema_1_7_log_distance = self.normalized_log_distance(one_minute_dema, seven_minute_dema, 'dema_1_7_log_distance')\n",
        "            state.append(dema_1_7_ratio)\n",
        "            state.append(dema_1_7_log_distance)\n",
        "            dema_1_35_ratio = self.calculate_avg_entry_price_deviation_ratio(one_minute_dema, thirty_five_minute_dema, 'dema_1_35_ratio')\n",
        "            dema_1_35_log_distance = self.normalized_log_distance(one_minute_dema, thirty_five_minute_dema, 'dema_1_35_log_distance')\n",
        "            state.append(dema_1_35_ratio)\n",
        "            state.append(dema_1_35_log_distance)\n",
        "            #\n",
        "            #\n",
        "            #\n",
        "\n",
        "            #\n",
        "\n",
        "            dema_7_35_ratio = self.calculate_avg_entry_price_deviation_ratio(seven_minute_dema, thirty_five_minute_dema, 'dema_7_35_ratio')\n",
        "            dema_7_35_log_distance = self.normalized_log_distance(seven_minute_dema, thirty_five_minute_dema, 'dema_7_35_log_distance')\n",
        "            state.append(dema_7_35_ratio)\n",
        "            state.append(dema_7_35_log_distance)\n",
        "\n",
        "\n",
        "            depth_ratio = self.calculate_avg_entry_price_deviation_ratio(self.cached_bid_depth, self.cached_ask_depth, 'depth_ratio')\n",
        "            depth_log_distance = self.normalized_log_distance(self.cached_bid_depth, self.cached_ask_depth, 'depth_log_distance')\n",
        "            state.append(depth_ratio)\n",
        "            state.append(depth_log_distance)\n",
        "\n",
        "            #\n",
        "\n",
        "\n",
        "            total_volume_ratio = self.calculate_avg_entry_price_deviation_ratio(self.cached_total_ask_volume, self.cached_total_bid_volume, 'total_volume_ratio')\n",
        "            total_volume_log_distance = self.normalized_log_distance(self.cached_total_ask_volume, self.cached_total_bid_volume, 'total_volume_log_distance')\n",
        "            state.append(total_volume_ratio)\n",
        "            state.append(total_volume_log_distance)\n",
        "\n",
        "            #\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #\n",
        "\n",
        "\n",
        "            own_best_bid_to_inventory_log_distance = self.normalized_log_distance(own_best_bid_volume, current_inventory, 'own_best_bid_to_inventory_log_distance')\n",
        "            own_best_ask_to_inventory_log_distance = self.normalized_log_distance(own_best_ask_volume, current_inventory, 'own_best_ask_to_inventory_log_distance')\n",
        "            state.append(own_best_bid_to_inventory_log_distance)\n",
        "            state.append(own_best_ask_to_inventory_log_distance)\n",
        "            own_best_ask_volume_to_total_active_order_value = self.normalized_log_distance(own_best_ask_volume, total_active_order_value, 'own_best_ask_volume_to_total_active_order_value')\n",
        "            own_best_bid_volume_to_total_active_order_value = self.normalized_log_distance(own_best_bid_volume, total_active_order_value, 'own_best_bid_volume_to_total_active_order_value')\n",
        "            state.append(own_best_ask_volume_to_total_active_order_value)\n",
        "            state.append(own_best_bid_volume_to_total_active_order_value)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            top_two_ask_levels_volume_log_distance_AUM = self.normalized_log_distance(self.cached_top_two_ask_levels_volume, AUM_unit_size, 'top_two_ask_levels_volume_log_distance_AUM')\n",
        "            top_two_bid_levels_volume_log_distance_AUM = self.normalized_log_distance(self.cached_top_two_bid_levels_volume, AUM_unit_size, 'top_two_bid_levels_volume_log_distance_AUM')\n",
        "            top_two_ask_levels_volume_ratio_AUM  = self.calculate_avg_entry_price_deviation_ratio(self.cached_top_two_ask_levels_volume, AUM_unit_size, 'top_two_ask_levels_volume_ratio_AUM')\n",
        "            top_two_bid_levels_volume_ratio_AUM = self.calculate_avg_entry_price_deviation_ratio(self.cached_top_two_bid_levels_volume, AUM_unit_size, 'top_two_bid_levels_volume_ratio_AUM')\n",
        "\n",
        "            state.append(top_two_ask_levels_volume_log_distance_AUM)\n",
        "            state.append(top_two_bid_levels_volume_log_distance_AUM)\n",
        "            state.append(top_two_ask_levels_volume_ratio_AUM)\n",
        "            state.append(top_two_bid_levels_volume_ratio_AUM)\n",
        "\n",
        "            top_two_ask_levels_volume_log_distance_inventory = self.normalized_log_distance(self.cached_top_two_ask_levels_volume, current_inventory, 'top_two_ask_levels_volume_log_distance_inventory')\n",
        "            top_two_bid_levels_volume_log_distance_inventory = self.normalized_log_distance(self.cached_top_two_bid_levels_volume, current_inventory, 'top_two_bid_levels_volume_log_distance_inventory')\n",
        "            top_two_ask_levels_volume_ratio_inventory = self.calculate_avg_entry_price_deviation_ratio(self.cached_top_two_ask_levels_volume, current_inventory, 'top_two_ask_levels_volume_ratio_inventory')\n",
        "            top_two_bid_levels_volume_ratio_inventory = self.calculate_avg_entry_price_deviation_ratio(self.cached_top_two_bid_levels_volume, current_inventory, 'top_two_bid_levels_volume_ratio_inventory')\n",
        "            state.append(top_two_ask_levels_volume_log_distance_inventory)\n",
        "            state.append(top_two_bid_levels_volume_log_distance_inventory)\n",
        "            state.append(top_two_ask_levels_volume_ratio_inventory)\n",
        "            state.append(top_two_bid_levels_volume_ratio_inventory)\n",
        "\n",
        "            top_two_bid_levels_volume_log_distance_own_best_bid = self.normalized_log_distance(own_best_bid_volume, self.cached_top_two_bid_levels_volume, 'top_two_bid_levels_volume_log_distance_own_best_bid')\n",
        "            top_two_ask_levels_volume_log_distance_own_best_ask = self.normalized_log_distance(own_best_ask_volume, self.cached_top_two_ask_levels_volume, 'top_two_ask_levels_volume_log_distance_own_best_ask')\n",
        "            state.append(top_two_bid_levels_volume_log_distance_own_best_bid)\n",
        "            state.append(top_two_ask_levels_volume_log_distance_own_best_ask)\n",
        "\n",
        "\n",
        "            top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume = self.normalized_log_distance(self.cached_top_two_bid_levels_volume, self.cached_top_two_ask_levels_volume, 'top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume')\n",
        "            top_two_bid_levels_volume_top_two_ask_levels_volume_ratio = self.calculate_avg_entry_price_deviation_ratio(self.cached_top_two_bid_levels_volume, self.cached_top_two_ask_levels_volume, 'top_two_bid_levels_volume_top_two_ask_levels_volume_ratio')\n",
        "            state.append(top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume)\n",
        "            state.append(top_two_bid_levels_volume_top_two_ask_levels_volume_ratio)\n",
        "\n",
        "\n",
        "            vwap_top_two_ask_ratio = self.calculate_avg_entry_price_deviation_ratio(self.cached_vwap , self.cached_top_two_ask_levels_volume, 'vwap_top_two_ask_ratio')\n",
        "            vwap_top_two_ask_log_distance = self.normalized_log_distance(self.cached_vwap , self.cached_top_two_ask_levels_volume, 'vwap_top_two_ask_log_distance')\n",
        "            vwap_top_two_bid_log_distance =self.normalized_log_distance(self.cached_vwap , self.cached_top_two_bid_levels_volume, 'vwap_top_two_bid_log_distance')\n",
        "            vwap_top_two_bid_ratio = self.calculate_avg_entry_price_deviation_ratio(self.cached_vwap , self.cached_top_two_bid_levels_volume, 'vwap_top_two_bid_ratio')\n",
        "\n",
        "\n",
        "            state.append(vwap_top_two_ask_ratio)\n",
        "            state.append(vwap_top_two_ask_log_distance)\n",
        "            state.append(vwap_top_two_bid_log_distance)\n",
        "            state.append(vwap_top_two_bid_ratio)\n",
        "\n",
        "\n",
        "            ratio_average_buy_to_vwap = self.calculate_avg_entry_price_deviation_ratio(average_buy_price, self.cached_vwap , 'ratio_average_buy_to_vwap')\n",
        "            log_diff_buy_vwap = self.normalized_log_distance(average_buy_price, self.cached_vwap , 'log_diff_buy_vwap')\n",
        "            ratio_average_sell_to_vwap = self.calculate_avg_entry_price_deviation_ratio(average_sell_price, self.cached_vwap , 'ratio_average_sell_to_vwap')\n",
        "            log_diff_sell_vwap = self.normalized_log_distance(average_sell_price, self.cached_vwap , 'log_diff_sell_vwap')\n",
        "            state.append(ratio_average_buy_to_vwap)\n",
        "            state.append(log_diff_buy_vwap)\n",
        "            state.append(ratio_average_sell_to_vwap)\n",
        "            state.append(log_diff_sell_vwap)\n",
        "\n",
        "\n",
        "\n",
        "            ratio_own_best_bid_to_vwap = self.calculate_avg_entry_price_deviation_ratio(own_best_bid, self.cached_vwap , 'ratio_own_best_bid_to_vwap')\n",
        "            log_diff_own_best_bid_vwap = self.normalized_log_distance(own_best_bid, self.cached_vwap , 'log_diff_own_best_bid_vwap')\n",
        "            state.append(ratio_own_best_bid_to_vwap)\n",
        "            state.append(log_diff_own_best_bid_vwap)\n",
        "\n",
        "            ratio_own_best_ask_to_vwap = self.calculate_avg_entry_price_deviation_ratio(own_best_ask, self.cached_vwap , 'ratio_own_best_ask_to_vwap')\n",
        "            log_diff_own_best_ask_vwap = self.normalized_log_distance(own_best_ask, self.cached_vwap , 'log_diff_own_best_ask_vwap')\n",
        "            state.append(ratio_own_best_ask_to_vwap)\n",
        "            state.append(log_diff_own_best_ask_vwap)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            cv_buy_sell_ratio = self.calculate_avg_entry_price_deviation_ratio(self.cached_cv_buy, self.cached_cv_sell, 'cv_buy_sell_ratio')\n",
        "            cv_buy_sell_log_distance = self.normalized_log_distance(self.cached_cv_buy, self.cached_cv_sell , 'cv_buy_sell_log_distance')\n",
        "            state.append(cv_buy_sell_ratio)\n",
        "            state.append(cv_buy_sell_log_distance)\n",
        "            ema_buy_sell_ratio = self.calculate_avg_entry_price_deviation_ratio(self.cached_ema_buy, self.cached_ema_sell , 'ema_buy_sell_ratio')\n",
        "            ema_buy_sell_log_distance = self.normalized_log_distance(self.cached_ema_buy, self.cached_ema_sell , 'ema_buy_sell_log_distance')\n",
        "            state.append(ema_buy_sell_ratio)\n",
        "            state.append(ema_buy_sell_log_distance)\n",
        "\n",
        "\n",
        "            # one_seven_ratio= self.calculate_avg_entry_price_deviation_ratio(one_minute_mad, seven_minute_mad, 'one_seven_ratio')\n",
        "            # one_sixty_ratio = self.calculate_avg_entry_price_deviation_ratio(one_minute_mad, sixty_minute_mad, 'one_sixty_ratio')\n",
        "            # sixty_seven_ratio = self.calculate_avg_entry_price_deviation_ratio(sixty_minute_mad, seven_minute_mad, 'sixty_seven_ratio')\n",
        "            # state.append(one_seven_ratio)\n",
        "            # state.append(one_sixty_ratio)\n",
        "            # state.append(sixty_seven_ratio)\n",
        "\n",
        "            # one_seven_log_distance = self.normalized_log_distance(one_minute_mad, seven_minute_mad, 'one_seven_log_distance')\n",
        "            # one_sixty_log_distance = self.normalized_log_distance(one_minute_mad, sixty_minute_mad, 'one_sixty_log_distance')\n",
        "            # sixty_seven_log_distance = self.normalized_log_distance(sixty_minute_mad, seven_minute_mad, 'sixty_seven_log_distance')\n",
        "            # state.append(one_seven_log_distance)\n",
        "            # state.append(one_sixty_log_distance)\n",
        "            # state.append(sixty_seven_log_distance)\n",
        "\n",
        "\n",
        "\n",
        "            state.append(rate_percentage)\n",
        "\n",
        "\n",
        "            state.append(inventory_side)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            state.append(self.cached_bid_ask_spread)\n",
        "\n",
        "            # normalized_buy_price_z_score = self.z_score_normalize(average_buy_price, mean_price, std_dev_price)\n",
        "            # normalized_sell_price_z_score = self.z_score_normalize(average_sell_price, mean_price, std_dev_price)\n",
        "            # Specify the target length\n",
        "            # target_length = 9\n",
        "\n",
        "            # # Extend scalar values to the target length\n",
        "            # extended_current_position = self.extend_to_length(inventory_side, target_length)\n",
        "\n",
        "            # extend_active_orders_to_aum_ratio = self.extend_to_length(active_orders_to_aum_ratio, target_length)\n",
        "            # extended_my_best_bid_to_current_ratio = self.extend_to_length(my_best_bid_to_current_ratio, target_length)\n",
        "            # extended_my_best_ask_to_current_ratio = self.extend_to_length(my_best_ask_to_current_ratio, target_length)\n",
        "            # extended_average_buy_to_best_bid_ratio = self.extend_to_length(average_buy_to_best_bid_ratio, target_length)\n",
        "            # extended_average_sell_to_best_ask_ratio = self.extend_to_length(average_sell_to_best_ask_ratio, target_length)\n",
        "            # extended_weighted_avg_price_spread = self.extend_to_length(weighted_avg_price_spread, target_length)\n",
        "            # extended_inventory_target_ratio = self.extend_to_length(inventory_target_ratio, target_length)\n",
        "            # extended_dema_ratio = self.extend_to_length(dema_ratio, target_length)\n",
        "\n",
        "            # # extended_avg_buy_price = self.extend_to_length(self.get_average_buy_price(), target_length)\n",
        "            # # extended_avg_sell_price = self.extend_to_length(self.get_average_sell_price(), target_length)\n",
        "\n",
        "            # extended_order_flow_ratio = self.extend_to_length(self.calculate_trade_flow_ratio(current_trades), target_length)\n",
        "\n",
        "            # extended_unrealized_pnl = self.extend_to_length(self.get_unrealized_pnl(), target_length)\n",
        "            # extended_rate_percentage = self.extend_to_length(rate_percentage, target_length)\n",
        "            # extended_liquidity = self.extend_to_length(self.liquidity, target_length)\n",
        "            #extended_liquidity = self.extend_to_length(self.calculate_sophisticated_liquidity_multi_snapshot(), target_length)\n",
        "\n",
        "            # Calculate mean and standard deviation for z-score normalization\n",
        "            # mean_price = (extended_avg_buy_price[0] + extended_avg_sell_price[0]) / 2\n",
        "            # std_dev_price = math.sqrt(((extended_avg_buy_price[0] - mean_price)**2 + (extended_avg_sell_price[0] - mean_price)**2) / 1)\n",
        "\n",
        "            # # Constructing the state vector\n",
        "            # state = [self.preprocess_feature_with_robust_scaling(feature) for feature in [\n",
        "            #     self.cached_bid_depth, self.cached_ask_depth,\n",
        "            #     self.cached_market_imbalance, self.cached_bid_ask_spread,\n",
        "            #     self.cached_vwap, self.cached_price_impact, self.cached_order_book_skewness, self.cached_order_book_slope,\n",
        "            #     self.cached_order_flow_ratio, self.cached_order_flow, self.cached_best_bid_price, self.cached_best_ask_price, self.cached_half_spread, self.cached_mid_price,\n",
        "            #     self.rolling_trade_volume,\n",
        "            #     self.cached_order_flow_rate,\n",
        "            #     self.cached_trading_volumes, self.cached_weighted_price_volatility, self.cached_time_weighted_volume_variability,\n",
        "\n",
        "            # ]]\n",
        "            # feature_names = [ 'market_imbalance_ratio',  'vwap', 'price_impact',  'rolling_trade_volume',   'weighted_price_volatility', 'time_weighted_volume_variability'] #'bid_skewness',  'ask_skewness', 'bid_slope', 'ask_slope',\n",
        "\n",
        "            # features = [ self.cached_imbalance_ratio,   self.cached_vwap, self.cached_price_impact,     self.rolling_trade_volume,  self.cached_weighted_price_volatility, self.cached_time_weighted_volume_variability]#self.cached_bid_skewness, self.cached_ask_skewness, self.cached_bid_slope, self.cached_ask_slope,\n",
        "\n",
        "            # # Constructing the state vector\n",
        "            # state = [self.preprocess_feature_with_robust_scaling(feature, name) for feature, name in zip(features, feature_names)]\n",
        "            # one_minute_mad = volatility_manager.get_mad_volatility_measures().get(\"1m\", 0)\n",
        "            # seven_minute_mad = volatility_manager.get_mad_volatility_measures().get(\"7m\", 0)\n",
        "            # sixty_minute_mad = volatility_manager.get_mad_volatility_measures().get(\"60m\", 0)\n",
        "\n",
        "            # Names of the features for debugging or reference\n",
        "            # feature_names2 = [\n",
        "            #     'bid_depth',\n",
        "            #     'ask_depth',\n",
        "            #     'bid_ask_spread',\n",
        "            #     'best_bid_price',\n",
        "            #     'best_ask_price',\n",
        "            #     'best_ask_volume',\n",
        "            #     'best_bid_volume',\n",
        "            #     'half_spread',\n",
        "            #     'mid_price'\n",
        "            # ]\n",
        "            # # Features to normalize\n",
        "            # features_to_normalize = [\n",
        "            #     self.cached_bid_depth,\n",
        "            #     self.cached_ask_depth,\n",
        "            #     self.cached_bid_ask_spread,\n",
        "            #     self.cached_best_bid_price,\n",
        "            #     self.cached_best_ask_price,\n",
        "            #     self.cached_best_ask_volume,\n",
        "            #     self.cached_best_bid_volume,\n",
        "            #     self.cached_half_spread,\n",
        "            #     self.cached_mid_price\n",
        "            # ]\n",
        "\n",
        "            # for feature, name in zip(features_to_normalize, feature_names2):\n",
        "            #     # Convert the queue to a list for calculation\n",
        "            #     feature_list = list(feature)\n",
        "            #     mean = np.mean(feature_list)\n",
        "            #     std_dev = np.std(feature_list)\n",
        "\n",
        "            #     normalized_feature = [self.z_score_normalize(value, mean, std_dev) for value in feature_list]\n",
        "            #     print(f'{name}: {normalized_feature}')\n",
        "\n",
        "            #     # Append the normalized feature to the state vector\n",
        "            #     state.append(normalized_feature)\n",
        "\n",
        "            # Integrate MAD volatilities into the state vector\n",
        "            # Integrate MAD volatilities into the state vector using aggregated features\n",
        "            # mad_values_tuple = tuple(mad_volatility for mad_volatility in mad_volatilities.values())\n",
        "\n",
        "            # # for key, mad_volatility in mad_volatilities.items():\n",
        "            #     # Ensure to handle None values or defaults if mad_volatility is not calculated\n",
        "            #     print(f'mad_volatility: {mad_volatility}')\n",
        "\n",
        "            #     if mad_volatility is not None:\n",
        "            #         # Calculate aggregated features for the mad_volatility data\n",
        "            #         aggregated_features = self.calculate_aggregated_features(mad_volatility)\n",
        "\n",
        "            #         # Append the aggregated features to the state vector\n",
        "            #         state.append(aggregated_features)\n",
        "            #     else:\n",
        "            #         # If MAD volatility is None, append default values (zeros) for each feature\n",
        "            #         state.append([0.0] * 9)  # 9 features: mean, std_dev, cv, skewness, kurtosis, q25, q50, q75, min_max_ratio\n",
        "\n",
        "            # cached_buy_order_flow_rate = self.preprocess_feature_with_robust_scaling(self.cached_buy_order_flow_rate, 'buy_order_flow_rate')\n",
        "            # cached_sell_order_flow_rate = self.preprocess_feature_with_robust_scaling(self.cached_sell_order_flow_rate, 'sell_order_flow_rate')\n",
        "\n",
        "            # # Assuming 'state' is a list to which you're appending features\n",
        "            # ageregated_buy_order_flow = self.ema_calculate_aggregated_features(cached_buy_order_flow_rate)\n",
        "            # ageregated_sell_order_flow = self.ema_calculate_aggregated_features(cached_sell_order_flow_rate)\n",
        "\n",
        "            # print(f\"ageregated_buy_order_flow: {ageregated_buy_order_flow}\")\n",
        "            # #\n",
        "            # state.append(ageregated_buy_order_flow)\n",
        "            # print(f\"ageregated_sell_order_flow: {ageregated_sell_order_flow}\")\n",
        "            # state.append(ageregated_sell_order_flow)\n",
        "            # # print(f\"difference_traded_volume: {self.difference_traded_volume}\")\n",
        "            # # state.append(self.difference_traded_volume)\n",
        "\n",
        "            # print(f\"extended_order_flow_ratio: {extended_order_flow_ratio}\")\n",
        "            # state.append(extended_order_flow_ratio)\n",
        "\n",
        "            # # print(f\"difference_traded_price: {self.difference_traded_price}\")\n",
        "            # # state.append(self.difference_traded_price)\n",
        "\n",
        "            # print(f\"extended_rate_percentage: {extended_rate_percentage}\")\n",
        "            # state.append(extended_rate_percentage)\n",
        "\n",
        "            # print(f\"extended_unrealized_pnl: {extended_unrealized_pnl}\")\n",
        "            # state.append(extended_unrealized_pnl)\n",
        "\n",
        "            # print(f\"extended_current_position: {extended_current_position}\")\n",
        "            # state.append(extended_current_position)\n",
        "\n",
        "            # print(f\"extended_my_best_bid_to_current_ratio: {extended_my_best_bid_to_current_ratio}\")\n",
        "            # state.append(extended_my_best_bid_to_current_ratio)\n",
        "\n",
        "            # print(f\"extended_my_best_ask_to_current_ratio: {extended_my_best_ask_to_current_ratio}\")\n",
        "            # state.append(extended_my_best_ask_to_current_ratio)\n",
        "\n",
        "            # print(f\"extended_average_buy_to_best_bid_ratio: {extended_average_buy_to_best_bid_ratio}\")\n",
        "            # state.append(extended_average_buy_to_best_bid_ratio)\n",
        "\n",
        "            # print(f\"extended_average_sell_to_best_ask_ratio: {extended_average_sell_to_best_ask_ratio}\")\n",
        "            # state.append(extended_average_sell_to_best_ask_ratio)\n",
        "\n",
        "            # print(f\"extended_weighted_avg_price_spread: {extended_weighted_avg_price_spread}\")\n",
        "            # state.append(extended_weighted_avg_price_spread)\n",
        "\n",
        "            # print(f\"extended_inventory_target_ratio: {extended_inventory_target_ratio}\")\n",
        "            # state.append(extended_inventory_target_ratio)\n",
        "\n",
        "            # # print(f\"extended_inventory_target_ratio: {extended_inventory_target_ratio}\")\n",
        "            # # state.append(extended_inventory_target_ratio)\n",
        "            # print(f\"extended_active_orders_ratio: {extend_active_orders_to_aum_ratio}\")\n",
        "            # state.append(extend_active_orders_to_aum_ratio)\n",
        "\n",
        "\n",
        "            # print(f\"extended_dema_ratio: {extended_dema_ratio}\")\n",
        "            # state.append(extended_dema_ratio)\n",
        "\n",
        "            # # This line seems to be a duplicate of the inventory target ratio.\n",
        "            # # If this is intentional, append it again, otherwise, you may want to remove or replace this line.\n",
        "\n",
        "\n",
        "\n",
        "            # Convert the state list to a tensor\n",
        "            print(\"State vector:\", state)\n",
        "            state_array = np.array(state)\n",
        "            print(f\"State size: {len(state)}\")\n",
        "\n",
        "\n",
        "            # Convert the flattened\n",
        "            state_tensor = torch.tensor(state_array, dtype=torch.float32)\n",
        "            actor_state = state_tensor.view(-1)  # Flatten to 1D\n",
        "            flattened_state_with_batch = actor_state.unsqueeze(0)\n",
        "\n",
        "            print(\"State tensor:\", flattened_state_with_batch.shape)\n",
        "\n",
        "\n",
        "            return 1, flattened_state_with_batch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "XUswFXtdWAtR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHq5wBHGYc91"
      },
      "outputs": [],
      "source": [],
      "id": "tHq5wBHGYc91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b67ebf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0243fb-a9f2-4461-b2a1-ff0c27fdf7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import heapq\n",
        "import queue\n",
        "import random\n",
        "import math\n",
        "import glob\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "import uuid\n",
        "\n",
        "TIME_FACTOR_CONSTANT = 2\n",
        "class OrderBook:\n",
        "    def __init__(self, depth=10):\n",
        "        self.depth = depth\n",
        "        self.bids = []  # List of tuples (price, volume)\n",
        "        self.asks = []  # List of tuples (price, volume)\n",
        "        print(\"OrderBook initialized with depth:\", self.depth)\n",
        "\n",
        "        self.active_orders = {}  # Active orders placed by the strategy\n",
        "        self.order_insertion_times = {}  # Insertion times of orders\n",
        "        # self.queue_position_estimate = {}  # Estimated position in the queue\n",
        "        self.my_trades = []  # Store trades executed by the strategy\n",
        "\n",
        "\n",
        "    def update_book(self, bids, asks):\n",
        "        \"\"\" Update the order book with new bid and ask data. \"\"\"\n",
        "        # Sort and trim the bids and asks to maintain the depth\n",
        "        print(\"Updating order book with new bids and asks\")\n",
        "        self.bids = sorted(bids, key=lambda x: x[0], reverse=True)[:self.depth]\n",
        "        self.asks = sorted(asks, key=lambda x: x[0])[:self.depth]\n",
        "\n",
        "    def display_book(self):\n",
        "        \"\"\" Display the current state of the order book. \"\"\"\n",
        "        print(\"Current state of the Order Book:\")\n",
        "        print(\"Bids:\")\n",
        "        for price, volume in self.bids:\n",
        "            print(f\"Price: {price}, Volume: {volume}\")\n",
        "        print(\"\\nAsks:\")\n",
        "        for price, volume in self.asks:\n",
        "            print(f\"Price: {price}, Volume: {volume}\")\n",
        "\n",
        "    # def place_limit_order(self, order_id, price, volume, side, current_time):\n",
        "    #     \"\"\" Place a limit order in the order book. \"\"\"\n",
        "    #     self.active_orders[order_id] = {'price': price, 'volume': volume, 'side': side}\n",
        "    #     self.order_insertion_times[order_id] = current_time\n",
        "    #     self.queue_position_estimate[order_id] = self.get_initial_queue_position(price, volume, side)\n",
        "\n",
        "    #     # Check for potential matches before adding the order to the book\n",
        "    #     remaining_volume, matched_orders = self.match_order(price, volume, side)\n",
        "\n",
        "    #     # If there's remaining volume after matching, add it to the order book\n",
        "    #     if remaining_volume > 0:\n",
        "    #         if side == 'buy':\n",
        "    #             self.bids.append((price, remaining_volume))\n",
        "    #         else:\n",
        "    #             self.asks.append((price, remaining_volume))\n",
        "    #         self.bids.sort(key=lambda x: x[0], reverse=True)\n",
        "    #         self.asks.sort(key=lambda x: x[0])\n",
        "\n",
        "    #     self.trim_order_book()\n",
        "    def place_limit_order(self, order_id, price, volume, side, current_time):\n",
        "        \"\"\" Place a limit order in the order book. \"\"\"\n",
        "        print(f\"Placing limit order: Order ID {order_id}, Price {price}, Volume {volume}, Side {side}\")\n",
        "\n",
        "        # Check for potential immediate matches\n",
        "        remaining_volume, matched_trades = self.match_order(price, volume, side)\n",
        "\n",
        "        # Add remaining volume to the order book\n",
        "        if remaining_volume > 0:\n",
        "            self.add_order_to_book(order_id, price, remaining_volume, side, current_time)\n",
        "\n",
        "        # Process matched trades\n",
        "        for trade  in matched_trades:\n",
        "            self.execute_my_trade(trade, order_id, side)\n",
        "\n",
        "        self.trim_order_book()\n",
        "\n",
        "    def execute_my_trade(self, trade, order_id, matched_side):\n",
        "        \"\"\" Execute a trade for the strategy and store it. \"\"\"\n",
        "        matched_price, matched_volume = trade\n",
        "        matched_price = matched_price[0]\n",
        "        print(f\"Executing matched trade: Order ID {order_id}, Price {matched_price}, Volume {matched_volume}, Side {matched_side}\")\n",
        "\n",
        "        # Logic to process the matched trade\n",
        "        # For example, updating positions, PnL calculations, etc.\n",
        "        # self.position_manager.update_position(...)  # Example\n",
        "\n",
        "        # Record the trade\n",
        "        recorded_trade = {\n",
        "            'order_id': order_id,\n",
        "            'price': matched_price,\n",
        "            'volume': matched_volume,\n",
        "            'side': matched_side\n",
        "        }\n",
        "        self.my_trades.append(recorded_trade)\n",
        "\n",
        "    def get_my_recent_trades(self):\n",
        "        \"\"\" Get the list of strategy's trades executed since the last update. \"\"\"\n",
        "        recent_trades_copy = self.my_trades.copy()\n",
        "        self.my_trades.clear()  # Clear the list after copying\n",
        "        return recent_trades_copy\n",
        "\n",
        "    def add_order_to_book(self, order_id, price, volume, side, current_time):\n",
        "        print(f\"Adding order to book: Order ID {order_id}, Price {price}, Volume {volume}, Side {side}, Time {current_time}\")\n",
        "        self.order_insertion_times[order_id] = current_time\n",
        "        five_minutes_in_microseconds = 5 * 60 * 1_000_000  # 5 minutes in microseconds\n",
        "        expiration_time = current_time + five_minutes_in_microseconds\n",
        "        self.active_orders[order_id] = {'price': price, 'volume': volume, 'side': side, 'expiration': expiration_time}\n",
        "\n",
        "        order_book = self.bids if side == 'buy' else self.asks\n",
        "\n",
        "        # Find existing price level and update volume or append new price-volume pair\n",
        "        found = False\n",
        "        for i, (p, v) in enumerate(order_book):\n",
        "            if p == price:\n",
        "                order_book[i] = (price, v + volume)  # Update total volume at this price level\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        if not found:\n",
        "            order_book.append((price, volume))  # Append new price level\n",
        "            order_book.sort(key=lambda x: x[0], reverse=(side == 'buy'))\n",
        "\n",
        "        # Truncate the order book to maintain the specified depth\n",
        "        if len(order_book) > self.depth:\n",
        "            order_book = order_book[:self.depth]\n",
        "\n",
        "    # def add_order_to_book(self, order_id, price, volume, side, current_time):\n",
        "    #     \"\"\" Add or update an order in the order book and maintain sorting. \"\"\"\n",
        "    #     print(f\"Adding order to book: Order ID {order_id}, Price {price}, Volume {volume}, Side {side}, Time {current_time}\")\n",
        "    #     expiration_time = current_time + 360000  # Add 5 minutes in milliseconds\n",
        "    #     self.active_orders[order_id] = {'price': price, 'volume': volume, 'side': side, 'expiration': expiration_time}\n",
        "    #     self.order_insertion_times[order_id] = current_time\n",
        "    #     self.queue_position_estimate[order_id] = self.get_initial_queue_position(price, volume, side)\n",
        "\n",
        "    #     order_book = self.bids if side == 'buy' else self.asks\n",
        "\n",
        "    #     # Find existing price and update volume or append new price-volume pair\n",
        "    #     for i, (p, v) in enumerate(order_book):\n",
        "    #         if p == price:\n",
        "    #             order_book[i] = (price, v + volume)\n",
        "    #             break\n",
        "    #     else:\n",
        "    #         order_book.append((price, volume))\n",
        "    #         order_book.sort(key=lambda x: x[0], reverse=(side == 'buy'))\n",
        "\n",
        "\n",
        "    # def match_order(self, price, volume, side):\n",
        "    #     \"\"\"Attempt to match the incoming order with existing orders in the book.\"\"\"\n",
        "    #     book_side = self.asks if side == 'buy' else self.bids\n",
        "    #     remaining_volume = volume\n",
        "    #     matched_orders = []\n",
        "\n",
        "    #     for order in book_side[:]:\n",
        "    #         if (side == 'buy' and order[0] <= price) or (side == 'sell' and order[0] >= price):\n",
        "    #             matched_volume = min(order[1], remaining_volume)\n",
        "    #             remaining_volume -= matched_volume\n",
        "    #             new_order_volume = order[1] - matched_volume\n",
        "\n",
        "    #             if new_order_volume > 0:\n",
        "    #                 order_index = book_side.index(order)\n",
        "    #                 book_side[order_index] = (order[0], new_order_volume)\n",
        "    #             else:\n",
        "    #                 book_side.remove(order)\n",
        "\n",
        "    #             matched_orders.append((order, matched_volume))\n",
        "    #             if remaining_volume <= 0:\n",
        "    #                 break\n",
        "\n",
        "\n",
        "    #     # Adjust queue positions at the end of matching process\n",
        "    #     for matched_order, matched_vol in matched_orders:\n",
        "    #         matched_order_price, matched_order_side = matched_order\n",
        "    #         self.adjust_queue_positions(matched_order, matched_vol)\n",
        "\n",
        "    #     return remaining_volume, matched_orders\n",
        "    def match_order(self, price, volume, side):\n",
        "        \"\"\"Attempt to match the incoming order with existing orders in the book.\"\"\"\n",
        "        book_side = self.asks if side == 'buy' else self.bids\n",
        "        remaining_volume = volume\n",
        "        matched_orders = []\n",
        "\n",
        "        for order in book_side[:]:\n",
        "            if (side == 'buy' and order[0] <= price) or (side == 'sell' and order[0] >= price):\n",
        "                matched_volume = min(order[1], remaining_volume)\n",
        "                remaining_volume -= matched_volume\n",
        "                new_order_volume = order[1] - matched_volume\n",
        "\n",
        "                if new_order_volume > 0:\n",
        "                    order_index = book_side.index(order)\n",
        "                    book_side[order_index] = (order[0], new_order_volume)\n",
        "                else:\n",
        "                    book_side.remove(order)\n",
        "\n",
        "                matched_orders.append((order, matched_volume))\n",
        "                if remaining_volume <= 0:\n",
        "                    break\n",
        "\n",
        "        return remaining_volume, matched_orders\n",
        "\n",
        "\n",
        "    def find_order_id_by_price(self, price, trade_side):\n",
        "    # Determine the opposite side for matching\n",
        "      opposite_side = 'sell' if trade_side == 'buy' else 'buy'\n",
        "\n",
        "      for order_id, order_details in self.active_orders.items():\n",
        "          if order_details['price'] == price and order_details['side'] == opposite_side:\n",
        "              return order_id\n",
        "      return None  # Return None if no matching order is found\n",
        "\n",
        "    # def calculate_execution_probability(self, order_id):\n",
        "    #     \"\"\"Calculate the probability of an order's execution based solely on its queue position.\"\"\"\n",
        "    #     print(f\"Calculating execution probability for Order ID {order_id}\")\n",
        "\n",
        "    #     position_in_queue = self.queue_position_estimate.get(order_id, 0)\n",
        "\n",
        "    #     # The simplest model might assume a linear decrease in probability\n",
        "    #     # the further back in the queue an order is.\n",
        "    #     # For example, the first order in the queue might have a near-100% probability of execution,\n",
        "    #     # while the last order in a queue of depth 20 might have only a 5% chance.\n",
        "    #     if self.depth > 0:\n",
        "    #         probability = max(1 - (position_in_queue / self.depth), 0)\n",
        "    #     else:\n",
        "    #         probability = 0  # If the depth is 0 or undefined, set probability to 0\n",
        "    #     return probability\n",
        "\n",
        "\n",
        "\n",
        "    # def get_initial_queue_position(self, price, volume, side):\n",
        "    #     \"\"\" Estimate the initial position of the order in the queue. \"\"\"\n",
        "    #     current_volume = sum(vol for p, vol in (self.bids if side == 'buy' else self.asks) if p == price)\n",
        "    #     return current_volume\n",
        "    def handle_trade_execution(self, trade_execution_event):\n",
        "        \"\"\" Handle trade execution events for market orders. \"\"\"\n",
        "        trade_side = trade_execution_event['side']\n",
        "        trade_volume = trade_execution_event['volume']\n",
        "        print('======================================================================')\n",
        "        print(f\"Handling trade execution event: side: {trade_side}, volume: {trade_volume}\")\n",
        "        print(f\"Current book: {self.bids}, {self.asks}\")\n",
        "        print('======================================================================')\n",
        "        # Choose the correct side of the order book for matching\n",
        "\n",
        "        # Choose the correct side of the order book for matching\n",
        "        book_side = self.asks if trade_side == 'buy' else self.bids\n",
        "        remaining_volume = trade_volume\n",
        "        matched_orders = []\n",
        "\n",
        "        for order in book_side:\n",
        "            if remaining_volume <= 0:\n",
        "                break\n",
        "\n",
        "            # Determine the opposite side for finding the matching order\n",
        "            opposite_side = 'sell' if trade_side == 'buy' else 'buy'\n",
        "            order_id = self.find_order_id_by_price(order[0], opposite_side)\n",
        "\n",
        "            if order_id is not None and self.check_order_execution(order_id):\n",
        "                matched_volume = min(order[1], remaining_volume)\n",
        "                remaining_volume -= matched_volume\n",
        "\n",
        "                # Update the order volume or remove the order if fully executed\n",
        "                new_order_volume = order[1] - matched_volume\n",
        "                if new_order_volume > 0:\n",
        "                    order_index = book_side.index(order)\n",
        "                    book_side[order_index] = (order[0], new_order_volume)\n",
        "                else:\n",
        "                    book_side.remove(order)\n",
        "\n",
        "                # Execute the trade for each matched order\n",
        "                self.execute_my_trade((order[0], matched_volume), order_id, trade_side)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Note: The method to update orders and adjust queue positions needs to be adjusted or removed\n",
        "        # as per the new implementation approach.\n",
        "        # self.update_order_and_queue() and self.trim_order_book() may need revision or removal.\n",
        "\n",
        "    # def handle_trade_execution(self, trade_execution_event):\n",
        "    #     \"\"\" Handle trade execution events. \"\"\"\n",
        "\n",
        "\n",
        "    #     trade_side = trade_execution_event['side']\n",
        "    #     trade_price = trade_execution_event['price']\n",
        "    #     trade_volume = trade_execution_event['volume']\n",
        "    #     print('======================================================================')\n",
        "    #     print(f\"Handling trade execution event: side: {trade_side}, price: {trade_price}, volume: {trade_volume}\")\n",
        "    #     print(f\"Current book: {self.bids}, {self.asks}\")\n",
        "    #     print('======================================================================')\n",
        "    #     book_side = self.asks if trade_side == 'buy' else self.bids\n",
        "    #     remaining_volume = trade_volume\n",
        "    #     matched_orders = []\n",
        "\n",
        "    #     for order in book_side[:]:\n",
        "    #         # Check if order price is compatible\n",
        "    #         if (trade_side == 'buy' and order[0] <= trade_price) or (trade_side == 'sell' and order[0] >= trade_price):\n",
        "    #             order_id = self.find_order_id_by_price(order[0], trade_side)\n",
        "    #             execution_probability = self.calculate_execution_probability(order_id)\n",
        "\n",
        "    #             # Only match if execution probability is above a certain threshold\n",
        "    #             if execution_probability >= 0.5:  # Example threshold\n",
        "    #                 print(f\"Matched order {order} with execution probability {execution_probability}\")\n",
        "    #                 matched_volume = min(order[1], remaining_volume)\n",
        "    #                 remaining_volume -= matched_volume\n",
        "    #                 new_order_volume = order[1] - matched_volume\n",
        "\n",
        "    #                 # Update the book and queue if partially or fully matched\n",
        "    #                 if new_order_volume > 0:\n",
        "    #                     order_index = book_side.index(order)\n",
        "    #                     book_side[order_index] = (order[0], new_order_volume)\n",
        "    #                 else:\n",
        "    #                     book_side.remove(order)\n",
        "\n",
        "    #                 matched_orders.append((order, matched_volume))\n",
        "    #                 # If there's still remaining volume, find the next price level\n",
        "    #                 if remaining_volume > 0:\n",
        "    #                     next_price = self.find_next_price(trade_price, trade_side)\n",
        "    #                     if next_price != trade_price:\n",
        "    #                         trade_price = next_price\n",
        "    #                     else:\n",
        "    #                         # If no next price is found or it's the same as the current price, exit the loop\n",
        "    #                         break\n",
        "\n",
        "    #     # Update active orders and adjust queue positions based on matched orders\n",
        "    #     for matched_order, matched_vol in matched_orders:\n",
        "    #         matched_order_price, matched_order_side = matched_order\n",
        "    #         self.update_order_and_queue(( matched_order_price, matched_order_side), matched_vol)\n",
        "\n",
        "    #     self.trim_order_book()\n",
        "\n",
        "    # def adjust_queue_positions(self, matched_order_info, matched_volume):\n",
        "    #     \"\"\"Adjust queue positions after a trade.\"\"\"\n",
        "    #     matched_order_price, matched_order_side = matched_order_info\n",
        "\n",
        "    #     print(f\"Adjusting queue positions: Price {matched_order_price}, Side {matched_order_side}, Matched Volume {matched_volume}\")\n",
        "\n",
        "    #     # Iterate over all orders in the queue\n",
        "    #     for order_id, order_details in self.active_orders.items():\n",
        "    #         # Check if the order is at the same price level and side as the matched order\n",
        "    #         if order_details['price'] == matched_order_price and order_details['side'] == matched_order_side:\n",
        "    #             # Adjust the estimated queue position for each affected order\n",
        "    #             self.queue_position_estimate[order_id] = max(self.queue_position_estimate[order_id] - matched_volume, 0)\n",
        "\n",
        "    # def update_order_and_queue(self, matched_order_info, matched_volume):\n",
        "    #     \"\"\" Update the active orders and queue positions after a trade. \"\"\"\n",
        "    #     print(f\"Updating order and queue: Matched Order Info {matched_order_info}, Matched Volume {matched_volume}\")\n",
        "\n",
        "    #     matched_order_price, matched_order_side = matched_order_info\n",
        "\n",
        "    #     # Find the order ID by price and side\n",
        "    #     order_id = self.find_order_id_by_price(matched_order_price, matched_order_side)\n",
        "    #     if order_id is None:\n",
        "    #         print(f\"No matching order found for price {matched_order_price} and side {matched_order_side}\")\n",
        "    #         return\n",
        "\n",
        "    #     # Update the volume in the active order or remove if fully matched\n",
        "    #     if order_id in self.active_orders:\n",
        "    #         order = self.active_orders[order_id]\n",
        "    #         new_volume = order['volume'] - matched_volume\n",
        "    #         if new_volume > 0:\n",
        "    #             order['volume'] = new_volume\n",
        "    #         else:\n",
        "    #             # Remove the order if fully matched\n",
        "    #             del self.active_orders[order_id]\n",
        "    #             del self.order_insertion_times[order_id]\n",
        "    #             del self.queue_position_estimate[order_id]\n",
        "\n",
        "    #     # Adjust the queue positions for remaining orders\n",
        "    #     for other_order_id, position in self.queue_position_estimate.items():\n",
        "    #         other_order = self.active_orders.get(other_order_id)\n",
        "    #         if other_order and other_order['price'] == matched_order_price and other_order['side'] == matched_order_side:\n",
        "    #             if position > self.queue_position_estimate.get(order_id, 0):\n",
        "    #                 self.queue_position_estimate[other_order_id] -= matched_volume\n",
        "\n",
        "    # def revise_queue_positions(self, market_update_event):\n",
        "    #     \"\"\" Revise the queue position estimates based on market update. \"\"\"\n",
        "    #     print(\"Revising queue positions based on market update event\")\n",
        "\n",
        "    #     for order_id in self.queue_position_estimate:\n",
        "    #         current_position = self.queue_position_estimate[order_id]\n",
        "    #         self.queue_position_estimate[order_id] = self.revise_queue_position_estimate(order_id, current_position, market_update_event)\n",
        "\n",
        "    # def revise_queue_position_estimate(self, order_id, current_position, market_update):\n",
        "    #     \"\"\" Revise the queue position estimate based on a single market update. \"\"\"\n",
        "    #     print(\"Revising queue position estimate based on market update\")\n",
        "\n",
        "    #     updated_position = current_position\n",
        "    #     order_details = self.active_orders[order_id]\n",
        "\n",
        "    #     # Check if the update is relevant to the order's price level\n",
        "    #     if market_update['price'] == order_details['price']:\n",
        "    #         front = self.get_volume_in_front_of_order(order_id)\n",
        "    #         back = self.get_volume_behind_order(order_id)\n",
        "    #         probability_of_impact = self.estimate_probability_of_impact(front, back)\n",
        "    #         position_change = self.calculate_position_change(market_update, probability_of_impact)\n",
        "    #         updated_position = max(updated_position + position_change, 0)\n",
        "\n",
        "    #     return updated_position\n",
        "\n",
        "    #     #return updated_position\n",
        "\n",
        "    # def get_volume_in_front_of_order(self, order_id):\n",
        "    #     \"\"\" Get the volume of orders in front of the specified order. \"\"\"\n",
        "    #     order_details = self.active_orders[order_id]\n",
        "    #     front_volume = 0\n",
        "    #     insertion_time = self.order_insertion_times[order_id]\n",
        "\n",
        "    #     for other_order_id, other_order_details in self.active_orders.items():\n",
        "    #         if other_order_details['price'] == order_details['price'] and \\\n",
        "    #            self.order_insertion_times[other_order_id] < insertion_time:\n",
        "    #             front_volume += other_order_details['volume']\n",
        "\n",
        "    #     return front_volume\n",
        "\n",
        "    # def get_volume_behind_order(self, order_id):\n",
        "    #     \"\"\" Get the volume of orders behind the specified order. \"\"\"\n",
        "    #     order_details = self.active_orders[order_id]\n",
        "    #     back_volume = 0\n",
        "    #     insertion_time = self.order_insertion_times[order_id]\n",
        "\n",
        "    #     for other_order_id, other_order_details in self.active_orders.items():\n",
        "    #         if other_order_details['price'] == order_details['price'] and \\\n",
        "    #            self.order_insertion_times[other_order_id] > insertion_time:\n",
        "    #             back_volume += other_order_details['volume']\n",
        "\n",
        "    #     return back_volume\n",
        "\n",
        "    # def estimate_probability_of_impact(self, front, back):\n",
        "    #     \"\"\" Estimate the probability that an update affects the queue position. \"\"\"\n",
        "    #     if front == 0 and back == 0:\n",
        "    #         # If both front and back volumes are zero, return a default low probability\n",
        "    #         return 0.9  # or some other default value of your choice\n",
        "\n",
        "    #     f = lambda x: math.log(1 + x)  # Example: logarithmic function\n",
        "    #     return f(back) / (f(front) + f(back))\n",
        "\n",
        "\n",
        "    # def calculate_position_change(self, update, probability_of_impact):\n",
        "    #     \"\"\" Calculate the change in position based on update and probability. \"\"\"\n",
        "    #     # Assuming 'size_change' is a column in your DataFrame\n",
        "    #     if 'size_change' in update and update['size_change'] < 0:\n",
        "    #         return update['size_change'] * probability_of_impact\n",
        "    #     return 0\n",
        "\n",
        "    # def get_order_execution_probability(self, order_id):\n",
        "    #     \"\"\" Calculate the probability of an order's execution based on its volume percentage at the price level. \"\"\"\n",
        "    #     order_details = self.active_orders[order_id]\n",
        "    #     book_side = self.bids if order_details['side'] == 'buy' else self.asks\n",
        "\n",
        "    #     total_volume_at_price = sum(v for p, v in book_side if p == order_details['price'])\n",
        "    #     if total_volume_at_price == 0:\n",
        "    #         return 0\n",
        "\n",
        "    #     volume_percentage = order_details['volume'] / total_volume_at_price\n",
        "    #     return volume_percentage\n",
        "\n",
        "    def get_order_execution_probability(self, order_id, current_time):\n",
        "        \"\"\" Calculate the probability of an order's execution based on volume percentage and the age of the order for Level 2 data. \"\"\"\n",
        "        order_details = self.active_orders[order_id]\n",
        "        book_side = self.bids if order_details['side'] == 'buy' else self.asks\n",
        "\n",
        "        total_volume_at_price = sum(v for p, v in book_side if p == order_details['price'])\n",
        "        if total_volume_at_price == 0:\n",
        "            return 0\n",
        "\n",
        "        volume_percentage = order_details['volume'] / total_volume_at_price\n",
        "\n",
        "        # Time factor based on order age\n",
        "\n",
        "        order_age = current_time - self.order_insertion_times[order_id]\n",
        "        time_factor = 1 + math.log(1 + order_age / TIME_FACTOR_CONSTANT)  # TIME_FACTOR_CONSTANT is a predefined constant\n",
        "\n",
        "        # Adjust probability based on volume percentage and time factor\n",
        "        adjusted_probability = volume_percentage * time_factor\n",
        "\n",
        "        return adjusted_probability\n",
        "\n",
        "    def check_order_execution(self, order_id, current_time):\n",
        "        \"\"\" Randomly determine if an order is executed based on its execution probability. \"\"\"\n",
        "        order_details = self.active_orders[order_id]\n",
        "        book_side = self.bids if order_details['side'] == 'buy' else self.asks\n",
        "\n",
        "        # Check if your order is the only order at that price level\n",
        "        total_volume_at_price = sum(v for p, v in book_side if p == order_details['price'])\n",
        "        if total_volume_at_price == order_details['volume']:\n",
        "            # If only your volume is present, execute the order\n",
        "            return True\n",
        "        probability = self.get_order_execution_probability(order_id, current_time)\n",
        "        return random.random() < probability\n",
        "\n",
        "    def process_market_data(self, market_data):\n",
        "        \"\"\" Simulate the arrival of new market data and update the order book. \"\"\"\n",
        "        print(f\"Simulating market data: {market_data}\")\n",
        "        ## Check for and execute any trades\n",
        "        updated_market_data = self.check_for_trade_executions(market_data)\n",
        "\n",
        "        # Update order book with the updated market data\n",
        "        if updated_market_data['side'] == 1.0:  # Bids\n",
        "            self.update_order_book_side(self.bids, updated_market_data, descending=True)\n",
        "        elif updated_market_data['side'] == -1.0:  # Asks\n",
        "            self.update_order_book_side(self.asks, updated_market_data, descending=False)\n",
        "\n",
        "\n",
        "        # Trim the order book and revise queue positions after updates\n",
        "        self.trim_order_book()\n",
        "        #self.revise_queue_positions(updated_market_data)\n",
        "\n",
        "        print(\"Finished simulating market data update\")\n",
        "\n",
        "    def check_for_trade_executions(self, update):\n",
        "        print(\"Checking for trade executions based on market update\")\n",
        "        trade_side = 'sell' if update['side'] == -1 else 'buy'  # Assuming '-1' represents sell in your system\n",
        "        remaining_volume = update['volume']\n",
        "        trade_price = update['price']\n",
        "        print(f\"Market Update - Side: {trade_side}, Price: {trade_price}, Volume: {remaining_volume}\")\n",
        "\n",
        "        # Choose the opposite book side to match trades\n",
        "        book_side = self.bids if trade_side == 'sell' else self.asks\n",
        "\n",
        "        for i, order in enumerate(book_side):\n",
        "            #print(f\"Checking Order {i} - Price: {order[0]}, Volume: {order[1]}\")\n",
        "            if (trade_side == 'sell' and order[0] >= trade_price) or (trade_side == 'buy' and order[0] <= trade_price):\n",
        "                #print(f\"Order meets trade conditions - Order Price: {order[0]}, Trade Price: {trade_price}\")\n",
        "                order_id = self.find_order_id_by_price(order[0], trade_side)\n",
        "                if order_id:\n",
        "                    #print(f\"Found Order ID {order_id} matching price {order[0]}\")\n",
        "                    if self.check_order_execution(order_id, update['local_timestamp']):\n",
        "                        matched_volume = min(order[1], remaining_volume)\n",
        "                        #print(f\"Matched Volume: {matched_volume} for Order ID {order_id}\")\n",
        "                        remaining_volume -= matched_volume\n",
        "\n",
        "                        # Update the order volume or remove the order if fully executed\n",
        "                        new_order_volume = order[1] - matched_volume\n",
        "                        if new_order_volume > 0:\n",
        "                            order_index = book_side.index(order)\n",
        "                            book_side[order_index] = (order[0], new_order_volume)\n",
        "                        else:\n",
        "                            book_side.remove(order)\n",
        "                            #print(f\"Order fully executed and removed from book - Order ID: {order_id}\")\n",
        "\n",
        "                        # Execute trade\n",
        "                        self.execute_trade(order_id, matched_volume, order[0])\n",
        "                        #print(f\"Executed trade for Order ID {order_id}, Volume: {matched_volume}, Price: {order[0]}\")\n",
        "\n",
        "                        if remaining_volume <= 0:\n",
        "                            #print(\"All volume matched, exiting loop\")\n",
        "                            break\n",
        "                    else:\n",
        "                        #print(f\"Order ID {order_id} did not meet execution criteria\")\n",
        "                        typee =0\n",
        "                else:\n",
        "                    #print(f\"No matching Order ID found for price {order[0]}\")\n",
        "                    typee =2\n",
        "            else:\n",
        "                #print(f\"Order at price {order[0]} does not meet trade conditions\")\n",
        "                typee =1\n",
        "\n",
        "        update['volume'] = remaining_volume\n",
        "        print(f\"Remaining volume after matching: {remaining_volume}\")\n",
        "        return update\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def find_next_price(self, current_price, side):\n",
        "        \"\"\" Find the next available price in the order book. \"\"\"\n",
        "        book_side = self.bids if side == 'sell' else self.asks  # Opposite side of the book\n",
        "        for price, volume in book_side:\n",
        "            if side == 'sell' and price < current_price:\n",
        "                return price\n",
        "            elif side == 'buy' and price > current_price:\n",
        "                return price\n",
        "        return current_price  # Return the same price if no next price is found\n",
        "\n",
        "    def should_execute_order(self, probability, order, update):\n",
        "        \"\"\" Determine if an order should be executed based on probability and update. \"\"\"\n",
        "        if (order['side'] == 'buy' and order['price'] >= update['price']) or \\\n",
        "           (order['side'] == 'sell' and order['price'] <= update['price']):\n",
        "            return probability > .5  # Define this threshold as needed\n",
        "        return False\n",
        "\n",
        "    def execute_trade(self, order_id, matched_volume, trade_price):\n",
        "        \"\"\" Execute a trade and return trade details. \"\"\"\n",
        "        # ... existing logic to execute the trade ...\n",
        "        side = 'side'\n",
        "        print(f'executing trade: orderId: {order_id}, side:  {self.active_orders[order_id][side]}, price: {trade_price}, volume: {matched_volume} ')\n",
        "        # Remove or update the order in the order book\n",
        "\n",
        "      # Append trade to my_trades\n",
        "        trade = {\n",
        "            'order_id': order_id,\n",
        "            'price': trade_price,\n",
        "            'volume': matched_volume,\n",
        "            'side': self.active_orders[order_id]['side']\n",
        "        }\n",
        "        self.my_trades.append(trade)  #\n",
        "\n",
        "    def calculate_trade_pnl(self, volume, price):\n",
        "        \"\"\" Calculate the profit or loss for a trade. \"\"\"\n",
        "        # Example profit or loss calculation, modify as needed\n",
        "        return volume * price  # Placeholder for PnL calculation logic\n",
        "\n",
        "    def update_order_book_side(self, book_side, update, descending):\n",
        "        price = update['price']\n",
        "        volume = update['volume']\n",
        "\n",
        "        # Calculate the total volume of your own orders at this price\n",
        "        my_volume_at_price = sum(order['volume'] for order_id, order in self.active_orders.items() if order['price'] == price)\n",
        "\n",
        "        # Find existing price and update or remove order\n",
        "        for i, (p, v) in enumerate(book_side):\n",
        "            if p == price:\n",
        "                # Update the total volume, ensuring to include your own volume\n",
        "                new_volume = max(volume + my_volume_at_price, 0)\n",
        "                if new_volume > 0:\n",
        "                    book_side[i] = (price, new_volume)\n",
        "                else:\n",
        "                    del book_side[i]  # Remove the price level if the total volume is zero\n",
        "                break\n",
        "        else:\n",
        "            # Add new price level if it doesn't exist and volume is non-zero\n",
        "            if volume > 0:\n",
        "                book_side.append((price, volume + my_volume_at_price))\n",
        "                book_side.sort(key=lambda x: x[0], reverse=descending)\n",
        "\n",
        "        # Truncate the order book to maintain the specified depth\n",
        "        if len(book_side) > self.depth:\n",
        "            book_side = book_side[:self.depth]\n",
        "\n",
        "\n",
        "\n",
        "    # No need to return anything as the book_side and sorted_prices are updated in place\n",
        "\n",
        "    def get_current_price(self):\n",
        "        \"\"\" Get the current price from the order book. \"\"\"\n",
        "        if self.bids and self.asks:\n",
        "            top_bid = self.bids[0][0]\n",
        "            top_ask = self.asks[0][0]\n",
        "            return (top_bid + top_ask) / 2  # Mid-price as the current price\n",
        "        return None  # Return None if the order book is empty\n",
        "\n",
        "    def get_current_book(self):\n",
        "        \"\"\" Returns the current bids and asks. \"\"\"\n",
        "        return self.bids[:self.depth], self.asks[:self.depth]\n",
        "\n",
        "\n",
        "    def get_best_bid_ask(self):\n",
        "        if self.bids and self.asks:\n",
        "            best_bid = self.bids[0][0]\n",
        "            best_ask = self.asks[0][0]\n",
        "            return best_bid, best_ask\n",
        "        return None, None\n",
        "\n",
        "    def find_order_index(self, book_side, price):\n",
        "        \"\"\" Find the index of an order in the order book side based on price. \"\"\"\n",
        "        for i, (p, _) in enumerate(book_side):\n",
        "            if p == price:\n",
        "                return i\n",
        "        return None\n",
        "\n",
        "    def trim_order_book(self):\n",
        "        \"\"\" Trim the order book to maintain the specified depth. \"\"\"\n",
        "        self.bids = self.bids[:self.depth]\n",
        "        self.asks = self.asks[:self.depth]\n",
        "\n",
        "    def remove_order(self, order_id):\n",
        "        \"\"\" Remove an order from the order book and return its details. \"\"\"\n",
        "        print(f\"Removing order: Order ID {order_id}\")\n",
        "        removed_order = None\n",
        "\n",
        "        if order_id in self.active_orders:\n",
        "            removed_order = self.active_orders[order_id]\n",
        "            book_side = self.bids if removed_order['side'] == 'buy' else self.asks\n",
        "            index = self.find_order_index(book_side, removed_order['price'])\n",
        "            if index is not None:\n",
        "                _, volume = book_side[index]\n",
        "                new_volume = volume - removed_order['volume']\n",
        "                if new_volume > 0:\n",
        "                    book_side[index] = (removed_order['price'], new_volume)\n",
        "                else:\n",
        "                    del book_side[index]\n",
        "            del self.active_orders[order_id]\n",
        "            # del self.order_insertion_times[order_id]\n",
        "            # del self.queue_position_estimate[order_id]\n",
        "\n",
        "        return removed_order\n",
        "\n",
        "    def remove_expired_orders(self, current_exchange_time):\n",
        "        \"\"\" Remove orders that have exceeded their lifetime and return their details. \"\"\"\n",
        "        expired_order_details = []\n",
        "        for order_id in list(self.active_orders.keys()):  # Use a list of keys to avoid runtime error\n",
        "            order_details = self.active_orders[order_id]\n",
        "            if order_details['expiration'] <= current_exchange_time:\n",
        "                removed_order = self.remove_order(order_id)\n",
        "                expired_order_details.append(removed_order)\n",
        "        return expired_order_details\n",
        "\n",
        "class PositionManager:\n",
        "    def __init__(self):\n",
        "        self.positions = {}  # Dictionary to store positions by asset\n",
        "        self.maker_fee_percent = 0.0016  # Maker fee as a percentage (0.16%)\n",
        "        self.realized_pnl = 0  # Realized profit and loss\n",
        "\n",
        "    def update_position(self, trade):\n",
        "        print(f\"Received trade: {trade}\")  # Debugging\n",
        "        asset = trade['asset']  # Assuming the trade dict has an 'asset' key\n",
        "        side, volume, trade_price = trade['side'], trade['volume'], trade['price']\n",
        "\n",
        "        # Ensure volume and trade_price are numerical\n",
        "        if not isinstance(volume, (int, float)) or not isinstance(trade_price, (int, float)):\n",
        "            print(\"Error: Volume or trade_price is not a number.\")\n",
        "            return 0\n",
        "\n",
        "        if asset not in self.positions:\n",
        "            self.positions[asset] = {'size': 0, 'avg_price': 0, 'unrealized_pnl': 0}\n",
        "\n",
        "        current_position = self.positions[asset]\n",
        "        trade_pnl = 0  # Initialize trade PnL\n",
        "\n",
        "        # Calculate the maker fee\n",
        "        maker_fee = trade_price * volume * self.maker_fee_percent\n",
        "\n",
        "        # Calculate PnL based on the side of the trade\n",
        "        if side == 'buy':\n",
        "            # If buying, PnL is realized if it's closing or reducing a short position\n",
        "            if current_position['size'] < 0:\n",
        "                trade_pnl = (current_position['avg_price'] - trade_price) * min(volume, -current_position['size']) - maker_fee\n",
        "        else:  # side == 'sell'\n",
        "            # If selling, PnL is realized if it's closing or reducing a long position\n",
        "            if current_position['size'] > 0:\n",
        "                trade_pnl = (trade_price - current_position['avg_price']) * min(volume, current_position['size']) - maker_fee\n",
        "\n",
        "        # Update position size and average price\n",
        "        if side == 'buy':\n",
        "            new_size = current_position['size'] + volume\n",
        "            new_avg_price = ((current_position['size'] * current_position['avg_price']) + (volume * trade_price)) / new_size if new_size != 0 else 0\n",
        "        else:  # side == 'sell'\n",
        "            new_size = current_position['size'] - volume\n",
        "            new_avg_price = ((-current_position['size'] * current_position['avg_price']) + (volume * trade_price)) / -new_size if new_size != 0 else 0\n",
        "\n",
        "        current_position['size'] = new_size\n",
        "        current_position['avg_price'] = new_avg_price\n",
        "\n",
        "        # Update realized PnL\n",
        "        self.realized_pnl += trade_pnl\n",
        "\n",
        "        # Update unrealized PnL if there's an open position\n",
        "        if new_size != 0:\n",
        "            current_position['unrealized_pnl'] = (trade_price - new_avg_price) * new_size\n",
        "        else:\n",
        "            current_position['unrealized_pnl'] = 0\n",
        "\n",
        "        print(f\"New position size: {current_position['size']}, New average price: {current_position['avg_price']}, Realized PnL: {self.realized_pnl}\")\n",
        "        return trade_pnl\n",
        "\n",
        "\n",
        "    # Accessor methods...\n",
        "    def get_realized_pnl(self):\n",
        "        return self.realized_pnl\n",
        "\n",
        "    def get_inventory(self, asset='BTC'):\n",
        "        return self.positions.get(asset, {'size': 0})['size']\n",
        "\n",
        "    def get_position(self, asset='BTC'):\n",
        "        return self.positions.get(asset, {'size': 0, 'avg_price': 0})\n",
        "\n",
        "\n",
        "    def get_position_size(self):\n",
        "        \"\"\" Get the current position size for BTC. \"\"\"\n",
        "        # Access 'BTC' position size from the positions dictionary\n",
        "        btc_position = self.positions.get('BTC', {'size': 0})\n",
        "        return btc_position['size']\n",
        "\n",
        "    def get_average_entry_price(self):\n",
        "        \"\"\" Get the average entry price for BTC. \"\"\"\n",
        "        # Access 'BTC' average price from the positions dictionary\n",
        "        btc_position = self.positions.get('BTC', {'avg_price': 0})\n",
        "        return btc_position['avg_price']\n",
        "\n",
        "\n",
        "class StatisticsManager:\n",
        "    def __init__(self):\n",
        "        self.total_pnl = 0\n",
        "        self.total_volume = 0\n",
        "        self.trades = []\n",
        "        self.winning_trades = 0\n",
        "        self.daily_returns = []  # Assuming daily returns are stored here\n",
        "\n",
        "        self.losing_trades = 0\n",
        "        self.total_win_amount = 0\n",
        "        self.total_loss_amount = 0\n",
        "\n",
        "    def record_trade(self, trade):\n",
        "        \"\"\" Record a trade and update statistics. \"\"\"\n",
        "        self.trades.append(trade)\n",
        "        self.calculate_pnl(trade)\n",
        "        self.total_volume += trade['volume']\n",
        "\n",
        "        # Count wins and losses\n",
        "        if trade['profit_loss'] > 0:\n",
        "            self.winning_trades += 1\n",
        "            self.total_win_amount += trade['profit_loss']\n",
        "        elif trade['profit_loss'] < 0:\n",
        "            self.losing_trades += 1\n",
        "            self.total_loss_amount += trade['profit_loss']\n",
        "\n",
        "    def calculate_pnl(self, trade):\n",
        "        \"\"\" Update total PnL based on the trade. \"\"\"\n",
        "        self.total_pnl += trade['profit_loss']\n",
        "\n",
        "    def get_pnl(self):\n",
        "        \"\"\" Get the total PnL. \"\"\"\n",
        "        return self.total_pnl\n",
        "\n",
        "    def get_average_win(self):\n",
        "        \"\"\" Calculate the average win amount per winning trade. \"\"\"\n",
        "        return self.total_win_amount / self.winning_trades if self.winning_trades > 0 else 0\n",
        "\n",
        "    def get_average_loss(self):\n",
        "        \"\"\" Calculate the average loss amount per losing trade. \"\"\"\n",
        "        return self.total_loss_amount / self.losing_trades if self.losing_trades > 0 else 0\n",
        "\n",
        "    def get_win_loss_ratio(self):\n",
        "        \"\"\" Calculate the win/loss ratio. \"\"\"\n",
        "        return self.winning_trades / self.losing_trades if self.losing_trades > 0 else float('inf')\n",
        "\n",
        "    def get_total_volume(self):\n",
        "        \"\"\" Get the total traded volume. \"\"\"\n",
        "        return self.total_volume\n",
        "\n",
        "    # Additional methods for other statistics can be added here.\n",
        "    def calculate_sharpe_ratio(self, risk_free_rate=0):\n",
        "        \"\"\" Calculate the Sharpe ratio. \"\"\"\n",
        "        excess_returns = np.array(self.daily_returns) - risk_free_rate\n",
        "        return np.mean(excess_returns) / np.std(excess_returns) if np.std(excess_returns) != 0 else 0\n",
        "\n",
        "    def calculate_sortino_ratio(self, risk_free_rate=0):\n",
        "        \"\"\" Calculate the Sortino ratio. \"\"\"\n",
        "        excess_returns = np.array(self.daily_returns) - risk_free_rate\n",
        "        negative_returns = [r for r in excess_returns if r < 0]\n",
        "        return np.mean(excess_returns) / np.std(negative_returns) if np.std(negative_returns) != 0 else 0\n",
        "\n",
        "    def calculate_risk_return_ratio(self):\n",
        "        \"\"\" Calculate the risk-return ratio. \"\"\"\n",
        "        if np.std(self.daily_returns) != 0:\n",
        "            return np.mean(self.daily_returns) / np.std(self.daily_returns)\n",
        "        return 0\n",
        "\n",
        "    def calculate_annualized_return(self, trading_days=252):\n",
        "        \"\"\" Calculate the annualized return. \"\"\"\n",
        "        cumulative_return = np.prod([1 + r for r in self.daily_returns]) - 1\n",
        "        return (1 + cumulative_return) ** (trading_days / len(self.daily_returns)) - 1\n",
        "\n",
        "    def calculate_max_drawdown(self):\n",
        "        \"\"\" Calculate the maximum drawdown. \"\"\"\n",
        "        cumulative_returns = np.cumprod([1 + r for r in self.daily_returns])\n",
        "        peak = np.maximum.accumulate(cumulative_returns)\n",
        "        drawdown = (peak - cumulative_returns) / peak\n",
        "        return np.max(drawdown)\n",
        "\n",
        "\n",
        "    def calculate_current_return(self, initial_capital):\n",
        "        \"\"\" Calculate the current return as a percentage of the initial capital. \"\"\"\n",
        "        if initial_capital <= 0:\n",
        "            raise ValueError(\"Initial capital must be greater than zero.\")\n",
        "\n",
        "        current_return = (self.total_pnl / initial_capital) * 100\n",
        "        return current_return\n",
        "\n",
        "    def print_summary(self, capital=None):\n",
        "        \"\"\" Print a summary of the trading statistics. \"\"\"\n",
        "        # Assuming the necessary metrics are calculated and stored in the class attributes\n",
        "        print('=========== Summary ===========')\n",
        "        print(f'Sharpe ratio: {self.sharpe_ratio:.1f}')\n",
        "        print(f'Sortino ratio: {self.sortino_ratio:.1f}')\n",
        "        print(f'Risk-return ratio: {self.risk_return_ratio:.1f}')\n",
        "\n",
        "        if capital is not None:\n",
        "            annualised_return_percentage = self.annualised_return / capital * 100\n",
        "            max_drawdown_percentage = self.max_drawdown / capital * 100\n",
        "            print(f'Annualised return: {annualised_return_percentage:.2f} %')\n",
        "            print(f'Max. draw down: {max_drawdown_percentage:.2f} %')\n",
        "        else:\n",
        "            print(f'Annualised return: {self.annualised_return:.2f}')\n",
        "            print(f'Max. draw down: {self.max_drawdown:.2f}')\n",
        "\n",
        "        print(f'The number of trades per day: {self.trades_per_day}')\n",
        "        print(f'Avg. daily trading volume: {self.avg_daily_volume}')\n",
        "        print(f'Avg. daily trading amount: {self.avg_daily_amount}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class TradingSimulation:\n",
        "    def __init__(self):\n",
        "        self.price = []  # Store price data\n",
        "        self.posi_arr = []  # Store positions data\n",
        "        self.inventory = []  # Store inventory data\n",
        "        self.pnl_arr = []  # Store PnL data\n",
        "        self.trade_data = []  # Store trade execution data\n",
        "        self.render_on = False\n",
        "\n",
        "    def _plot_trading(self):\n",
        "        # Ensure that there is data to plot and check data types\n",
        "        if not self.price:\n",
        "            print(\"Price data not available to plot.\")\n",
        "            return\n",
        "\n",
        "        # Debugging: Print data types\n",
        "        print(f\"Data types - Price: {type(self.price)}, Position: {type(self.posi_arr)}, Inventory: {type(self.inventory)}, PnL: {type(self.pnl_arr)}\")\n",
        "\n",
        "        # Check if data are lists of numbers and plot only if they are valid\n",
        "        if not all(isinstance(x, (int, float)) for x in self.price):\n",
        "            print(\"Price data contains non-numeric values.\")\n",
        "            return\n",
        "\n",
        "        # Time axis (x-axis)\n",
        "        time_axis = list(range(len(self.price)))\n",
        "\n",
        "        # Clear previous plots if necessary\n",
        "        self.ax.clear()\n",
        "        self.ax2.clear()\n",
        "        self.ax4.clear()\n",
        "        self.ax5.clear()\n",
        "\n",
        "        # Plotting trade executions\n",
        "        buy_trades = [trade for trade in self.trade_data if trade['side'] == 'buy']\n",
        "        sell_trades = [trade for trade in self.trade_data if trade['side'] == 'sell']\n",
        "\n",
        "        # Plot trades on the price chart\n",
        "        self.ax.scatter([trade['time'] for trade in buy_trades], [trade['price'] for trade in buy_trades], color='green', marker='^', label='Buy Trades', s=50)\n",
        "        self.ax.scatter([trade['time'] for trade in sell_trades], [trade['price'] for trade in sell_trades], color='red', marker='v', label='Sell Trades', s=50)\n",
        "\n",
        "        # Plotting price data\n",
        "        self.ax.plot(time_axis, self.price, color='cyan', label='Price', linewidth=2)\n",
        "\n",
        "        # Plotting positions if available and valid\n",
        "        if isinstance(self.posi_arr, dict):\n",
        "            # Convert dictionary to list or handle it as per your logic\n",
        "            positions_list = [self.posi_arr.get(i, None) for i in time_axis]  # Example conversion\n",
        "            self.ax2.plot(time_axis, positions_list, color='blue', label='Position', linewidth=2)\n",
        "\n",
        "        # Plotting inventory if available and valid\n",
        "        if isinstance(self.inventory, dict):\n",
        "            # Convert dictionary to list or handle it as per your logic\n",
        "            inventory_list = [self.inventory.get(i, None) for i in time_axis]  # Example conversion\n",
        "            self.ax4.plot(time_axis, inventory_list, color='purple', label='Inventory', linewidth=2)\n",
        "\n",
        "        # Plotting PnL if available and valid\n",
        "        if self.pnl_arr and all(isinstance(x, (int, float)) for x in self.pnl_arr):\n",
        "            self.ax5.plot(time_axis, self.pnl_arr, color='orange', label='PnL', linewidth=2)\n",
        "\n",
        "        # Adding legends and labels\n",
        "        self.ax.legend(loc='upper left')\n",
        "        self.ax2.legend(loc='upper right')\n",
        "        self.ax4.legend(loc='upper left')\n",
        "        self.ax5.legend(loc='upper left')\n",
        "\n",
        "        self.ax.set_xlabel('Time Steps')\n",
        "        self.ax.set_ylabel('Price')\n",
        "        self.ax2.set_ylabel('Positions')\n",
        "        self.ax4.set_ylabel('Inventory')\n",
        "        self.ax5.set_ylabel('PnL')\n",
        "\n",
        "        # Adjust and display the plot\n",
        "        plt.draw()\n",
        "        plt.pause(0.1)\n",
        "\n",
        "    def render(self, save=False):\n",
        "        if not self.render_on:\n",
        "            plt.style.use('dark_background')\n",
        "            self.render_on = True\n",
        "\n",
        "            # Define the layout for subplots\n",
        "            left, width = 0.1, 0.8\n",
        "            rect_price = [left, 0.4, width, 0.2]\n",
        "            rect_positions = [left, 0.2, width, 0.15]\n",
        "            rect_inventory = [left, 0.6, width, 0.2]\n",
        "            rect_pnl = [left, 0.75, width, 0.15]\n",
        "\n",
        "            self.fig = plt.figure(figsize=(15, 9))\n",
        "            self.fig.suptitle('Trading Simulation', fontsize=14, fontweight='bold')\n",
        "\n",
        "            # Create subplots\n",
        "            self.ax = self.fig.add_axes(rect_price)  # Price chart\n",
        "            self.ax2 = self.fig.add_axes(rect_positions, sharex=self.ax)  # Positions chart\n",
        "            self.ax4 = self.fig.add_axes(rect_inventory, sharex=self.ax)  # Inventory chart\n",
        "            self.ax5 = self.fig.add_axes(rect_pnl, sharex=self.ax)  # PnL chart\n",
        "\n",
        "            # Set grid and styling for each subplot\n",
        "            for ax in [self.ax, self.ax2, self.ax4, self.ax5]:\n",
        "                ax.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "            self._plot_trading()\n",
        "\n",
        "        if save:\n",
        "            self.fig.savefig(f'fig/{self.t_index}.png')\n",
        "\n",
        "\n",
        "    # Other methods as needed\n",
        "\n",
        "\n",
        "# Corrected BacktestEngine with event processing and handler methods\n",
        "\n",
        "class BacktestEngine:\n",
        "    def __init__(self, market_data_stream, population_size, num_generations, actor_critic_hyperparams, ppo_hyperparams, rollout_buffer_params, evolutionary_training_config):\n",
        "        self.market_data_stream = market_data_stream\n",
        "        self.population_size = population_size\n",
        "        self.num_generations = num_generations\n",
        "        self.actor_critic_hyperparams = actor_critic_hyperparams\n",
        "        self.ppo_hyperparams = ppo_hyperparams\n",
        "        self.rollout_buffer_params = rollout_buffer_params\n",
        "        self.initial_capital = 500\n",
        "        self.current_capital = self.initial_capital\n",
        "        #self.env = gym.make(env_name)  # Replace with your specific environment\n",
        "        self.penalty_threshold = -2000\n",
        "        # Initialize components for backtesting\n",
        "        self.lob = OrderBook()  # Limit Order Book\n",
        "        self.volatility_manager = VolatilityManager()\n",
        "        self.portfolio_manager = PortfolioManager(self.current_capital)\n",
        "        self.trading_manager = TradeUpdateManager()\n",
        "\n",
        "        self.evolutionary_training_config = evolutionary_training_config\n",
        "        self.evolutionary_model = EvolutionaryModel( self.actor_critic_hyperparams, self.ppo_hyperparams, self.rollout_buffer_params,  self.lob,  self.evolutionary_training_config, self.volatility_manager, self.portfolio_manager, self.current_capital, self.trading_manager)#self.env,\n",
        "        #self.statistics_manager = StatisticsManager()\n",
        "        #self.trading_simulation = TradingSimulation()\n",
        "        #self.strategy = SimpleTwoSidedQuoteStrategy(max_position=100, order_qty=20)\n",
        "\n",
        "        self.current_time = 0\n",
        "        self.train_counter = 0\n",
        "        self.drawdown_max = 0.007\n",
        "        # Initialize timing for training and evolution\n",
        "        self.TRAINING_INTERVAL = 5 * 60 * 1000000  # 30 minutes in seconds\n",
        "        self.EVOLUTION_INTERVAL = 10 * 60 * 1000000  # 2 hours in seconds\n",
        "        self.TRAINING_FREQUENCY = 4\n",
        "        self.training_interval = self.EVOLUTION_INTERVAL / self.TRAINING_FREQUENCY\n",
        "        self.next_training_time = 0\n",
        "        self.next_evolution_time = self.EVOLUTION_INTERVAL\n",
        "        self.current_generation = 0\n",
        "\n",
        "        # ... Other initialization ...\n",
        "\n",
        "\n",
        "    def calculate_next_training_time(self, current_time):\n",
        "        # Logic to calculate the next training time\n",
        "        return current_time + self.TRAINING_INTERVAL\n",
        "\n",
        "    def calculate_next_evolution_time(self, current_time):\n",
        "        # Logic to calculate the next evolution time\n",
        "        return current_time + self.EVOLUTION_INTERVAL\n",
        "\n",
        "    def update_next_training_time(self):\n",
        "        # Update the next training time based on the current local exchange time\n",
        "        if self.train_counter % TRAINING_FREQUENCY == 0:\n",
        "            self.next_training_time = self.current_time + EVOLUTION_INTERVAL\n",
        "            self.next_evolution_time = self.next_training_time\n",
        "        else:\n",
        "            self.next_training_time += EVOLUTION_INTERVAL / TRAINING_FREQUENCY\n",
        "\n",
        "        self.train_counter += 1\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        print(\"Starting backtest...\")\n",
        "        warm_up_duration =  8 * 60 * 1000000    # 30 minutes in seconds\n",
        "        warm_up_start_time = None\n",
        "        warm_up_complete = False\n",
        "        pop_reduced = False\n",
        "\n",
        "        with tqdm(total=self.num_generations, desc=\"Processing Generations\") as pbar:\n",
        "            for index, market_data in self.market_data_stream.iterrows():\n",
        "                #if isinstance(market_data, dict) and 'local_timestamp' in market_data:\n",
        "                self.current_time = market_data['local_timestamp']\n",
        "                    # ... rest of the code ...\n",
        "                #else:\n",
        "                    # Handle the case where market_data is not as expected\n",
        "                    #print(f\"Unexpected market_data format: {market_data}\")\n",
        "                            # Start warm-up timer on first data point\n",
        "                if warm_up_start_time is None:\n",
        "                    warm_up_start_time = self.current_time\n",
        "                    print(warm_up_start_time)\n",
        "                    print(\"Warm-up period started.\")\n",
        "\n",
        "                # Check if warm-up period is complete\n",
        "                if not warm_up_complete and self.current_time - warm_up_start_time >= warm_up_duration:\n",
        "                    warm_up_complete = True\n",
        "                    self.next_training_time = self.calculate_next_training_time(self.current_time)\n",
        "                    self.next_evolution_time = self.calculate_next_evolution_time(self.current_time)\n",
        "                    print(\"Warm-up period complete. Starting main process.\")\n",
        "\n",
        "                # Process market and trade data\n",
        "                print(\"market_data type:\", type(market_data))\n",
        "                print(\"market_data content:\", market_data)\n",
        "\n",
        "                if market_data['event'] == 1:  # Market data update\n",
        "                    print(\"Processing market data update\")\n",
        "                    self.simulate_market_data(market_data)\n",
        "                    self.process_market_data(market_data, self.evolutionary_model, self.rollout_buffer_params, warm_up_complete) #self.process_market_data(market_data)\n",
        "                    print(\"Finished processing market data update\")\n",
        "                elif market_data['event'] == 2:  # Trade execution event\n",
        "                    print(\"Processing trade data update\")\n",
        "                    self.process_trade_execution(market_data)\n",
        "                    self.process_trade_data(market_data, self.evolutionary_model, self.rollout_buffer_params, warm_up_complete)\n",
        "                    print(\"Finished processing trade data update\")\n",
        "\n",
        "                # Train models and evolve population after warm-up is complete\n",
        "                if warm_up_complete :\n",
        "                    if self.current_time >= self.next_training_time:\n",
        "                        self.train_and_update_models()\n",
        "                        self.next_training_time = self.calculate_next_training_time(self.current_time)\n",
        "\n",
        "                    if self.current_time >= self.next_evolution_time and pop_reduced == False:\n",
        "                        self.evolutionary_model.evolve_population()\n",
        "                        self.next_evolution_time = self.calculate_next_evolution_time(self.current_time)\n",
        "\n",
        "                        for model in self.evolutionary_model.population:\n",
        "                            model.ppo.target_entropy =  model.ppo.target_entropy - 0.05\n",
        "                        self.current_generation += 1\n",
        "\n",
        "                        pbar.update(1)\n",
        "                        tqdm.write(f\"Generation {self.current_generation}/{self.num_generations} completed.\")\n",
        "\n",
        "                    # Check if all generations are concluded\n",
        "                    if pop_reduced == False:\n",
        "                        if self.current_generation >= self.num_generations:\n",
        "                            top_performers = self.evolutionary_model.select_top_performers(3)\n",
        "                            pop_reduced = True\n",
        "\n",
        "                            self.TRAINING_INTERVAL = 2 * 60 * 60 # 2 hours in seconds\n",
        "                            self.calculate_next_training_time(self.current_time)\n",
        "                            print(\"All generations concluded. Continuing training with top performers.\")\n",
        "\n",
        "\n",
        "                # Additional backtesting logic if needed\n",
        "        print(\"Backtest completed.\")\n",
        "\n",
        "    def round_price(self, price):\n",
        "        \"\"\"\n",
        "        Rounds the price to a maximum of 5 decimal places.\n",
        "        \"\"\"\n",
        "        return round(price, 5)\n",
        "\n",
        "    def adjust_order_size(self, size, price, aum):\n",
        "        \"\"\"\n",
        "        Ensures the order size is at least the minimum required size, does not exceed available capital,\n",
        "        and is within 5% of the AUM.\n",
        "        \"\"\"\n",
        "        if size <= 0:\n",
        "            return -1\n",
        "        MIN_ORDER_SIZE = 10  # Minimum order size\n",
        "        MAX_SIZE_BASED_ON_AUM = (0.05 * aum) / price  # Maximum size as 5% of AUM\n",
        "\n",
        "        # Choose the smaller of the two maximum sizes\n",
        "\n",
        "\n",
        "        adjusted_size = max(round(MAX_SIZE_BASED_ON_AUM, 0), MIN_ORDER_SIZE)\n",
        "        return adjusted_size\n",
        "\n",
        "    def place_order(self, order_size, order_price, is_buy):\n",
        "        # Logic to place an order\n",
        "        order_id = self.generate_order_id()\n",
        "        order = {'order_id': order_id, 'price': order_price, 'size': order_size, 'timestamp': self.current_time, 'side': is_buy}\n",
        "        # Logic to add order to the system\n",
        "        # ...\n",
        "        return  order_id,  order_price,  order_size, is_buy\n",
        "\n",
        "    def process_action(self, action, model):\n",
        "        print(\"Starting process_action...\")\n",
        "        # Unpack the action array\n",
        "        action = action.flatten()\n",
        "        bid_price_adjustment, ask_price_adjustment, buy_order_size, sell_order_size, hold, target_inventory_level, cancellation_intensity, cancellation_strategy = action\n",
        "        print(f\"Action unpacked: {action}\")\n",
        "        # Retrieve current inventory and mid-price\n",
        "        current_inventory = model.environment.order_manager.inventory\n",
        "        current_mid_price = model.environment.market_data_transformation.cached_mid_price if model.environment.market_data_transformation.cached_mid_price else 0\n",
        "        print(f\"Current inventory: {current_inventory}, Current mid-price: {current_mid_price}\")\n",
        "\n",
        "        # Initialize a list to keep track of orders\n",
        "        orders = []\n",
        "        t_i_l = (model.environment.initial_capital * target_inventory_level)\n",
        "        print(f\"Target inventory level: {t_i_l}\")\n",
        "        model.environment.order_manager.update_target_inventory(t_i_l)\n",
        "        # Process 'hold' action\n",
        "        print(f\"Hold action value: {hold}\")\n",
        "        if hold < 0.5:\n",
        "            # Calculate bid and ask prices\n",
        "            bid_price = self.round_price(current_mid_price * (1 + bid_price_adjustment))\n",
        "            ask_price = self.round_price(current_mid_price * (1 + ask_price_adjustment))\n",
        "            print(f\"Bid price: {bid_price}, Ask price: {ask_price}\")\n",
        "\n",
        "            current_time = self.current_time\n",
        "\n",
        "            # Adjust order sizes\n",
        "            adjusted_buy_order_size = self.adjust_order_size(buy_order_size, bid_price, model.environment.initial_capital)\n",
        "\n",
        "            # Check against target inventory level before placing buy orders\n",
        "            if adjusted_buy_order_size > 0 :\n",
        "                if model.environment.cash_balance >= adjusted_buy_order_size * bid_price:\n",
        "                    order_id, price, volume, side = self.place_order(adjusted_buy_order_size, bid_price, is_buy='buy')\n",
        "                    model.lob_instance.place_limit_order(order_id, price, volume, side, current_time)\n",
        "                    model.environment.order_manager.place_order(order_id, volume, price, side, current_time)\n",
        "                    model.environment.rate_limiter.update_on_order_placement(current_time)\n",
        "\n",
        "                    #ratelimiter\n",
        "\n",
        "            adjusted_sell_order_size = self.adjust_order_size(sell_order_size, ask_price, model.environment.initial_capital)\n",
        "\n",
        "            # Check against target inventory level before placing sell orders\n",
        "\n",
        "            if adjusted_sell_order_size > 0 :\n",
        "                # Check if there's enough cash balance to place the sell order\n",
        "                if model.environment.cash_balance >= adjusted_sell_order_size * ask_price:\n",
        "                    # Logic to place the sell order, assuming short selling is always allowed\n",
        "                    order_id, price, volume, side = self.place_order(adjusted_sell_order_size, ask_price, is_buy='sell')\n",
        "                    model.lob_instance.place_limit_order(order_id, price, volume, side, current_time)\n",
        "                    model.environment.order_manager.place_order(order_id, volume, price, side, current_time)\n",
        "                    # Increment the rate limiter\n",
        "                    model.environment.rate_limiter.update_on_order_placement(current_time)\n",
        "\n",
        "\n",
        "        # Update target inventory level regardless of 'hold' action\n",
        "\n",
        "\n",
        "        # Handle order cancellation if necessary\n",
        "        if cancellation_strategy > 0.6:\n",
        "            model.environment.process_cancellation(model, cancellation_intensity, cancellation_strategy, self.current_time)\n",
        "            print(\"Order cancellation logic executed\")\n",
        "\n",
        "\n",
        "\n",
        "        # Update the rate limiter based on the actions taken\n",
        "        # model.rate_limiter.update_rate_limit_status()\n",
        "\n",
        "        # return orders\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def process_market_data(self, market_data, evolutionary_model, hyperparams):\n",
        "    #     for i, model in enumerate(evolutionary_model.population):\n",
        "    #         # Step 1: Update model's LOB instance with market data\n",
        "    #         model.lob_instance.process_market_data(market_data)\n",
        "    #         #order_book_lob = model.lob_instance.get_order_book()\n",
        "    #         # Step 2: Construct State Vector\n",
        "    #         current_time = market_data['local_timestamp']\n",
        "    #         #model.environment.orderbook.update_order_book(market_data) THIS FUCNTION IS IMPORTANT FOR LIVE\n",
        "    #         model.environment.order_book_manager.update_from_lob_instance(model.lob_instance)\n",
        "\n",
        "\n",
        "    #         if  self.model.decision_time < current_time or self.model.decision_time == None:\n",
        "    #             start_time = time.time()\n",
        "    #             order_book_snapshots = model.environment.orderbook.get_order_book_history()\n",
        "    #             current_trades = model.environment.trade_update_manager.get_latest_trades()\n",
        "\n",
        "\n",
        "    #             state = model.environment.market_data_transformation.construct_state_vector(order_book_snapshots, current_trades)\n",
        "\n",
        "    #             # Step 3: Sample Action from the model\n",
        "    #             action, log_prob, value = model.actor_critic.act(state)\n",
        "    #             action = action.cpu().numpy()\n",
        "\n",
        "    #             # Step 4: Process Action in Market Environment\n",
        "    #             self.process_action(action, model)\n",
        "    #             end_time = time.time()\n",
        "    #             print(f'Time taken to process action: {end_time-start_time}')\n",
        "    #             calc_time = end_time - start_time\n",
        "    #             self.model.decision_time = current_time + calc_time\n",
        "    #         else:\n",
        "    #             self.rate_limiter.simulate_time_step(current_time)\n",
        "\n",
        "    #         book = model.lob_istance.get_order_book()\n",
        "\n",
        "    #         # Step 5: Retrieve recent trades executed by the model\n",
        "    #         recent_trades = model.lob_instance.get_my_recent_trades()\n",
        "\n",
        "    #         # Step 6: Update Order Management with Trade Data\n",
        "    #         self.update_order_manager(model.environment.order_manager, recent_trades)\n",
        "\n",
        "\n",
        "    #         # Step 7: Calculate Reward\n",
        "    #         reward = self.get_reward(model, market_data)\n",
        "    #         model.performance mulated_reward += reward  # Accumulate reward for the model\n",
        "\n",
        "    #         print(f'Reward: {reward}')\n",
        "    #         # Step 8: Check if Episode is Done\n",
        "    #         done, termination_reason = self.check_if_done(model, market_data)\n",
        "\n",
        "    #         # Step 9: Update the Rollout Buffer\n",
        "    #         model.rollout_buffer.add(state, action, reward, log_prob, value, done)\n",
        "\n",
        "    #         if done:\n",
        "    #             # Reset the model's state for a new training session\n",
        "    #             self.train_model(model, hyperparams)\n",
        "    #             self.reset_model_state(model)\n",
        "\n",
        "    def process_market_data(self, market_data, evolutionary_model, hyperparams, warm_up_complete):\n",
        "        print(\"Starting process_market_data...\")\n",
        "        for i, model in enumerate(evolutionary_model.population):\n",
        "            print(f'Processing model {i}')\n",
        "\n",
        "            # Step 1: Update model's LOB instance with market data\n",
        "            model.lob_instance.process_market_data(market_data)\n",
        "            print(f'Market data updated for model {i}')\n",
        "\n",
        "            # Step 2: Construct State Vector\n",
        "            current_time = market_data['local_timestamp']\n",
        "            model.environment.orderbook.update_from_lob_instance(model.lob_instance)\n",
        "\n",
        "            print(f'State vector constructed for model {i}')\n",
        "\n",
        "            # Only process actions if warm-up is complete\n",
        "            if warm_up_complete:\n",
        "                print(\"Warm-up complete, processing actions\")\n",
        "                if model.decision_time is None or model.decision_time < current_time:\n",
        "\n",
        "                    start_time = time.time()\n",
        "                    order_book_snapshots = model.environment.orderbook.get_order_book_history()\n",
        "                    current_trades = model.environment.trade_update_manager.get_latest_trades()\n",
        "                    print(f\"Order book snapshots and current trades retrieved for model {i}\")\n",
        "                    model.lob_instance.display_book()\n",
        "                    num, state = model.environment.market_data_transformation.construct_state_vector(order_book_snapshots, current_trades, current_time)\n",
        "                    if num == 1:\n",
        "                        action, log_prob, value = model.actor_critic.act(state)\n",
        "                        #action = action.cpu().numpy() GPU\n",
        "                        action = action.detach().cpu().numpy()\n",
        "\n",
        "                        print(f\"Action sampled from model {i}: {action}\")\n",
        "\n",
        "                        # Step 4: Process Action in Market Environment\n",
        "                        self.process_action(action, model)\n",
        "                        end_time = time.time()\n",
        "                        calc_time = end_time - start_time\n",
        "                        print(f\"Action processed for model {i}. Time taken: {calc_time}\")\n",
        "                        model.decision_time = current_time + calc_time\n",
        "                    else:\n",
        "                      continue\n",
        "                else:\n",
        "                    self.rate_limiter.simulate_time_step(current_time)\n",
        "                    #rint(\"Rate limiter simulated time step\")\n",
        "\n",
        "                # Step 5: Retrieve recent trades executed by the model\n",
        "                recent_trades = model.lob_instance.get_my_recent_trades()\n",
        "                print(f\"Recent trades retrieved for model {i}\")\n",
        "                if recent_trades:\n",
        "                      # Step 7: Update Order Management with Trade Data\n",
        "                      self.update_order_manager(model, recent_trades, current_time)\n",
        "                      print(f\"Order manager updated for model {i}\")\n",
        "                else:\n",
        "                      print(f\"No recent trades for model {i}, skipping order manager update\")\n",
        "                print(f'Current time: {current_time}')\n",
        "                print(f'Decision time: {model.decision_time}')\n",
        "\n",
        "\n",
        "                # Step 7: Calculate Reward\n",
        "                reward = self.get_reward(model, market_data)\n",
        "                model.performance += reward\n",
        "                print(f\"Reward calculated for model {i}: {reward}\")\n",
        "\n",
        "                # Step 8: Check if Episode is Done\n",
        "                done, termination_reason = self.check_if_done(model)\n",
        "                print(f\"Checked if episode is done for model {i}. Done: {done}, Reason: {termination_reason}\")\n",
        "\n",
        "                # Step 9: Update the Rollout Buffer\n",
        "                model.rollout_buffer.add(state, action, reward, log_prob, value, done)\n",
        "                print(f\"Rollout buffer updated for model {i}\")\n",
        "\n",
        "                if done:\n",
        "                    # Reset the model's state for a new training session\n",
        "                    self.train_model(model,hyperparams)\n",
        "                    self.reset_model_state(model)\n",
        "                    print(f\"Model {i} state reset for new training session\")\n",
        "\n",
        "        print(\"Finished process_market_data\")\n",
        "\n",
        "\n",
        "            # Additional checks or updates can be added here if necessary\n",
        "\n",
        "# ... [Rest of the methods]\n",
        "\n",
        "    def get_reward(self, model, market_data):\n",
        "        # Calculate the reward for the given model using its reward manager\n",
        "        reward = model.environment.reward_manager._get_reward(self.current_time)#model, market_data\n",
        "        return reward\n",
        "\n",
        "    def reset_model_state(self, model):\n",
        "        # Reset the model's LOB to the base state\n",
        "        model.lob_instance = copy.deepcopy(self.lob)\n",
        "        model.trading_manager = copy.deepcopy(self.trading_manager)\n",
        "\n",
        "        model.portfolio_manager = copy.deepcopy(self.portfolio_manager)\n",
        "        model.volatility_manager = copy.deepcopy(self.volatility_manager)\n",
        "\n",
        "        model.environment = ContinuousTradingEnvironment(model.volatility_manager, model.portfolio_manager, self.initial_capital, model.trading_manager)\n",
        "        # Reset the accumulated reward\n",
        "        model.performance = 0\n",
        "        # Reset the model's internal state\n",
        "        # model.reset()\n",
        "\n",
        "    def check_if_done(self, model):\n",
        "        # Check various conditions from the Reward class\n",
        "        if self.check_drawdown_condition(model):\n",
        "            return True, \"Drawdown limit exceeded\"\n",
        "        if self.check_penalty_threshold(model):\n",
        "            return True, \"Penalty threshold exceeded\"\n",
        "        if self.check_capital_depletion(model):\n",
        "            return True, \"Capital depleted\"\n",
        "\n",
        "        # Other conditions...\n",
        "\n",
        "        return False, \"\"\n",
        "\n",
        "    # Example helper methods for different conditions\n",
        "    def check_drawdown_condition(self, model):\n",
        "        # Check if the drawdown exceeds a certain threshold\n",
        "        drawdown_penalty = self.get_drawdown_penalty(model)\n",
        "        return drawdown_penalty > self.drawdown_max\n",
        "\n",
        "    def check_penalty_threshold(self, model):\n",
        "        # Check if the total penalty exceeds a certain threshold\n",
        "        rate_limit_penalty = model.environment.rate_limiter.get_usage_percentage()\n",
        "\n",
        "        percentage = rate_limit_penalty / 100\n",
        "\n",
        "        return percentage > 1\n",
        "\n",
        "    def check_capital_depletion(self, model):\n",
        "        # Check for capital depletion using the capital stored in the model's environment\n",
        "        current_capital = model.environment.portfolio_manager.current_capital\n",
        "        return current_capital < 250\n",
        "\n",
        "    def select_top_performers(self, num_top_performers, model):\n",
        "        sorted_population = sorted(self.population, key=lambda model: model.performance, reverse=True)\n",
        "        return sorted_population[:num_top_performers]\n",
        "\n",
        "\n",
        "    def get_drawdown_penalty(self, model):\n",
        "        # Calculate the drawdown penalty using the drawdown manager\n",
        "        drawdown_penalty = model.environment.reward_manager.get_drawdown_penalty()\n",
        "        return drawdown_penalty\n",
        "\n",
        "    def process_trade_data(self, market_data, evolutionary_model, hyperparams, warm_up_complete):\n",
        "        print(\"Starting process_trade_data...\")\n",
        "        for i, model in enumerate(evolutionary_model.population):\n",
        "            print(f'Processing trade data for model {i}')\n",
        "\n",
        "            # Step 1: Update model's LOB instance with market data\n",
        "            current_time = market_data['local_timestamp']\n",
        "            model.lob_instance.handle_trade_execution(market_data)\n",
        "            self.trading_manager.update_trades(market_data)\n",
        "            model.environment.trade_update_manager.update_trades(market_data)\n",
        "            model.volatility.update_tick_data(market_data, current_time)\n",
        "            print(f'Market data and trade execution updated for model {i}')\n",
        "\n",
        "            if warm_up_complete:\n",
        "                print(\"Warm-up complete, processing actions\")\n",
        "                if model.decision_time is None or model.decision_time < current_time:\n",
        "\n",
        "                    start_time = time.time()\n",
        "\n",
        "                    # Step 2: Retrieve the entire order book history and current trades\n",
        "                    order_book_history = model.environment.orderbook.get_order_book_history()\n",
        "                    current_trades = model.environment.trade_update_manager.get_latest_trades()\n",
        "                    print(f\"Order book history and current trades retrieved for model {i}\")\n",
        "\n",
        "                    # Step 3: Construct State Vector\n",
        "                    num, state = model.environment.market_data_transformation.construct_state_vector(order_book_history, current_trades, current_time)\n",
        "                    print(f\"State vector constructed for model {i}\")\n",
        "                    if num == 1:\n",
        "\n",
        "                        # Step 4: Sample Action from the model\n",
        "                        action, log_prob, value = model.actor_critic.act(state)\n",
        "                        #action = action.cpu().numpy() # GPU\n",
        "                        action = action.detach().cpu().numpy()\n",
        "\n",
        "                        print(f\"Action sampled from model {i}: {action}\")\n",
        "\n",
        "                        # Step 5: Process Action in Market Environment\n",
        "                        self.process_action(action, model)\n",
        "                        end_time = time.time()\n",
        "                        calc_time = end_time - start_time\n",
        "                        print(f\"Action processed for model {i}. Time taken: {calc_time}\")\n",
        "                        model.decision_time = current_time + calc_time\n",
        "                    else:\n",
        "                        continue\n",
        "                else:\n",
        "                    self.rate_limiter.simulate_time_step(current_time)\n",
        "                    print(\"Rate limiter simulated time step\")\n",
        "\n",
        "                # Step 6: Retrieve recent trades executed by the model\n",
        "                recent_trades = model.lob_instance.get_my_recent_trades()\n",
        "                print(f\"Recent trades retrieved for model {i}\")\n",
        "                if recent_trades:\n",
        "                      # Step 7: Update Order Management with Trade Data\n",
        "                      self.update_order_manager(model, recent_trades, current_time)\n",
        "                      print(f\"Order manager updated for model {i}\")\n",
        "                else:\n",
        "                      print(f\"No recent trades for model {i}, skipping order manager update\")\n",
        "\n",
        "\n",
        "                # Step 8: Calculate Reward\n",
        "                reward = self.get_reward(model, market_data)\n",
        "                model.performance += reward\n",
        "                print(f\"Reward calculated for model {i}: {reward}\")\n",
        "\n",
        "                # Step 9: Check if Episode is Done\n",
        "                done, termination_reason = self.check_if_done(model)\n",
        "                print(f\"Checked if episode is done for model {i}. Done: {done}, Reason: {termination_reason}\")\n",
        "\n",
        "                # Step 10: Update the Rollout Buffer\n",
        "                model.rollout_buffer.add(state, action, reward, log_prob, value, done)\n",
        "                print(f\"Rollout buffer updated for model {i}\")\n",
        "\n",
        "                if done:\n",
        "                    # Reset the model's state for a new training session\n",
        "                    self.train_model(model, hyperparams)\n",
        "                    self.reset_model_state(model)\n",
        "                    print(f\"Model {i} state reset for new training session\")\n",
        "\n",
        "        print(\"Finished process_trade_data\")\n",
        "\n",
        "\n",
        "            # Additional checks or updates can be added here if necessary\n",
        "\n",
        "    def update_order_manager(self, model, trades, current_time):\n",
        "        #model.environment.trade_update_manager.update_trades(trades)\n",
        "        model.environment.trade_update_manager.format_and_append_trade_data(trades, current_time)\n",
        "        model.volatility.update_tick_data(trades, current_time)\n",
        "        for trade in trades:\n",
        "            order_id = trade['order_id']\n",
        "            matched_price = trade['price']\n",
        "            matched_volume = trade['volume']\n",
        "            is_buy = trade['side'] == 'buy'\n",
        "\n",
        "            # Update the OrderManager within the model's environment with trade execution details\n",
        "            model.environment.order_manager.process_order_execution(order_id, matched_volume, matched_price)\n",
        "\n",
        "\n",
        "# ... [Rest of the methods]\n",
        "\n",
        "    def train_and_update_models(self):\n",
        "        # Loop through each model in the population\n",
        "        for model in self.evolutionary_model.population:\n",
        "            # Check if the rollout buffer has enough data to train\n",
        "            if len(model.rollout_buffer.states) >= self.hyperparams['training_batch_size']:\n",
        "                print(f\"Training Model ID {id(model)}\")\n",
        "\n",
        "                # Perform training\n",
        "                last_value = model.actor_critic.critic_forward(model.rollout_buffer.states[-1])\n",
        "                model.rollout_buffer.compute_returns_and_advantage(last_value, self.hyperparams['gamma'], self.hyperparams['lambda_gae'])\n",
        "                avg_actor_loss, avg_critic_loss, avg_entropy_loss = model.ppo.update(model.rollout_buffer)\n",
        "\n",
        "                # Reset the rollout buffer for the next training session\n",
        "                model.rollout_buffer.reset()\n",
        "\n",
        "                # Debugging print statements\n",
        "                print(f\"Model ID {id(model)}, Actor Loss: {avg_actor_loss}, Critic Loss: {avg_critic_loss}, Entropy: {avg_entropy_loss}\")\n",
        "\n",
        "                # Optional: Logging\n",
        "                # logging.info(f'Model ID {id(model)}, Actor Loss: {avg_actor_loss}, Critic Loss: {avg_critic_loss}, Entropy: {avg_entropy_loss}')\n",
        "            else:\n",
        "                print(f\"Not enough data to train Model ID {id(model)}\")\n",
        "\n",
        "    # def train_model(self,model, hyperparams):\n",
        "    #     # Ensure there's enough data for training\n",
        "    #     # if rollout_buffer.ptr >= hyperparams['min_batch_size']:\n",
        "    #     # Prepare the buffer for training, e.g., computing returns and advantages\n",
        "    #     last_state_tensor = torch.tensor(model.rollout_buffer.states[-1], dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "    #     last_value = model.actor_critic.forward(last_state_tensor).detach().item()  # Assuming critic_forward returns a tensor\n",
        "\n",
        "    #     # Call compute_returns_and_advantage with gamma and lambda_gae from hyperparams\n",
        "    #     model.rollout_buffer.compute_returns_and_advantage(last_value, hyperparams['gamma'], hyperparams['lambda_gae'])\n",
        "\n",
        "    #     # Collect all batches into a list or generator\n",
        "    #     sequential_batches = list(model.rollout_buffer.get_sequential_mini_batches(hyperparams['mini_batch_size']))\n",
        "    #     random_batches = list(model.rollout_buffer.get_random_mini_batches(hyperparams['mini_batch_size']))\n",
        "\n",
        "    #     # First Epoch: Sequential\n",
        "    #     model.ppo.update(sequential_batches)\n",
        "\n",
        "    #     # Second Epoch: Random\n",
        "    #     model.ppo.update(random_batches)\n",
        "\n",
        "    #     # Reset the buffer after training\n",
        "    #     model.rollout_buffer.reset()\n",
        "    def train_model(self, model, hyperparams):\n",
        "        print(\"Starting training model...\")\n",
        "\n",
        "        # Debug: Check the size of the states buffer\n",
        "        print(f\"Number of states in buffer: {len(model.rollout_buffer.states)}\")\n",
        "\n",
        "        # Assuming the last state is correctly shaped, let's print its shape\n",
        "        if len(model.rollout_buffer.states) > 0:\n",
        "            print(f\"Shape of the last state: {model.rollout_buffer.states[-1].shape}\")\n",
        "\n",
        "        # Prepare the buffer for training, e.g., computing returns and advantages\n",
        "        last_state_tensor = torch.tensor(model.rollout_buffer.states[-1], dtype=torch.float32)\n",
        "        print(f\"Shape of last_state_tensor for model input: {last_state_tensor.shape}\")\n",
        "\n",
        "        # Passing last_state_tensor through the model\n",
        "         # Correctly handling the model's forward method when it returns multiple outputs\n",
        "        mean, std, nu, value_tensor = model.actor_critic.forward(last_state_tensor)\n",
        "        last_value = value_tensor.detach().item()\n",
        "        print(f\"Last value from critic: {last_value}\")\n",
        "        # Call compute_returns_and_advantage with gamma and lambda_gae from hyperparams\n",
        "        model.rollout_buffer.compute_returns_and_advantage(last_value, hyperparams['gamma'], hyperparams['lambda_gae'])\n",
        "\n",
        "        # Debug: Check if returns and advantages are computed\n",
        "        print(\"Returns and advantages computed.\")\n",
        "\n",
        "        # Collect all batches into a list or generator\n",
        "        sequential_batches = list(model.rollout_buffer.get_sequential_mini_batches(hyperparams['mini_batch_size']))\n",
        "        random_batches = list(model.rollout_buffer.get_random_mini_batches(hyperparams['mini_batch_size']))\n",
        "\n",
        "        print(f\"Number of sequential batches: {len(sequential_batches)}\")\n",
        "        print(f\"Number of random batches: {len(random_batches)}\")\n",
        "\n",
        "        # First Epoch: Sequential\n",
        "        print(\"Updating model with sequential batches...\")\n",
        "        model.ppo.update(sequential_batches)  # Pass mean, std, nu for policy update\n",
        "\n",
        "        # Second Epoch: Random\n",
        "        print(\"Updating model with random batches...\")\n",
        "        model.ppo.update(random_batches)  # Pass mean, std, nu for policy update\n",
        "\n",
        "\n",
        "        # Reset the buffer after training\n",
        "        model.rollout_buffer.reset()\n",
        "        print(\"Training completed. Buffer reset.\")\n",
        "\n",
        "\n",
        "    # def check_capital_depletion(self, model):\n",
        "    #     # Check for capital depletion using the capital stored in the model's environment\n",
        "    #     current_capital = model.portfolio_manager.current_capital\n",
        "    #     return current_capital < self.min_capital_threshold\n",
        "\n",
        "    #     # Evolve the population and reset rewards after each generation\n",
        "    #     self.evolutionary_model.evolve_population()\n",
        "    #     for model in self.evolutionary_model.population:\n",
        "    #         model.accumulated_reward = 0  # Reset rewards for the new generation\n",
        "\n",
        "            # Other backtesting logic: plotting, statistics updating, etc.\n",
        "\n",
        "#     def run_backtest(self, market_data_stream):\n",
        "#         print(\"Starting backtest...\")\n",
        "#         self.trading_simulation.render()\n",
        "#         market_data_index = 0\n",
        "#         total_market_data_points = len(market_data_stream)\n",
        "#         count=0\n",
        "#         for index, market_data in market_data_stream.iterrows():\n",
        "#     # Process each row of market data\n",
        "#             count+=1\n",
        "#             print(count)\n",
        "#            #market_data = market_data_stream[market_data_index]\n",
        "#             print(f\"Processing market data: {market_data}\")\n",
        "#             # Calculate ingestion latency and schedule market event\n",
        "#             ingestion_latency = self.calculate_ingestion_latency(market_data)\n",
        "#             #self.schedule_event(market_data, ingestion_latency)\n",
        "\n",
        "#             # Update the current time to the maximum of current time and market data's timestamp plus latency\n",
        "#             # Set current time to the local timestamp of the market data\n",
        "#             self.current_time = market_data['local_timestamp']\n",
        "#             price = self.lob.get_current_price()\n",
        "#             expired_orders = self.lob.remove_expired_orders(self.current_time)\n",
        "# #             for expired_order in expired_orders:\n",
        "# #                 self.position_manager.update_position_on_expiry(expired_order, price)\n",
        "#             self.lob.display_book()\n",
        "#             print(f\"Current simulation time: {self.current_time}\")\n",
        "\n",
        "#             if market_data['event'] == 1:  # Market data update\n",
        "#                 print(\"Processing market data update\")\n",
        "#                 self.simulate_market_data(market_data)\n",
        "#                 print(\"Finished processing market data update\")\n",
        "#             elif market_data['event'] == 2:  # Trade execution event\n",
        "#                 print(\"Processing trade data update\")\n",
        "#                 #trade_execution_event = TradeExecutionEvent(market_data['trade'])  # Assuming market_data['trade'] contains trade details\n",
        "#                 self.process_trade_execution(market_data)\n",
        "#                 print(\"Finished processing trade data update\")\n",
        "#             # Check if it's time to make a new decision\n",
        "#             if self.current_time >= self.next_decision_time:\n",
        "#                 print('Making Decision')\n",
        "#                 # Handle any orders generated as a result of the decision\n",
        "#                 start_time = time.time()  # Start time\n",
        "#                 current_position_size = self.position_manager.get_position_size()\n",
        "#                 print(f\"Current BTC Position Size: {current_position_size}\")  # Get current position size\n",
        "#                 best_bid, best_ask = self.lob.get_best_bid_ask()\n",
        "#                 if best_bid != None or best_ask != None:\n",
        "#                     # Get the decision from the strategy\n",
        "#                     bid_price, ask_price = self.strategy.make_decision(best_bid, best_ask, current_position_size,self.lob.active_orders)\n",
        "\n",
        "#                     end_time = time.time()\n",
        "#                     execution_time = end_time - start_time\n",
        "#                     print(execution_time)\n",
        "#                     self.next_decision_time = self.current_time + execution_time #+ ingestion_latency / 1e6\n",
        "#                     if bid_price != None:\n",
        "#                         # Place orders based on strategy's decision\n",
        "#                         buy_order_id = self.generate_order_id()\n",
        "#                         self.lob.place_limit_order(buy_order_id, bid_price, volume=self.strategy.order_qty, side='buy', current_time=self.current_time)\n",
        "#                         #self.strategy.submit_order(buy_order_id,'buy', bid_price)\n",
        "#                     if ask_price != None:\n",
        "#                         sell_order_id = self.generate_order_id()\n",
        "#                         self.lob.place_limit_order(sell_order_id, ask_price, volume=self.strategy.order_qty, side='sell', current_time=self.current_time)\n",
        "#                         #self.strategy.submit_order(sell_order_id,'buy', bid_price)\n",
        "#             # Process all scheduled events (market updates and orders)\n",
        "#             #self.process_scheduled_events()\n",
        "#             print(f\"Next decision time: {self.next_decision_time}\")\n",
        "\n",
        "#             trade_data = self.get_trade_data()\n",
        "#             self.trading_simulation.trade_data = trade_data\n",
        "#             for trade in trade_data:\n",
        "#                 print(f\"Processing trade: {trade}\")\n",
        "#                 pnl = self.position_manager.update_position(trade)\n",
        "#                 trade['profit_loss'] = pnl  # Add PnL to the trade dictionary\n",
        "\n",
        "#                 # Record the trade with PnL in the StatisticsManager\n",
        "#                 self.statistics_manager.record_trade(trade)\n",
        "\n",
        "\n",
        "\n",
        "#             # Update data for plotting\n",
        "#            # Update data for plotting\n",
        "#             new_price = self.get_current_price()  # Example method to get current price\n",
        "#             if new_price is not None:\n",
        "#                 self.trading_simulation.price.append(new_price)\n",
        "#             #self.trading_simulation.reward_arr = self.get_rewards()\n",
        "#             self.trading_simulation.posi_arr = self.get_positions()\n",
        "#             self.trading_simulation.inventory = self.get_inventory()\n",
        "#             self.trading_simulation.trade_data = self.get_trade_data()\n",
        "#             #self.trading_simulation.obs_features = self.get_features()\n",
        "\n",
        "#             # Call the plotting function\n",
        "#             self.trading_simulation._plot_trading()\n",
        "\n",
        "#             # Increment market data index to process the next market data point\n",
        "#             market_data_index += 1\n",
        "#             print(f'PNL : {self.statistics_manager.get_pnl()}')\n",
        "#             current_return = self.statistics_manager.calculate_current_return(self.initial_capital)\n",
        "#             print(f\"Current Return: {current_return:.2f}%\")\n",
        "\n",
        "#         # Print summary of statistics at the end of the backtest\n",
        "#         self.statistics_manager.print_summary(capital=self.initial_capital)\n",
        "#         print(\"Backtest completed.\")\n",
        "\n",
        "    def generate_order_id(self):\n",
        "        return str(uuid.uuid4())\n",
        "\n",
        "    def calculate_ingestion_latency(self, market_data):\n",
        "        \"\"\" Calculate the latency between exchange and local timestamps. \"\"\"\n",
        "        latency = market_data['local_timestamp'] - market_data['exch_timestamp']\n",
        "\n",
        "        # Example calculation (adjust based on your data format)\n",
        "        print(f\"Calculated ingestion latency: {latency}\")\n",
        "        return latency\n",
        "\n",
        "    def schedule_event(self, market_data, ingestion_latency):\n",
        "        \"\"\" Schedule a market event based on ingestion latency. \"\"\"\n",
        "        event_time = market_data.exch_timestamp + ingestion_latency\n",
        "        self.event_queue.put((event_time, market_data))\n",
        "\n",
        "    def process_scheduled_events(self):\n",
        "        \"\"\" Process events that are scheduled to occur up to the current time. \"\"\"\n",
        "        while not self.event_queue.empty():\n",
        "            event_time, event = self.event_queue.queue[0]  # Peek at the next event\n",
        "            if event_time <= self.current_time:\n",
        "                _, event = self.event_queue.get()\n",
        "                self.process_event(event)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    def calculate_decision_time(self):\n",
        "        \"\"\" Calculate the time taken for decision-making. \"\"\"\n",
        "        # Decision time can be a fixed value or dynamically calculated\n",
        "        return random.uniform(0.001, 0.005)  # Random time between 1ms and 5ms for example\n",
        "\n",
        "\n",
        "\n",
        "    def process_trade_execution(self, trade_execution_event):\n",
        "        \"\"\" Process a trade execution event. \"\"\"\n",
        "        self.lob.handle_trade_execution(trade_execution_event)\n",
        "\n",
        "\n",
        "    def simulate_market_data(self, market_data):\n",
        "        \"\"\" Simulate the arrival of new market data and update the order book. \"\"\"\n",
        "        print(f\"Simulating market data: {market_data}\")\n",
        "        executed_trades = self.lob.process_market_data(market_data)\n",
        "#         for trade in executed_trades:\n",
        "#             # Update position and record the trade\n",
        "#             self.position_manager.update_position(trade['asset'], trade['side'], trade['volume'])\n",
        "#             self.statistics_manager.record_trade(trade)\n",
        "\n",
        "#             # Optional: Update daily returns and other statistics\n",
        "#             pnl_change = trade['price'] * trade['volume']\n",
        "#             self.statistics_manager.daily_returns.append(pnl_change / self.initial_capital)\n",
        "\n",
        "#         return executed_trades\n",
        "\n",
        "    def execute_simple_strategy(self):\n",
        "        print(\"Executing simple strategy\")\n",
        "        end_time=0\n",
        "        best_bid, best_ask = self.lob.get_best_bid_ask()\n",
        "\n",
        "\n",
        "        if best_bid and best_ask:\n",
        "            best_bid=best_bid+0.00001\n",
        "            best_ask=best_ask-0.00001\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Place buy order at best bid\n",
        "            buy_order_id = self.generate_order_id()\n",
        "            self.lob.place_limit_order(buy_order_id, best_bid, volume=2, side='buy', current_time=self.current_time)\n",
        "            self.strategy.submit_order(buy_order_id,'buy', bid_price)\n",
        "            # Place sell order at best ask\n",
        "            sell_order_id = self.generate_order_id()\n",
        "            self.lob.place_limit_order(sell_order_id, best_ask, volume=2, side='sell', current_time=self.current_time)\n",
        "        return end_time\n",
        "\n",
        "    def handle_generated_orders(self):\n",
        "        \"\"\" Handle any orders generated from decision making. \"\"\"\n",
        "        # Simulate a trading strategy decision\n",
        "        print(\"Handling generated orders\")\n",
        "        new_order = self.generate_new_order_based_on_strategy()\n",
        "        if new_order:\n",
        "            self.handle_order(new_order)\n",
        "\n",
        "    def generate_new_order_based_on_strategy(self):\n",
        "        \"\"\" Generate a new order based on a trading strategy. \"\"\"\n",
        "        # Example trading strategy logic\n",
        "        # This is a placeholder - replace with your strategy logic\n",
        "        if random.choice([True, False]):  # Randomly decide to place an order or not\n",
        "            order_side = random.choice(['buy', 'sell'])\n",
        "            order_price = self.get_current_market_price()  # Placeholder for market price\n",
        "            order_volume = random.uniform(1, 10)  # Random volume\n",
        "            order = {'side': order_side, 'price': order_price, 'volume': order_volume}\n",
        "            return OrderEvent(order)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def handle_order(self, order_event):\n",
        "        \"\"\" Handle new order events with added latency. \"\"\"\n",
        "        order = order_event.order\n",
        "        execution_time = self.current_time + self.calculate_order_latency()\n",
        "        order = order_event.order\n",
        "        order_side = order['side']\n",
        "        order_price = order['price']\n",
        "        order_volume = order['volume']\n",
        "        order_expiration = order['expiration']\n",
        "        trade_execution_event = TradeExecutionEvent(order)\n",
        "        print(f\"Handling order: {order_event.order}\")\n",
        "        self.event_queue.put(execution_time,trade_execution_event)\n",
        "        #self.order_execution_queue.put((execution_time, order))\n",
        "\n",
        "    def calculate_order_latency(self):\n",
        "        \"\"\" Calculate the latency for order execution. \"\"\"\n",
        "        # Fixed or dynamic latency\n",
        "        return self.order_execution_latency\n",
        "\n",
        "\n",
        "    def get_current_price(self):\n",
        "        price = self.lob.get_current_price()\n",
        "        print(f\"Current market price: {price}\")\n",
        "        return price\n",
        "\n",
        "    def get_positions(self):\n",
        "        # Retrieve current positions from PositionManager\n",
        "        return self.position_manager.positions\n",
        "\n",
        "\n",
        "    def get_inventory(self):\n",
        "        \"\"\" Retrieve inventory data for BTC. \"\"\"\n",
        "        return {'BTC': self.position_manager.get_position_size()}\n",
        "\n",
        "    def get_trade_data(self):\n",
        "        # Assuming you have a method or a log that records trade data\n",
        "        return self.lob.get_my_recent_trades()\n",
        "\n",
        "\n",
        "\n",
        "# # Event Types\n",
        "# class Event:\n",
        "#     \"\"\" Base class for all events. \"\"\"\n",
        "#     pass\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# class MarketEvent(Event):\n",
        "#     \"\"\" Event for market updates and trade executions. \"\"\"\n",
        "#     LIMIT_ORDER = 1\n",
        "#     TRADE_EXECUTION = 2\n",
        "\n",
        "#     def __init__(self, event_type, exch_timestamp, local_timestamp, side, price, qty):\n",
        "#         self.event_type = event_type\n",
        "#         self.exch_timestamp = exch_timestamp\n",
        "#         self.local_timestamp = local_timestamp\n",
        "#         self.side = side\n",
        "#         self.price = price\n",
        "#         self.qty = qty\n",
        "\n",
        "# def load_data(data):\n",
        "#     \"\"\" Load data and create MarketEvent instances. \"\"\"\n",
        "#     events = []\n",
        "#     for index, row in data.iterrows():\n",
        "#         event_type = MarketEvent.LIMIT_ORDER if row['event'] == 1.0 else MarketEvent.TRADE_EXECUTION\n",
        "#         event = MarketEvent(event_type, row['exch_timestamp'], row['local_timestamp'], row['side'], row['price'], row['qty'])\n",
        "#         events.append(event)\n",
        "#     return events\n",
        "\n",
        "# # Example usage\n",
        "# data = pd.DataFrame([\n",
        "#     # Your data rows here\n",
        "#     # Example: [1.0, 1.702079e+15, 1.702079e+15, -1.0, 0.66856, 4531.652925],\n",
        "#     # ...\n",
        "# ])\n",
        "\n",
        "# market_events = load_data(data)\n",
        "\n",
        "# class TradeExecutionEvent(Event):\n",
        "#     \"\"\" Event for trade executions. \"\"\"\n",
        "#     def __init__(self, trade):\n",
        "#         self.trade = trade\n",
        "\n",
        "# class OrderEvent(Event):\n",
        "#     \"\"\" Event for new orders. \"\"\"\n",
        "#     def __init__(self, order):\n",
        "#         self.order = order\n",
        "\n",
        "# class TimerEvent(Event):\n",
        "#     \"\"\" Event for simulating the passage of time. \"\"\"\n",
        "#     pass\n",
        "\n",
        "# class SimpleTwoSidedQuoteStrategy:\n",
        "\n",
        "#     def __init__(self, max_position=100, order_qty= 20):\n",
        "#         self.max_position = max_position\n",
        "\n",
        "#         self.skew = 0.01  # Skew per unit of position\n",
        "#         self.max_sigfigs = 5  # Maximum number of significant figures\n",
        "\n",
        "#         self.order_qty = order_qty\n",
        "#         self.order_id = 0\n",
        "#         self.position = 0  # Current position\n",
        "#         self.active_orders = {}  # Store active orders\n",
        "\n",
        "#     def make_decision(self, best_bid, best_ask, current_position, active_orders):\n",
        "#         # Calculate mid_price and reservation price\n",
        "#         mid_price = (best_bid + best_ask) / 2.0\n",
        "#         #reservation_price = mid_price - self.skew * current_position\n",
        "\n",
        "#         # Calculate spread and adjust half spread\n",
        "#         spread = best_ask - best_bid\n",
        "#         half_spread = spread / 2\n",
        "#         self.half_spread = max(half_spread * 0.9, 0.00001)  # Adjusted and bounded by min price precision\n",
        "#         self.half_spread = round(self.half_spread, self.max_sigfigs)  # Round to max price precision\n",
        "\n",
        "#         # Calculate bid and ask prices based on reservation price and half spread\n",
        "#         #bid_price = max(reservation_price - self.half_spread, 0)  # Ensure bid price is non-negative\n",
        "#         #ask_price = reservation_price + self.half_spread\n",
        "#         ask_price = mid_price + self.half_spread\n",
        "#         bid_price = mid_price - self.half_spread\n",
        "#         ask_price = round(ask_price, self.max_sigfigs)  # Round to max price precision\n",
        "#         bid_price = round(bid_price, self.max_sigfigs)  # Round to max price precision\n",
        "\n",
        "#         # Check the count of active buy and sell orders\n",
        "#         buy_order_count = sum(1 for order in active_orders.values() if order['side'] == 'buy')\n",
        "#         sell_order_count = sum(1 for order in active_orders.values() if order['side'] == 'sell')\n",
        "#         print(f\"Buy order count: {buy_order_count}, Sell order count: {sell_order_count}\")\n",
        "#         if buy_order_count < 1:\n",
        "#             ask_price = None\n",
        "#         # Adjust decision based on the count of active orders\n",
        "#         if buy_order_count >= 5:\n",
        "#             bid_price = None  # Do not place a new buy order\n",
        "#         if sell_order_count >= 5:\n",
        "#             ask_price = None  # Do not place a new sell order\n",
        "\n",
        "#         # Return the calculated bid and ask prices\n",
        "#         return bid_price, ask_price\n",
        "\n",
        "\n",
        "#     def submit_order(self, order_id, side, price):\n",
        "\n",
        "#         self.active_orders[order_id] = {'side': side, 'price': price}\n",
        "\n",
        "#         print(f\"Order submitted: ID {order_id}, Side {side}, Price {price}\")\n",
        "\n",
        "#     def cancel_order(self, order_id):\n",
        "#         \"\"\"\n",
        "#         Cancel an existing order.\n",
        "\n",
        "#         :param order_id: ID of the order to cancel\n",
        "#         \"\"\"\n",
        "#         # Logic to cancel order\n",
        "#         # ...\n",
        "#         del self.active_orders[order_id]\n",
        "#         print(f\"Order cancelled: ID {order_id}\")\n",
        "\n",
        "#     def update_position(self, trade):\n",
        "#         \"\"\"\n",
        "#         Update the current position based on executed trades.\n",
        "\n",
        "#         :param trade: Trade data\n",
        "#         \"\"\"\n",
        "#         if trade['side'] == 'buy':\n",
        "#             self.position += trade['volume']\n",
        "#         else:\n",
        "#             self.position -= trade['volume']\n",
        "#         print(f\"Position updated: {self.position}\")\n"
      ],
      "id": "2b67ebf3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5f71b70",
        "outputId": "d7311fd2-f423-4ff0-d9ac-231cf131d06e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def load_csv_data(file_path):\n",
        "    try:\n",
        "        # Read the CSV file\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "        # Print the first few rows of the DataFrame\n",
        "        print(data.head())\n",
        "\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the CSV file: {e}\")\n",
        "        return None\n"
      ],
      "id": "f5f71b70"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf1336dd",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a4bb657-6872-4b88-9a7b-cf4cdb46a16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "OrderBook initialized with depth: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting backtest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Generations:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.10164061322360649, 0.005359254137513325, 0, 0, 0, 0, 0.163028543655666, 0.06762387895196391, 25.06441236841673, 2.8669944563273684, 1, 1, 0, 0, 1, 1, 0.09540466470370208, 0.8516369983075791, 0.9999657051148472, 0.514025716791165, 0.41862105208746303, 0.9997688447607455, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 13: [[-5.99999999e-04  5.99999999e-04  2.64999996e-02  2.64999996e-02\n",
            "   0.00000000e+00 -3.49999994e-01  1.00000000e+00  0.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [-5.99999999e-04  5.99999999e-04  2.64999996e-02  2.64999996e-02\n",
            "  0.00000000e+00 -3.49999994e-01  1.00000000e+00  0.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 0.0\n",
            "Bid price: 0.66829, Ask price: 0.6691\n",
            "Placing limit order: Order ID 01629e88-bc2b-49f2-963c-646ee0d40cf3, Price 0.66829, Volume 37.0, Side buy\n",
            "Adding order to book: Order ID 01629e88-bc2b-49f2-963c-646ee0d40cf3, Price 0.66829, Volume 37.0, Side buy, Time 1702076242542653.0\n",
            "Placing limit order: Order ID c80599c1-4d79-4875-8356-ee1ea0d011f5, Price 0.6691, Volume 37.0, Side sell\n",
            "Adding order to book: Order ID c80599c1-4d79-4875-8356-ee1ea0d011f5, Price 0.6691, Volume 37.0, Side sell, Time 1702076242542653.0\n",
            "Action processed for model 13. Time taken: 0.07155060768127441\n",
            "Recent trades retrieved for model 13\n",
            "No recent trades for model 13, skipping order manager update\n",
            "Current time: 1702076242542653.0\n",
            "Decision time: 1702076242542653.0\n",
            "Current inventory: 0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Current time (type: <class 'numpy.float64'>): 1702076242542653.0\n",
            "Order time placed (type: <class 'numpy.float64'>): 1702076242542653.0\n",
            "Time in queue (seconds): 0.0\n",
            "Calculated reward: 0.0\n",
            "Current time (type: <class 'numpy.float64'>): 1702076242542653.0\n",
            "Order time placed (type: <class 'numpy.float64'>): 1702076242542653.0\n",
            "Time in queue (seconds): 0.0\n",
            "Calculated reward: 0.0\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0.0\n",
            "Rate Limit Penalty: -0.03636363636363636\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.298863631893288\n",
            "Reward calculated for model 13: -0.298863631893288\n",
            "Checked if episode is done for model 13. Done: False, Reason: \n",
            "Rollout buffer updated for model 13\n",
            "Processing model 14\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686100e-01\n",
            "volume             1.600000e+03\n",
            "Name: 6809, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66861, Volume: 1600.0\n",
            "Remaining volume after matching: 1600.0\n",
            "Finished simulating market data update\n",
            "Market data updated for model 14\n",
            "State vector constructed for model 14\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 14\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 1700.6860341\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 16556.39530575), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242542653.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 94203.40927111\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 9574.892286069997\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.1131402584753147\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: inventory_target_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 94203.40927111\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 94203.40927111\n",
            "log_distance: 0.1071850827502665\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 2891.59995837, y: 747.764185086591\n",
            "log_distance: 1.3524775790392782\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 2891.59995837, y: 0\n",
            "log_distance: 30.995416176669725\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 2891.59995837\n",
            "log_distance: 30.995416176669725\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 2891.59995837, y: 19490.03407443\n",
            "log_distance: 1.9080932940740416\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 2891.59995837\n",
            "log_distance: 8.372421041749261\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 2891.59995837\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.10164061322360649, 0.005359254137513325, 0, 0, 0, 0, 0.163028543655666, 0.06762387895196391, 25.06441236841673, 2.8669944563273684, 1, 1, 0, 0, 1, 1, 0.09540466470370208, 0.8516369983075791, 0.9999657051148472, 0.514025716791165, 0.41862105208746303, 0.9997688447607455, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 14: [[9.99999756e-05 5.99999999e-04 2.64999996e-02 2.64999996e-02\n",
            "  1.00000000e+00 3.49999994e-01 0.00000000e+00 0.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [9.99999756e-05 5.99999999e-04 2.64999996e-02 2.64999996e-02\n",
            " 1.00000000e+00 3.49999994e-01 0.00000000e+00 0.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: 174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Action processed for model 14. Time taken: 0.07022953033447266\n",
            "Recent trades retrieved for model 14\n",
            "No recent trades for model 14, skipping order manager update\n",
            "Current time: 1702076242542653.0\n",
            "Decision time: 1702076242542653.0\n",
            "Current inventory: 0\n",
            "Inventory target: 174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 14: -0.26249999552965164\n",
            "Checked if episode is done for model 14. Done: False, Reason: \n",
            "Rollout buffer updated for model 14\n",
            "Processing model 15\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686100e-01\n",
            "volume             1.600000e+03\n",
            "Name: 6809, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66861, Volume: 1600.0\n",
            "Remaining volume after matching: 1600.0\n",
            "Finished simulating market data update\n",
            "Market data updated for model 15\n",
            "State vector constructed for model 15\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 15\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 1700.6860341\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 16556.39530575), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242542653.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 94203.40927111\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 9574.892286069997\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.1131402584753147\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: inventory_target_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 94203.40927111\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 94203.40927111\n",
            "log_distance: 0.1071850827502665\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 2891.59995837, y: 747.764185086591\n",
            "log_distance: 1.3524775790392782\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 2891.59995837, y: 0\n",
            "log_distance: 30.995416176669725\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 2891.59995837\n",
            "log_distance: 30.995416176669725\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 2891.59995837, y: 19490.03407443\n",
            "log_distance: 1.9080932940740416\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 2891.59995837\n",
            "log_distance: 8.372421041749261\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 2891.59995837\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.10164061322360649, 0.005359254137513325, 0, 0, 0, 0, 0.163028543655666, 0.06762387895196391, 25.06441236841673, 2.8669944563273684, 1, 1, 0, 0, 1, 1, 0.09540466470370208, 0.8516369983075791, 0.9999657051148472, 0.514025716791165, 0.41862105208746303, 0.9997688447607455, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 15: [[ 9.99999756e-05 -9.99999756e-05  2.64999996e-02 -2.44999995e-02\n",
            "   0.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05 -9.99999756e-05  2.64999996e-02 -2.44999995e-02\n",
            "  0.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 0.0\n",
            "Bid price: 0.66876, Ask price: 0.66863\n",
            "Placing limit order: Order ID 37774f54-8297-42a5-939e-aa72a2b43f49, Price 0.66876, Volume 37.0, Side buy\n",
            "Executing matched trade: Order ID 37774f54-8297-42a5-939e-aa72a2b43f49, Price 0.66873, Volume 37.0, Side buy\n",
            "Executing cancellation logic: Selecting orders furthest from market\n",
            "Not enough orders to cancel while maintaining at least one order per side.\n",
            "Order cancellation logic executed\n",
            "Action processed for model 15. Time taken: 0.08186674118041992\n",
            "Recent trades retrieved for model 15\n",
            "new_trade_data: [{'order_id': '37774f54-8297-42a5-939e-aa72a2b43f49', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Debugging update_tick_data method:\n",
            "Timestamp (float): 1702076242542653.0\n",
            "Type of timestamp: <class 'numpy.float64'>\n",
            "One hour window (timedelta): 1:00:00\n",
            "Type of one_hour_window: <class 'datetime.timedelta'>\n",
            "Updating EMA trades with new_trade_data: [{'order_id': '37774f54-8297-42a5-939e-aa72a2b43f49', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Adding trade to queue: Timestamp: 1702076242542653.0, Price: 0.66873\n",
            "Trade queue before removal: [(1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873)]\n",
            "Trade queue after removal: [(1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873)]\n",
            "Updating EMA trades with new_trade_data: [{'order_id': '37774f54-8297-42a5-939e-aa72a2b43f49', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Adding trade to queue: Timestamp: 1702076242542653.0, Price: 0.66873\n",
            "Trade queue before removal: [(1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873)]\n",
            "Trade queue after removal: [(1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873)]\n",
            "Updating EMA trades with new_trade_data: [{'order_id': '37774f54-8297-42a5-939e-aa72a2b43f49', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Adding trade to queue: Timestamp: 1702076242542653.0, Price: 0.66873\n",
            "Trade queue before removal: [(1702075816910821.0, 0.6686), (1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873)]\n",
            "Trade queue after removal: [(1702075816910821.0, 0.6686), (1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873)]\n",
            "Order manager updated for model 15\n",
            "Current time: 1702076242542653.0\n",
            "Decision time: 1702076242542653.0\n",
            "Current inventory: 37.0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 211.99999701976776\n",
            "Unrealized PnL: 0.0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: -0.0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -211.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.01818181818181818\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.3361818137114698\n",
            "Reward calculated for model 15: -0.3361818137114698\n",
            "Checked if episode is done for model 15. Done: False, Reason: \n",
            "Rollout buffer updated for model 15\n",
            "Processing model 16\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686100e-01\n",
            "volume             1.600000e+03\n",
            "Name: 6809, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66861, Volume: 1600.0\n",
            "Remaining volume after matching: 1600.0\n",
            "Finished simulating market data update\n",
            "Market data updated for model 16\n",
            "State vector constructed for model 16\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 16\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 1700.6860341\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 16556.39530575), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242542653.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 94203.40927111\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 9574.892286069997\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.1131402584753147\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: inventory_target_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 94203.40927111\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 94203.40927111\n",
            "log_distance: 0.1071850827502665\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 2891.59995837, y: 747.764185086591\n",
            "log_distance: 1.3524775790392782\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 2891.59995837, y: 0\n",
            "log_distance: 30.995416176669725\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 2891.59995837\n",
            "log_distance: 30.995416176669725\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 2891.59995837, y: 19490.03407443\n",
            "log_distance: 1.9080932940740416\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 2891.59995837\n",
            "log_distance: 8.372421041749261\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 2891.59995837\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.10164061322360649, 0.005359254137513325, 0, 0, 0, 0, 0.163028543655666, 0.06762387895196391, 25.06441236841673, 2.8669944563273684, 1, 1, 0, 0, 1, 1, 0.09540466470370208, 0.8516369983075791, 0.9999657051148472, 0.514025716791165, 0.41862105208746303, 0.9997688447607455, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 16: [[ 9.99999756e-05 -9.99999756e-05  2.64999996e-02 -2.44999995e-02\n",
            "   1.00000000e+00  3.49999994e-01  1.00000000e+00  1.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05 -9.99999756e-05  2.64999996e-02 -2.44999995e-02\n",
            "  1.00000000e+00  3.49999994e-01  1.00000000e+00  1.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: 174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Executing cancellation logic: Selecting orders furthest from market\n",
            "Not enough orders to cancel while maintaining at least one order per side.\n",
            "Order cancellation logic executed\n",
            "Action processed for model 16. Time taken: 0.07159829139709473\n",
            "Recent trades retrieved for model 16\n",
            "No recent trades for model 16, skipping order manager update\n",
            "Current time: 1702076242542653.0\n",
            "Decision time: 1702076242542653.0\n",
            "Current inventory: 0\n",
            "Inventory target: 174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 16: -0.26249999552965164\n",
            "Checked if episode is done for model 16. Done: False, Reason: \n",
            "Rollout buffer updated for model 16\n",
            "Processing model 17\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686100e-01\n",
            "volume             1.600000e+03\n",
            "Name: 6809, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66861, Volume: 1600.0\n",
            "Remaining volume after matching: 1600.0\n",
            "Finished simulating market data update\n",
            "Market data updated for model 17\n",
            "State vector constructed for model 17\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 17\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 1700.6860341\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 16556.39530575), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242542653.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 94203.40927111\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 9574.892286069997\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.1131402584753147\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: inventory_target_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 94203.40927111\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 94203.40927111\n",
            "log_distance: 0.1071850827502665\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 2891.59995837, y: 747.764185086591\n",
            "log_distance: 1.3524775790392782\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 2891.59995837, y: 0\n",
            "log_distance: 30.995416176669725\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 2891.59995837\n",
            "log_distance: 30.995416176669725\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 2891.59995837, y: 19490.03407443\n",
            "log_distance: 1.9080932940740416\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 2891.59995837\n",
            "log_distance: 8.372421041749261\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 2891.59995837\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.10164061322360649, 0.005359254137513325, 0, 0, 0, 0, 0.163028543655666, 0.06762387895196391, 25.06441236841673, 2.8669944563273684, 1, 1, 0, 0, 1, 1, 0.09540466470370208, 0.8516369983075791, 0.9999657051148472, 0.514025716791165, 0.41862105208746303, 0.9997688447607455, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 17: [[-5.99999999e-04 -9.99999756e-05  2.64999995e-02  2.64999996e-02\n",
            "   1.00000000e+00  3.49999994e-01  1.00000000e+00  0.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [-5.99999999e-04 -9.99999756e-05  2.64999995e-02  2.64999996e-02\n",
            "  1.00000000e+00  3.49999994e-01  1.00000000e+00  0.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: 174.99999701976682\n",
            "Hold action value: 1.0\n",
            "Action processed for model 17. Time taken: 0.06776118278503418\n",
            "Recent trades retrieved for model 17\n",
            "No recent trades for model 17, skipping order manager update\n",
            "Current time: 1702076242542653.0\n",
            "Decision time: 1702076242542653.0\n",
            "Current inventory: 0\n",
            "Inventory target: 174.99999701976682\n",
            "Inventory deviation: 174.99999701976682\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976682\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.2624999955296502\n",
            "Reward calculated for model 17: -0.2624999955296502\n",
            "Checked if episode is done for model 17. Done: False, Reason: \n",
            "Rollout buffer updated for model 17\n",
            "Processing model 18\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686100e-01\n",
            "volume             1.600000e+03\n",
            "Name: 6809, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66861, Volume: 1600.0\n",
            "Remaining volume after matching: 1600.0\n",
            "Finished simulating market data update\n",
            "Market data updated for model 18\n",
            "State vector constructed for model 18\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 18\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 1700.6860341\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 16556.39530575), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242542653.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 94203.40927111\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 9574.892286069997\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.1131402584753147\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: inventory_target_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 94203.40927111\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 94203.40927111\n",
            "log_distance: 0.1071850827502665\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 2891.59995837, y: 747.764185086591\n",
            "log_distance: 1.3524775790392782\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 2891.59995837, y: 0\n",
            "log_distance: 30.995416176669725\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 2891.59995837\n",
            "log_distance: 30.995416176669725\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 2891.59995837, y: 19490.03407443\n",
            "log_distance: 1.9080932940740416\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 2891.59995837\n",
            "log_distance: 8.372421041749261\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 2891.59995837\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.10164061322360649, 0.005359254137513325, 0, 0, 0, 0, 0.163028543655666, 0.06762387895196391, 25.06441236841673, 2.8669944563273684, 1, 1, 0, 0, 1, 1, 0.09540466470370208, 0.8516369983075791, 0.9999657051148472, 0.514025716791165, 0.41862105208746303, 0.9997688447607455, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 18: [[-5.99999999e-04  5.99999999e-04  2.64999996e-02  2.64999996e-02\n",
            "   1.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [-5.99999999e-04  5.99999999e-04  2.64999996e-02  2.64999996e-02\n",
            "  1.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Executing cancellation logic: Selecting orders furthest from market\n",
            "Not enough orders to cancel while maintaining at least one order per side.\n",
            "Order cancellation logic executed\n",
            "Action processed for model 18. Time taken: 0.06702446937561035\n",
            "Recent trades retrieved for model 18\n",
            "No recent trades for model 18, skipping order manager update\n",
            "Current time: 1702076242542653.0\n",
            "Decision time: 1702076242542653.0\n",
            "Current inventory: 0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 18: -0.26249999552965164\n",
            "Checked if episode is done for model 18. Done: False, Reason: \n",
            "Rollout buffer updated for model 18\n",
            "Processing model 19\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686100e-01\n",
            "volume             1.600000e+03\n",
            "Name: 6809, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66861, Volume: 1600.0\n",
            "Remaining volume after matching: 1600.0\n",
            "Finished simulating market data update\n",
            "Market data updated for model 19\n",
            "State vector constructed for model 19\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 19\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 1700.6860341\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 16556.39530575), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242542653.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 94203.40927111\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 9574.892286069997\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.1131402584753147\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: inventory_target_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 94203.40927111\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 94203.40927111\n",
            "log_distance: 0.1071850827502665\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 2891.59995837, y: 747.764185086591\n",
            "log_distance: 1.3524775790392782\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 2891.59995837, y: 0\n",
            "log_distance: 30.995416176669725\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 2891.59995837\n",
            "log_distance: 30.995416176669725\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 2891.59995837, y: 19490.03407443\n",
            "log_distance: 1.9080932940740416\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 2891.59995837\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 2891.59995837\n",
            "log_distance: 8.372421041749261\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 2891.59995837\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.10164061322360649, 0.005359254137513325, 0, 0, 0, 0, 0.163028543655666, 0.06762387895196391, 25.06441236841673, 2.8669944563273684, 1, 1, 0, 0, 1, 1, 0.09540466470370208, 0.8516369983075791, 0.9999657051148472, 0.514025716791165, 0.41862105208746303, 0.9997688447607455, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 19: [[ 9.99999756e-05 -9.99999756e-05 -2.44999995e-02  2.64999996e-02\n",
            "   1.00000000e+00  3.49999994e-01  0.00000000e+00  0.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05 -9.99999756e-05 -2.44999995e-02  2.64999996e-02\n",
            "  1.00000000e+00  3.49999994e-01  0.00000000e+00  0.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: 174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Action processed for model 19. Time taken: 0.07926678657531738\n",
            "Recent trades retrieved for model 19\n",
            "No recent trades for model 19, skipping order manager update\n",
            "Current time: 1702076242542653.0\n",
            "Decision time: 1702076242542653.0\n",
            "Current inventory: 0\n",
            "Inventory target: 174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 19: -0.26249999552965164\n",
            "Checked if episode is done for model 19. Done: False, Reason: \n",
            "Rollout buffer updated for model 19\n",
            "Finished process_market_data\n",
            "Finished processing market data update\n",
            "market_data type: <class 'pandas.core.series.Series'>\n",
            "market_data content: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Processing market data update\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66862, Volume: 16656.85963345\n",
            "Remaining volume after matching: 16656.85963345\n",
            "Finished simulating market data update\n",
            "Starting process_market_data...\n",
            "Processing model 0\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66862, Volume: 16656.85963345\n",
            "Remaining volume after matching: 16656.85963345\n",
            "Finished simulating market data update\n",
            "Market data updated for model 0\n",
            "State vector constructed for model 0\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 0\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 16656.85963345\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 16656.85963345), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242547360.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 109159.58287046\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 24531.06588542\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.2898676091624814\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: -174.99999701976776\n",
            "feature_name: inventory_target_log_distance, x: 0, y: -174.99999701976776\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 109159.58287046\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 109159.58287046\n",
            "log_distance: 0.25453958455069525\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 17847.77355772, y: 747.764185086591\n",
            "log_distance: 3.1725463810783356\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 17847.77355772, y: 0\n",
            "log_distance: 32.81548497870878\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 17847.77355772\n",
            "log_distance: 32.81548497870878\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 17847.77355772, y: 19490.03407443\n",
            "log_distance: 0.08802449203498419\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 17847.77355772\n",
            "log_distance: 10.192489843788318\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 17847.77355772\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.22472663636440504, 0.012726979227534763, 0, 0, 0, 0, 0.163028543655666, 0.15862731905391678, 25.06441236841673, 22.868184534210112, 1, 1, 0, 0, 1, 1, 0.00440122460174921, 0.08426155184944334, 0.9999657051148472, 0.514025716791165, 0.5096244921894159, 0.9999625494755384, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 0: [[ 9.99999756e-05 -9.99999756e-05 -2.44999995e-02  2.64999996e-02\n",
            "   1.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05 -9.99999756e-05 -2.44999995e-02  2.64999996e-02\n",
            "  1.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Executing cancellation logic: Selecting orders furthest from market\n",
            "Not enough orders to cancel while maintaining at least one order per side.\n",
            "Order cancellation logic executed\n",
            "Action processed for model 0. Time taken: 0.08136200904846191\n",
            "Recent trades retrieved for model 0\n",
            "No recent trades for model 0, skipping order manager update\n",
            "Current time: 1702076242547360.0\n",
            "Decision time: 1702076242547360.0\n",
            "Current inventory: 0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 0: -0.26249999552965164\n",
            "Checked if episode is done for model 0. Done: False, Reason: \n",
            "Rollout buffer updated for model 0\n",
            "Processing model 1\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66862, Volume: 16656.85963345\n",
            "Remaining volume after matching: 16656.85963345\n",
            "Finished simulating market data update\n",
            "Market data updated for model 1\n",
            "State vector constructed for model 1\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 1\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 16656.85963345\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 16656.85963345), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242547360.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 109159.58287046\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 24531.06588542\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.2898676091624814\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: -174.99999701976776\n",
            "feature_name: inventory_target_log_distance, x: 0, y: -174.99999701976776\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 109159.58287046\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 109159.58287046\n",
            "log_distance: 0.25453958455069525\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 17847.77355772, y: 747.764185086591\n",
            "log_distance: 3.1725463810783356\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 17847.77355772, y: 0\n",
            "log_distance: 32.81548497870878\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 17847.77355772\n",
            "log_distance: 32.81548497870878\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 17847.77355772, y: 19490.03407443\n",
            "log_distance: 0.08802449203498419\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 17847.77355772\n",
            "log_distance: 10.192489843788318\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 17847.77355772\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.22472663636440504, 0.012726979227534763, 0, 0, 0, 0, 0.163028543655666, 0.15862731905391678, 25.06441236841673, 22.868184534210112, 1, 1, 0, 0, 1, 1, 0.00440122460174921, 0.08426155184944334, 0.9999657051148472, 0.514025716791165, 0.5096244921894159, 0.9999625494755384, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 1: [[ 9.99999756e-05 -9.99999756e-05 -2.44999829e-02  2.64999996e-02\n",
            "   1.00000000e+00 -3.49999994e-01  0.00000000e+00  1.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05 -9.99999756e-05 -2.44999829e-02  2.64999996e-02\n",
            "  1.00000000e+00 -3.49999994e-01  0.00000000e+00  1.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Executing cancellation logic: Selecting orders furthest from market\n",
            "Not enough orders to cancel while maintaining at least one order per side.\n",
            "Order cancellation logic executed\n",
            "Action processed for model 1. Time taken: 0.0793917179107666\n",
            "Recent trades retrieved for model 1\n",
            "No recent trades for model 1, skipping order manager update\n",
            "Current time: 1702076242547360.0\n",
            "Decision time: 1702076242547360.0\n",
            "Current inventory: 0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 1: -0.26249999552965164\n",
            "Checked if episode is done for model 1. Done: False, Reason: \n",
            "Rollout buffer updated for model 1\n",
            "Processing model 2\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66862, Volume: 16656.85963345\n",
            "Remaining volume after matching: 16656.85963345\n",
            "Finished simulating market data update\n",
            "Market data updated for model 2\n",
            "State vector constructed for model 2\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 2\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 16656.85963345\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 16656.85963345), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242547360.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 109159.58287046\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 24531.06588542\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.2898676091624814\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: -174.99999701976776\n",
            "feature_name: inventory_target_log_distance, x: 0, y: -174.99999701976776\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 109159.58287046\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 109159.58287046\n",
            "log_distance: 0.25453958455069525\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 17847.77355772, y: 747.764185086591\n",
            "log_distance: 3.1725463810783356\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 17847.77355772, y: 0\n",
            "log_distance: 32.81548497870878\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 17847.77355772\n",
            "log_distance: 32.81548497870878\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 17847.77355772, y: 19490.03407443\n",
            "log_distance: 0.08802449203498419\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 17847.77355772\n",
            "log_distance: 10.192489843788318\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 17847.77355772\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.22472663636440504, 0.012726979227534763, 0, 0, 0, 0, 0.163028543655666, 0.15862731905391678, 25.06441236841673, 22.868184534210112, 1, 1, 0, 0, 1, 1, 0.00440122460174921, 0.08426155184944334, 0.9999657051148472, 0.514025716791165, 0.5096244921894159, 0.9999625494755384, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 2: [[ 9.99999756e-05 -9.99999756e-05  2.64999996e-02  2.64999996e-02\n",
            "   1.00000000e+00 -3.49999994e-01  0.00000000e+00  0.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05 -9.99999756e-05  2.64999996e-02  2.64999996e-02\n",
            "  1.00000000e+00 -3.49999994e-01  0.00000000e+00  0.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Action processed for model 2. Time taken: 0.07469844818115234\n",
            "Recent trades retrieved for model 2\n",
            "No recent trades for model 2, skipping order manager update\n",
            "Current time: 1702076242547360.0\n",
            "Decision time: 1702076242547360.0\n",
            "Current inventory: 0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 2: -0.26249999552965164\n",
            "Checked if episode is done for model 2. Done: False, Reason: \n",
            "Rollout buffer updated for model 2\n",
            "Processing model 3\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66862, Volume: 16656.85963345\n",
            "Remaining volume after matching: 16656.85963345\n",
            "Finished simulating market data update\n",
            "Market data updated for model 3\n",
            "State vector constructed for model 3\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 3\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 16656.85963345\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 16656.85963345), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242547360.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 109159.58287046\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 24531.06588542\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.2898676091624814\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 174.99999701976776\n",
            "feature_name: inventory_target_log_distance, x: 0, y: 174.99999701976776\n",
            "log_distance: 28.19063688683407\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 109159.58287046\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 109159.58287046\n",
            "log_distance: 0.25453958455069525\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 17847.77355772, y: 747.764185086591\n",
            "log_distance: 3.1725463810783356\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 17847.77355772, y: 0\n",
            "log_distance: 32.81548497870878\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 17847.77355772\n",
            "log_distance: 32.81548497870878\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 17847.77355772, y: 19490.03407443\n",
            "log_distance: 0.08802449203498419\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 17847.77355772\n",
            "log_distance: 10.192489843788318\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 17847.77355772\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.22472663636440504, 0.012726979227534763, 0, 0, 0, 0, 0.163028543655666, 0.15862731905391678, 25.06441236841673, 22.868184534210112, 1, 1, 0, 0, 1, 1, 0.00440122460174921, 0.08426155184944334, 0.9999657051148472, 0.514025716791165, 0.5096244921894159, 0.9999625494755384, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 3: [[ 9.99999756e-05  5.99999999e-04 -2.44999995e-02  2.64999996e-02\n",
            "   1.00000000e+00  3.49999994e-01  1.00000000e+00  0.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05  5.99999999e-04 -2.44999995e-02  2.64999996e-02\n",
            "  1.00000000e+00  3.49999994e-01  1.00000000e+00  0.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: 174.99999701976776\n",
            "Hold action value: 1.0\n",
            "Action processed for model 3. Time taken: 0.06980013847351074\n",
            "Recent trades retrieved for model 3\n",
            "No recent trades for model 3, skipping order manager update\n",
            "Current time: 1702076242547360.0\n",
            "Decision time: 1702076242547360.0\n",
            "Current inventory: 0\n",
            "Inventory target: 174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 3: -0.26249999552965164\n",
            "Checked if episode is done for model 3. Done: False, Reason: \n",
            "Rollout buffer updated for model 3\n",
            "Processing model 4\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66862, Volume: 16656.85963345\n",
            "Remaining volume after matching: 16656.85963345\n",
            "Finished simulating market data update\n",
            "Market data updated for model 4\n",
            "State vector constructed for model 4\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 4\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 16656.85963345\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4536.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 16656.85963345), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Current Time: 1702076242547360.0\n",
            "Debug: Total Bid Volume for most recent snapshot: 109159.58287046\n",
            "Debug: Total Ask Volume for most recent snapshot: 84628.51698504\n",
            "Debug: Imbalance for most recent snapshot: 24531.06588542\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.2898676091624814\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686900e-01\n",
            "volume             1.393712e+03\n",
            "Name: 1283, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate -0.6646512699360287 at index 1\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 2\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 3\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 4\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 5\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 6\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 7\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 8\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 9\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 10\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 11\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 12\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 13\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: -0.010467602769430786, Difference trade volume: 523.4726719112298\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687997202797202\n",
            "Initial seven_minute_dema: 0.6687062810043649\n",
            "Initial thirty_five_minute_dema: 0.6685391492162851\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4536.69549713\n",
            "log_distance: 31.44580509188591\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: normalized_weighted_avg_price_spread, x: -1.0, y: -1.0\n",
            "log_distance: 0.0\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 0, y: 500\n",
            "log_distance: 29.24045902836265\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 0\n",
            "Reference price: -174.99999701976776\n",
            "feature_name: inventory_target_log_distance, x: 0, y: -174.99999701976776\n",
            "log_distance: 0.0\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6687062810043649\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687997202797202, y: 0.6687062810043649\n",
            "log_distance: 0.00013972165420955696\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687997202797202\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687997202797202, y: 0.6685391492162851\n",
            "log_distance: 0.00038968592430238536\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6687062810043649\n",
            "Reference price: 0.6685391492162851\n",
            "feature_name: dema_7_35_log_distance, x: 0.6687062810043649, y: 0.6685391492162851\n",
            "log_distance: 0.0002499642700928284\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84628.51698504\n",
            "Reference price: 109159.58287046\n",
            "feature_name: total_volume_log_distance, x: 84628.51698504, y: 109159.58287046\n",
            "log_distance: 0.25453958455069525\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19490.03407443, y: 747.764185086591\n",
            "log_distance: 3.26057087311332\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 17847.77355772, y: 747.764185086591\n",
            "log_distance: 3.1725463810783356\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 747.764185086591\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 747.764185086591\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19490.03407443, y: 0\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 17847.77355772, y: 0\n",
            "log_distance: 32.81548497870878\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19490.03407443\n",
            "Reference price: 0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 17847.77355772\n",
            "log_distance: 32.81548497870878\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19490.03407443\n",
            "log_distance: 32.90350947074377\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 17847.77355772, y: 19490.03407443\n",
            "log_distance: 0.08802449203498419\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 19490.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 19490.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.6684084802056168, y: 19490.03407443\n",
            "log_distance: 10.280514335823302\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.6684084802056168, y: 17847.77355772\n",
            "log_distance: 10.192489843788318\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.6684084802056168\n",
            "Reference price: 17847.77355772\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_buy_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.6684084802056168\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.6684084802056168\n",
            "log_distance: 22.622995134920465\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.756787261938648\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.756787261938648, y: -1.826696600214756\n",
            "log_distance: 25.074419165771918\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 439.3941612295557\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 439.3941612295557, y: -0.022889600041385353\n",
            "log_distance: 29.11124780174978\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0.00013973141573454532, 6.986082710477848e-06, 0.0003897618617258173, 1.948429621511927e-05, 0.00024999551376420645, 1.249821350464142e-05, 0.0, 0, 0.22472663636440504, 0.012726979227534763, 0, 0, 0, 0, 0.163028543655666, 0.15862731905391678, 25.06441236841673, 22.868184534210112, 1, 1, 0, 0, 1, 1, 0.00440122460174921, 0.08426155184944334, 0.9999657051148472, 0.514025716791165, 0.5096244921894159, 0.9999625494755384, 0, 1, 0, 1, 0, 1, 0, 1, -5.246346799477658, 1, -19197.235864109145, 1, 0.0, 0, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 4: [[ 9.99999756e-05 -9.99999756e-05  2.64999996e-02 -2.44999995e-02\n",
            "   8.73466716e-01 -3.49999994e-01  0.00000000e+00  1.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99999756e-05 -9.99999756e-05  2.64999996e-02 -2.44999995e-02\n",
            "  8.73466716e-01 -3.49999994e-01  0.00000000e+00  1.00000000e+00]\n",
            "Current inventory: 0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 0.8734667163407814\n",
            "Executing cancellation logic: Selecting orders furthest from market\n",
            "Not enough orders to cancel while maintaining at least one order per side.\n",
            "Order cancellation logic executed\n",
            "Action processed for model 4. Time taken: 0.07021260261535645\n",
            "Recent trades retrieved for model 4\n",
            "No recent trades for model 4, skipping order manager update\n",
            "Current time: 1702076242547360.0\n",
            "Decision time: 1702076242547360.0\n",
            "Current inventory: 0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 174.99999701976776\n",
            "Unrealized PnL: 0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: 0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -174.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -0.0\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -0.26249999552965164\n",
            "Reward calculated for model 4: -0.26249999552965164\n",
            "Checked if episode is done for model 4. Done: False, Reason: \n",
            "Rollout buffer updated for model 4\n",
            "Processing model 5\n",
            "Simulating market data: event              1.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.686200e-01\n",
            "volume             1.665686e+04\n",
            "Name: 6810, dtype: float64\n",
            "Checking for trade executions based on market update\n",
            "Market Update - Side: buy, Price: 0.66862, Volume: 16656.85963345\n",
            "Remaining volume after matching: 16656.85963345\n",
            "Finished simulating market data update\n",
            "Market data updated for model 5\n",
            "State vector constructed for model 5\n",
            "Warm-up complete, processing actions\n",
            "Order book snapshots and current trades retrieved for model 5\n",
            "Current state of the Order Book:\n",
            "Bids:\n",
            "Price: 0.66866, Volume: 1190.91392427\n",
            "Price: 0.66862, Volume: 16656.85963345\n",
            "Price: 0.66861, Volume: 1600.0\n",
            "Price: 0.66857, Volume: 18229.59679266\n",
            "Price: 0.66852, Volume: 5707.21292916\n",
            "Price: 0.66847, Volume: 413.67640798\n",
            "Price: 0.66846, Volume: 14959.70809512\n",
            "Price: 0.66845, Volume: 5050.0\n",
            "Price: 0.66844, Volume: 353.72651763\n",
            "Price: 0.66843, Volume: 44997.88857019\n",
            "\n",
            "Asks:\n",
            "Price: 0.66873, Volume: 4499.69549713\n",
            "Price: 0.66875, Volume: 14953.3385773\n",
            "Price: 0.66877, Volume: 1600.0\n",
            "Price: 0.66878, Volume: 14952.72031144\n",
            "Price: 0.6688, Volume: 5000.0\n",
            "Price: 0.66886, Volume: 14950.98456893\n",
            "Price: 0.66888, Volume: 4000.0\n",
            "Price: 0.6689, Volume: 4786.94482342\n",
            "Price: 0.66892, Volume: 10458.22893682\n",
            "Price: 0.66893, Volume: 9389.60427\n",
            "Current Order_Book: [([(0.66866, 1190.91392427), (0.66862, 1700.6860341), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4536.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)]), ([(0.66866, 1190.91392427), (0.66862, 16656.85963345), (0.66861, 1600.0), (0.66857, 18229.59679266), (0.66852, 5707.21292916), (0.66847, 413.67640798), (0.66846, 14959.70809512), (0.66845, 5050.0), (0.66844, 353.72651763), (0.66843, 44997.88857019)], [(0.66873, 4499.69549713), (0.66875, 14953.3385773), (0.66877, 1600.0), (0.66878, 14952.72031144), (0.6688, 5000.0), (0.66886, 14950.98456893), (0.66888, 4000.0), (0.6689, 4786.94482342), (0.66892, 10458.22893682), (0.66893, 9389.60427)])]\n",
            "Current Trades: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64, event              2.000000e+00\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             3.700000e+01\n",
            "dtype: float64]\n",
            "Current Time: 1702076242547360.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-b23c665de96a>:1017: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.returns[t] = last_advantage + self.values[t]\n",
            "<ipython-input-25-b23c665de96a>:885: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  value_loss = F.mse_loss(state_values, returns)\n",
            "\rProcessing Generations:   0%|          | 0/10 [06:48<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug: Total Bid Volume for most recent snapshot: 109159.58287046\n",
            "Debug: Total Ask Volume for most recent snapshot: 84591.51698504\n",
            "Debug: Imbalance for most recent snapshot: 24568.06588542\n",
            "Debug: Imbalance Ratio for most recent snapshot: 1.2904317922300041\n",
            "trades_data_snapshots: [event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687600e-01\n",
            "volume             1.400747e+02\n",
            "Name: 1310, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.685000e-01\n",
            "volume             1.544844e+03\n",
            "Name: 2641, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.591396e+03\n",
            "Name: 3543, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.408604e+03\n",
            "Name: 3544, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683300e-01\n",
            "volume             7.480774e+02\n",
            "Name: 3704, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683400e-01\n",
            "volume             1.585706e+03\n",
            "Name: 4054, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.129290e+00\n",
            "Name: 4127, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683500e-01\n",
            "volume             3.438367e+02\n",
            "Name: 4650, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             3.011746e+03\n",
            "Name: 4668, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683800e-01\n",
            "volume             3.426240e+03\n",
            "Name: 4669, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.683700e-01\n",
            "volume             1.459685e+03\n",
            "Name: 4839, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.683600e-01\n",
            "volume             1.000000e+03\n",
            "Name: 5525, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             6.782716e+01\n",
            "Name: 6450, dtype: float64, event              2.000000e+00\n",
            "exch_timestamp     1.702076e+15\n",
            "local_timestamp    1.702076e+15\n",
            "side              -1.000000e+00\n",
            "price              6.686600e-01\n",
            "volume             4.228838e+02\n",
            "Name: 6713, dtype: float64, event              2.000000e+00\n",
            "local_timestamp    1.702076e+15\n",
            "side               1.000000e+00\n",
            "price              6.687300e-01\n",
            "volume             3.700000e+01\n",
            "dtype: float64]\n",
            "Debug: Processing 15 trades data snapshots\n",
            "Debug: Added buy flow rate 0.019617411852339485 at index 1\n",
            "Debug: Added buy flow rate 0.0007323193594563164 at index 2\n",
            "Debug: Added buy flow rate -2574.5348712676073 at index 3\n",
            "Debug: Added buy flow rate -0.028932081685318602 at index 4\n",
            "Debug: Added buy flow rate 0.022082128380335984 at index 5\n",
            "Debug: Added sell flow rate -0.11077415070802445 at index 6\n",
            "Debug: Added sell flow rate 0.010465716794114554 at index 7\n",
            "Debug: Added buy flow rate 0.5916958293005864 at index 8\n",
            "Debug: Added buy flow rate 4764.303835517239 at index 9\n",
            "Debug: Added buy flow rate -0.062492080739857535 at index 10\n",
            "Debug: Added sell flow rate -0.017802125821453123 at index 11\n",
            "Debug: Added buy flow rate -0.014413480294503721 at index 12\n",
            "Debug: Added sell flow rate 0.009507658725860457 at index 13\n",
            "Debug: Added buy flow rate -0.1363361521489126 at index 14\n",
            "Debug: Cached EMA/CV values calculated for buy and sell flow rates\n",
            "Difference traded price: 0.010468698591214442, Difference trade volume: -91.25055156995846\n",
            "Finished updating trade metrics\n",
            "Checking DEMAs and MADs:\n",
            "Initial one_minute_dema: 0.6687297208386018\n",
            "Initial seven_minute_dema: 0.6686364682551054\n",
            "Initial thirty_five_minute_dema: 0.6684692013812252\n",
            "Retrieved MAD Volatilities:\n",
            "Name of Feature: my_best_bid_to_ask_volume_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0\n",
            "feature_name: my_best_bid_to_ask_volume_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: log_distance_my_best_bid_volume_to_market_best_volume, x: 0, y: 1190.91392427\n",
            "log_distance: 30.108327224870422\n",
            "feature_name: log_distance_my_best_ask_volume_to_market_best_volume, x: 0, y: 4499.69549713\n",
            "log_distance: 31.43761593610489\n",
            "feature_name: my_worst_bid_to_market_best_bid_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_worst_ask_to_market_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: my_worst_bid_to_my_best_bid_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_worst_ask_to_my_best_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: my_best_bid_to_current_log_distance, x: 0, y: 0.66866\n",
            "log_distance: 22.62337136067266\n",
            "feature_name: my_best_ask_to_current_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "Name of Feature: average_buy_to_best_bid_ratio\n",
            "Average entry price: 0.66873\n",
            "Reference price: 0.66866\n",
            "Name of Feature: average_sell_to_best_ask_ratio\n",
            "Average entry price: 0\n",
            "Reference price: 0.66873\n",
            "feature_name: average_buy_to_best_bid_log_distance, x: 0.66873, y: 0.66866\n",
            "log_distance: 0.00010468150661202547\n",
            "feature_name: average_sell_to_best_ask_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: average_sell_to_worst_ask_log_distance, x: 0, y: 0\n",
            "log_distance: 0.0\n",
            "feature_name: average_buy_to_worst_bid_log_distance, x: 0, y: 0.66873\n",
            "log_distance: 22.62347604217927\n",
            "feature_name: normalized_weighted_avg_price_spread, x: 5.234075325822273e-05, y: -1.0\n",
            "log_distance: 13.16811566061052\n",
            "Name of Feature: active_orders_to_aum_ratio\n",
            "Average entry price: 24.74301\n",
            "Reference price: 500\n",
            "feature_name: active_orders_to_aum_log_distance, x: 24.74301, y: 500\n",
            "log_distance: 3.0060650735391534\n",
            "Name of Feature: inventory_target_ratio\n",
            "Average entry price: 37.0\n",
            "Reference price: -174.99999701976776\n",
            "feature_name: inventory_target_log_distance, x: 37.0, y: -174.99999701976776\n",
            "log_distance: 26.636768842584683\n",
            "Name of Feature: dema_1_7_ratio\n",
            "Average entry price: 0.6687297208386018\n",
            "Reference price: 0.6686364682551054\n",
            "feature_name: dema_1_7_log_distance, x: 0.6687297208386018, y: 0.6686364682551054\n",
            "log_distance: 0.00013945706779200373\n",
            "Name of Feature: dema_1_35_ratio\n",
            "Average entry price: 0.6687297208386018\n",
            "Reference price: 0.6684692013812252\n",
            "feature_name: dema_1_35_log_distance, x: 0.6687297208386018, y: 0.6684692013812252\n",
            "log_distance: 0.00038964952236170136\n",
            "Name of Feature: dema_7_35_ratio\n",
            "Average entry price: 0.6686364682551054\n",
            "Reference price: 0.6684692013812252\n",
            "feature_name: dema_7_35_log_distance, x: 0.6686364682551054, y: 0.6684692013812252\n",
            "log_distance: 0.00025019245456969763\n",
            "Name of Feature: depth_ratio\n",
            "Average entry price: 10\n",
            "Reference price: 10\n",
            "feature_name: depth_log_distance, x: 10, y: 10\n",
            "log_distance: 0.0\n",
            "Name of Feature: total_volume_ratio\n",
            "Average entry price: 84591.51698504\n",
            "Reference price: 109159.58287046\n",
            "feature_name: total_volume_log_distance, x: 84591.51698504, y: 109159.58287046\n",
            "log_distance: 0.25497688502536775\n",
            "feature_name: own_best_bid_to_inventory_log_distance, x: 0, y: 37.0\n",
            "log_distance: 26.636768842584683\n",
            "feature_name: own_best_ask_to_inventory_log_distance, x: 0, y: 37.0\n",
            "log_distance: 26.636768842584683\n",
            "feature_name: own_best_ask_volume_to_total_active_order_value, x: 0, y: 24.74301\n",
            "log_distance: 26.234393954823496\n",
            "feature_name: own_best_bid_volume_to_total_active_order_value, x: 0, y: 24.74301\n",
            "log_distance: 26.234393954823496\n",
            "feature_name: top_two_ask_levels_volume_log_distance_AUM, x: 19453.03407443, y: 747.6859121020441\n",
            "log_distance: 3.258775344241445\n",
            "feature_name: top_two_bid_levels_volume_log_distance_AUM, x: 17847.77355772, y: 747.6859121020441\n",
            "log_distance: 3.172651062584948\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_AUM\n",
            "Average entry price: 19453.03407443\n",
            "Reference price: 747.6859121020441\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_AUM\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 747.6859121020441\n",
            "feature_name: top_two_ask_levels_volume_log_distance_inventory, x: 19453.03407443, y: 37.0\n",
            "log_distance: 6.264840417780599\n",
            "feature_name: top_two_bid_levels_volume_log_distance_inventory, x: 17847.77355772, y: 37.0\n",
            "log_distance: 6.178716136124102\n",
            "Name of Feature: top_two_ask_levels_volume_ratio_inventory\n",
            "Average entry price: 19453.03407443\n",
            "Reference price: 37.0\n",
            "Name of Feature: top_two_bid_levels_volume_ratio_inventory\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 37.0\n",
            "feature_name: top_two_bid_levels_volume_log_distance_own_best_bid, x: 0, y: 17847.77355772\n",
            "log_distance: 32.81548497870878\n",
            "feature_name: top_two_ask_levels_volume_log_distance_own_best_ask, x: 0, y: 19453.03407443\n",
            "log_distance: 32.90160926036528\n",
            "feature_name: top_two_bid_levels_volume_log_distance_top_two_ask_levels_volume, x: 17847.77355772, y: 19453.03407443\n",
            "log_distance: 0.0861242816564971\n",
            "Name of Feature: top_two_bid_levels_volume_top_two_ask_levels_volume_ratio\n",
            "Average entry price: 17847.77355772\n",
            "Reference price: 19453.03407443\n",
            "Name of Feature: vwap_top_two_ask_ratio\n",
            "Average entry price: 0.668385821630189\n",
            "Reference price: 19453.03407443\n",
            "feature_name: vwap_top_two_ask_log_distance, x: 0.668385821630189, y: 19453.03407443\n",
            "log_distance: 10.278648025313178\n",
            "feature_name: vwap_top_two_bid_log_distance, x: 0.668385821630189, y: 17847.77355772\n",
            "log_distance: 10.19252374365668\n",
            "Name of Feature: vwap_top_two_bid_ratio\n",
            "Average entry price: 0.668385821630189\n",
            "Reference price: 17847.77355772\n",
            "Name of Feature: ratio_average_buy_to_vwap\n",
            "Average entry price: 0.66873\n",
            "Reference price: 0.668385821630189\n",
            "feature_name: log_diff_buy_vwap, x: 0.66873, y: 0.668385821630189\n",
            "log_distance: 0.0005148071271683929\n",
            "Name of Feature: ratio_average_sell_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.668385821630189\n",
            "feature_name: log_diff_sell_vwap, x: 0, y: 0.668385821630189\n",
            "log_distance: 22.622961235052102\n",
            "Name of Feature: ratio_own_best_bid_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.668385821630189\n",
            "feature_name: log_diff_own_best_bid_vwap, x: 0, y: 0.668385821630189\n",
            "log_distance: 22.622961235052102\n",
            "Name of Feature: ratio_own_best_ask_to_vwap\n",
            "Average entry price: 0\n",
            "Reference price: 0.668385821630189\n",
            "feature_name: log_diff_own_best_ask_vwap, x: 0, y: 0.668385821630189\n",
            "log_distance: 22.622961235052102\n",
            "Name of Feature: cv_buy_sell_ratio\n",
            "Average entry price: 7.754884994888232\n",
            "Reference price: -1.826696600214756\n",
            "feature_name: cv_buy_sell_log_distance, x: 7.754884994888232, y: -1.826696600214756\n",
            "log_distance: 25.07417389665735\n",
            "Name of Feature: ema_buy_sell_ratio\n",
            "Average entry price: 359.5715120138363\n",
            "Reference price: -0.022889600041385353\n",
            "feature_name: ema_buy_sell_log_distance, x: 359.5715120138363, y: -0.022889600041385353\n",
            "log_distance: 28.910764008081163\n",
            "State vector: [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0.00010468698591214443, 0, 5.234075330601274e-06, 1, 0, 1, 0.658405783030526, 0.95051398, 0.15030325367695768, -1.2114285750291787, 1, 0.00013946679238094258, 6.972853389600186e-06, 0.00038972544559763865, 1.948247611808507e-05, 0.0002502237553121652, 1.2509622728484882e-05, 0.0, 0, 0.2250655896567047, 0.012748844251268387, 1, 1, 1, 1, 0.16293876721207226, 0.1586325531292474, 25.017654953187154, 22.870683222508195, 0.31324202088902997, 0.3089358068062051, 524.7576776872974, 481.37225831675676, 1, 1, 0.0043062140828248555, 0.0825198018246435, 0.9999656410501789, 0.5139324012656589, 0.509626187182834, 0.9999625507450849, 0.000514939663099966, 2.574035635841965e-05, 0, 1, 0, 1, 0, 1, -5.24530542947117, 1, -15709.946917539668, 1, 1.8181818181818181, 1, 7.00000000000145e-05]\n",
            "State size: 66\n",
            "State tensor: torch.Size([1, 66])\n",
            "Action sampled from model 5: [[ 9.99966772e-05  5.99999999e-04  2.64999996e-02 -2.44999995e-02\n",
            "   0.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]]\n",
            "Starting process_action...\n",
            "Action unpacked: [ 9.99966772e-05  5.99999999e-04  2.64999996e-02 -2.44999995e-02\n",
            "  0.00000000e+00 -3.49999994e-01  1.00000000e+00  1.00000000e+00]\n",
            "Current inventory: 37.0, Current mid-price: 0.668695\n",
            "Target inventory level: -174.99999701976776\n",
            "Hold action value: 0.0\n",
            "Bid price: 0.66876, Ask price: 0.6691\n",
            "Placing limit order: Order ID 00b5028f-f19d-4920-afc7-20b289d061f6, Price 0.66876, Volume 37.0, Side buy\n",
            "Executing matched trade: Order ID 00b5028f-f19d-4920-afc7-20b289d061f6, Price 0.66873, Volume 37.0, Side buy\n",
            "Executing cancellation logic: Selecting orders furthest from market\n",
            "Not enough orders to cancel while maintaining at least one order per side.\n",
            "Order cancellation logic executed\n",
            "Action processed for model 5. Time taken: 0.08569002151489258\n",
            "Recent trades retrieved for model 5\n",
            "new_trade_data: [{'order_id': '00b5028f-f19d-4920-afc7-20b289d061f6', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Debugging update_tick_data method:\n",
            "Timestamp (float): 1702076242547360.0\n",
            "Type of timestamp: <class 'numpy.float64'>\n",
            "One hour window (timedelta): 1:00:00\n",
            "Type of one_hour_window: <class 'datetime.timedelta'>\n",
            "Updating EMA trades with new_trade_data: [{'order_id': '00b5028f-f19d-4920-afc7-20b289d061f6', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Adding trade to queue: Timestamp: 1702076242547360.0, Price: 0.66873\n",
            "Trade queue before removal: [(1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873), (1702076242547360.0, 0.66873)]\n",
            "Trade queue after removal: [(1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873), (1702076242547360.0, 0.66873)]\n",
            "Updating EMA trades with new_trade_data: [{'order_id': '00b5028f-f19d-4920-afc7-20b289d061f6', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Adding trade to queue: Timestamp: 1702076242547360.0, Price: 0.66873\n",
            "Trade queue before removal: [(1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873), (1702076242547360.0, 0.66873)]\n",
            "Trade queue after removal: [(1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873), (1702076242547360.0, 0.66873)]\n",
            "Updating EMA trades with new_trade_data: [{'order_id': '00b5028f-f19d-4920-afc7-20b289d061f6', 'price': 0.66873, 'volume': 37.0, 'side': 'buy'}]\n",
            "Adding trade to queue: Timestamp: 1702076242547360.0, Price: 0.66873\n",
            "Trade queue before removal: [(1702075816910821.0, 0.6686), (1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873), (1702076242547360.0, 0.66873)]\n",
            "Trade queue after removal: [(1702075816910821.0, 0.6686), (1702075831228826.0, 0.66869), (1702075833114984.0, 0.66876), (1702075904723294.0, 0.6685), (1702075968290668.0, 0.66834), (1702075968290739.0, 0.66834), (1702075991120986.0, 0.66833), (1702076029053384.0, 0.66834), (1702076043339896.0, 0.66835), (1702076075894509.0, 0.66835), (1702076080403429.0, 0.66837), (1702076080403516.0, 0.66838), (1702076111872385.0, 0.66837), (1702076137694309.0, 0.66836), (1702076202367991.0, 0.66873), (1702076239712268.0, 0.66866), (1702076242542653.0, 0.66873), (1702076242547360.0, 0.66873)]\n",
            "Order manager updated for model 5\n",
            "Current time: 1702076242547360.0\n",
            "Decision time: 1702076242547360.0\n",
            "Current inventory: 74.0\n",
            "Inventory target: -174.99999701976776\n",
            "Inventory deviation: 248.99999701976776\n",
            "Unrealized PnL: 0.0\n",
            "Realized PnL: 0\n",
            "Drawdown Penalty: -0.0\n",
            "Liquidity Reward: 0\n",
            "Inventory Penalty: -248.99999701976776\n",
            "Queue Position Reward: 0\n",
            "Rate Limit Penalty: -320.9681818181818\n",
            "Position Penalty: 0\n",
            "directional reward: 0\n",
            "Total Reward: -321.34168181371143\n",
            "Reward calculated for model 5: -321.34168181371143\n",
            "Checked if episode is done for model 5. Done: True, Reason: Penalty threshold exceeded\n",
            "Rollout buffer updated for model 5\n",
            "Starting training model...\n",
            "Number of states in buffer: 2\n",
            "Shape of the last state: (1, 66)\n",
            "Shape of last_state_tensor for model input: torch.Size([1, 66])\n",
            "Last value from critic: -598.9874267578125\n",
            "Returns and advantages computed.\n",
            "Number of sequential batches: 1\n",
            "Number of random batches: 1\n",
            "Updating model with sequential batches...\n",
            "Batch structure:\n",
            "states: torch.Size([2, 1, 66])\n",
            "actions: torch.Size([2, 1, 8])\n",
            "rewards: torch.Size([2])\n",
            "dones: torch.Size([2, 1, 1])\n",
            "log_probs: torch.Size([2, 1, 1])\n",
            "values: torch.Size([2])\n",
            "returns: torch.Size([2])\n",
            "advantages: torch.Size([2])\n",
            "States shape: torch.Size([2, 66])\n",
            "Processed a batch.\n",
            "Updating model with random batches...\n",
            "Batch structure:\n",
            "states: torch.Size([2, 1, 66])\n",
            "actions: torch.Size([2, 1, 8])\n",
            "rewards: torch.Size([2])\n",
            "dones: torch.Size([2, 1, 1])\n",
            "log_probs: torch.Size([2, 1, 1])\n",
            "values: torch.Size([2])\n",
            "returns: torch.Size([2])\n",
            "advantages: torch.Size([2])\n",
            "States shape: torch.Size([2, 66])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "NaN detected in shared_output after shared_layers",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-22af05171f2e>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Run the backtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-fe18f02c10fd>\u001b[0m in \u001b[0;36mrun_backtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1107\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing market data update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate_market_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_market_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevolutionary_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_up_complete\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#self.process_market_data(market_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished processing market data update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Trade execution event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-fe18f02c10fd>\u001b[0m in \u001b[0;36mprocess_market_data\u001b[0;34m(self, market_data, evolutionary_model, hyperparams, warm_up_complete)\u001b[0m\n\u001b[1;32m   1378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m                     \u001b[0;31m# Reset the model's state for a new training session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_model_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model {i} state reset for new training session\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-fe18f02c10fd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, hyperparams)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;31m# Second Epoch: Random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Updating model with random batches...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_batches\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass mean, std, nu for policy update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-b23c665de96a>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, batches)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processed a batch.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-b23c665de96a>\u001b[0m in \u001b[0;36mcompute_losses\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"States shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0maction_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m# Create Student's t-distribution for current policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-b23c665de96a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m# Shared feature extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mshared_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NaN detected in shared_output after shared_layers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;31m# Actor path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: NaN detected in shared_output after shared_layers"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "marketdata_df = pd.read_csv('/content/drive/MyDrive/filenamefile.csv')\n",
        "\n",
        "# # Convert DataFrame to list of MarketEvent objects\n",
        "# marketdata_events = load_data(marketdata_df)\n",
        "\n",
        "# Initialize the BacktestEngine\n",
        "population_size =6  # Number of agents in the population\n",
        "num_generations = 10\n",
        "engine = BacktestEngine(marketdata_df, population_size, num_generations, actor_critic_hyperparams, ppo_hyperparams, environment_training_settings, evolutionary_training_config)\n",
        "\n",
        "# Run the backtest\n",
        "engine.run_backtest()"
      ],
      "id": "cf1336dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afa03b8a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_csv_files(update_files, trade_files):\n",
        "    all_update_dfs = []\n",
        "    all_trade_dfs = []\n",
        "\n",
        "    for update_file in update_files:\n",
        "        try:\n",
        "            update_df = pd.read_csv(update_file, names=[\"Local Timestamp\", \"Price\", \"Volume\", \"Exchange Timestamp\", \"Type\"], header=0)\n",
        "            update_df['Exchange Timestamp'] = (update_df['Exchange Timestamp'] * 1e9).astype('int64')\n",
        "            all_update_dfs.append(update_df)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File not found: {update_file}\")\n",
        "\n",
        "    for trade_file in trade_files:\n",
        "        try:\n",
        "            trade_df = pd.read_csv(trade_file, names=[\"Local Time\", \"Exchange Time\", \"Price\", \"Volume\", \"Side\"], header=0)\n",
        "            trade_df['Exchange Time'] = (trade_df['Exchange Time'] * 1e9).astype('int64')\n",
        "            all_trade_dfs.append(trade_df)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File not found: {trade_file}\")\n",
        "\n",
        "    combined_update_df = pd.concat(all_update_dfs, ignore_index=True) if all_update_dfs else None\n",
        "    combined_trade_df = pd.concat(all_trade_dfs, ignore_index=True) if all_trade_dfs else None\n",
        "\n",
        "    return combined_update_df, combined_trade_df\n",
        "\n",
        "# Use glob to find all update and trade files\n",
        "update_files = glob.glob(\"update_snapshot_*.csv\")\n",
        "trade_files = glob.glob(\"trade_snapshot_*.csv\")\n",
        "\n",
        "# Process data\n",
        "processed_data = read_csv_files(update_files, trade_files)\n",
        "update_df, trade_df = processed_data\n",
        "\n",
        "# Print DataFrames (optional, for checking)\n",
        "if update_df is not None:\n",
        "    print(\"Update DataFrame:\")\n",
        "    print(update_df.head())\n",
        "\n",
        "if trade_df is not None:\n",
        "    print(\"\\nTrade DataFrame:\")\n",
        "    print(trade_df.head())"
      ],
      "id": "afa03b8a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e289d81f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Constants for event types\n",
        "DEPTH_EVENT = 1\n",
        "TRADE_EVENT = 2\n",
        "\n",
        "# Continue with the rest of your code...\n",
        "\n",
        "# Immediately after loading the data\n",
        "print(update_df.head())\n",
        "print(trade_df.head())\n",
        "\n",
        "# Rename columns to standardize\n",
        "update_df.rename(columns={'Local Timestamp': 'local_timestamp', 'Price': 'price', 'Volume': 'volume', 'Exchange Timestamp': 'exch_timestamp', 'Type': 'side'}, inplace=True)\n",
        "trade_df.rename(columns={'Local Time': 'local_timestamp', 'Exchange Time': 'exch_timestamp', 'Price': 'price', 'Volume': 'volume', 'Side': 'side'}, inplace=True)\n",
        "print(\"Unique values in 'Type' column of update_df:\", update_df['side'].unique())\n",
        "\n",
        "# Check unique values in the 'Side' column of trade_df\n",
        "print(\"Unique values in 'Side' column of trade_df:\", trade_df['side'].unique())\n",
        "\n",
        "# Assuming the renaming is done as before\n",
        "\n",
        "# Correct mapping for 'side' based on the inspected unique values\n",
        "update_df['side'] = update_df['side'].map({'ask': -1, 'bid': 1})\n",
        "trade_df['side'] = trade_df['side'].map({'s': -1, 'b': 1})\n",
        "\n",
        "# Add event type column and concatenate dataframes as before\n",
        "# ...\n",
        "\n",
        "# Add event type column\n",
        "update_df['event'] = DEPTH_EVENT\n",
        "trade_df['event'] = TRADE_EVENT\n",
        "\n",
        "# Concatenate dataframes\n",
        "combined_df = pd.concat([update_df, trade_df], ignore_index=True)\n",
        "\n",
        "# Sort if necessary\n",
        "combined_df.sort_values(by=[ 'local_timestamp'], inplace=True)\n",
        "\n",
        "# Reorder columns\n",
        "column_order = ['event', 'exch_timestamp', 'local_timestamp', 'side', 'price', 'volume']\n",
        "combined_df = combined_df[column_order]\n",
        "\n",
        "# Print the combined DataFrame\n",
        "print(combined_df.head(10))"
      ],
      "id": "e289d81f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2283a8f0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "prev_exch_timestamp = 0\n",
        "prev_local_timestamp = 0\n",
        "correct_exch_timestamp = True  # Enable timestamp correction\n",
        "\n",
        "def correct_timestamp(row):\n",
        "    global prev_exch_timestamp, prev_local_timestamp\n",
        "    if correct_exch_timestamp:\n",
        "        # If exch_timestamp is out of order, mark it as -1\n",
        "        if row['exch_timestamp'] < prev_exch_timestamp:\n",
        "            row['exch_timestamp'] = -1\n",
        "\n",
        "        # Update prev_exch_timestamp if it's not -1\n",
        "        if row['exch_timestamp'] != -1:\n",
        "            prev_exch_timestamp = row['exch_timestamp']\n",
        "\n",
        "        # Ensure local_timestamp is always greater or equal to exch_timestamp\n",
        "        # If not, adjust local_timestamp to be equal to exch_timestamp\n",
        "        # Also, ensure local_timestamp is non-decreasing\n",
        "        if row['local_timestamp'] < max(prev_local_timestamp, row['exch_timestamp']):\n",
        "            row['local_timestamp'] = max(prev_local_timestamp, row['exch_timestamp'])\n",
        "        else:\n",
        "            prev_local_timestamp = row['local_timestamp']\n",
        "\n",
        "    return row\n",
        "\n",
        "# Convert timestamps from nanoseconds to microseconds\n",
        "combined_df['exch_timestamp'] = combined_df['exch_timestamp'] // 1000\n",
        "combined_df['local_timestamp'] = combined_df['local_timestamp'] // 1000\n",
        "\n",
        "# Apply the correct_timestamp function\n",
        "combined_df = combined_df.apply(correct_timestamp, axis=1)\n",
        "\n",
        "# Sorting the DataFrame\n",
        "combined_df.sort_values(by=['local_timestamp', 'exch_timestamp'], inplace=True)\n",
        "\n",
        "\n",
        "# Print the sorted DataFrame (optional)\n",
        "print(combined_df.head(15))\n",
        "\n",
        "combined_df.to_csv('filename.csv', index=False)  # Set index=False to exclude row indices\n"
      ],
      "id": "2283a8f0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26e448f9"
      },
      "outputs": [],
      "source": [],
      "id": "26e448f9"
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}